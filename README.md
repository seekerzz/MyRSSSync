# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [supabase/supabase](https://github.com/supabase/supabase) | 以下是Supabase i18n (国际化)目录的简要中文概述：<br/><br/>1. **总览**：<br/>   - "概述"：提供目录整体介绍<br/><br/>2. **语言列表**：<br/>   - "中文"：当前页面的语言版本<br/>   - "其他语言"：列出所有已翻译的Supabase语言版本<br/><br/>3. **详细内容**：<br/>   - "每种语言的详情页"：为每个已翻译的语言版本提供详细的文档和指南<br/><br/>请注意，这只是一个简要概述。实际目录可能会包含更多细节或特定语言的链接。 |
| [tokio-rs/tokio](https://github.com/tokio-rs/tokio) | Tokio是一个用于构建高性能网络应用程序的Rust库。它遵循MSRV（Minimum Supported Rust Version）策略，至少每六个月发布一个新的MSRV版本。<br/><br/>对于bug修复， Tokio有一些LTS（长期支持）版本，这些版本会持续一年或更长时间提供回溯的bug修复。<br/><br/>贡献者在提交代码作为Tokio的一部分时，默认情况下，该代码将遵循MIT许可证，没有额外条款。 |
| [sebastianstarke/AI4Animation](https://github.com/sebastianstarke/AI4Animation) | 抱歉，您的问题似乎没有提供足够的信息来生成一个准确的摘要。您提到了一篇关于SIGGRAPH 2020项目快速前进演示的论文，但具体到摘要的部分，需要明确论文的主要内容、创新点以及实际展示的效果等信息。如果能提供更详细的信息，我会很高兴帮助你生成摘要。 |
| [free-educa/books](https://github.com/free-educa/books) | 这个仓库是Dev-Books，一个致力于提供精选开发和编程书籍的资源库。它由名为"free-educa"的团队维护，并且所有的书籍都可以免费下载阅读。<br/><br/>此外，仓库还提供了如何使用这个资源库的方法，包括浏览话题、贡献书籍、下载阅读以及反馈建议等操作指南。<br/><br/>总的来说，这个Dev-Books仓库是一个为开发者提供高质量学习资料的平台。 |
| [git-ecosystem/git-credential-manager](https://github.com/git-ecosystem/git-credential-manager) | Git Credential Manager 是一个用于 Git 的凭据管理工具。它可以帮助用户在使用 Git 进行操作时，自动填充和更新凭据信息。<br/><br/>GCM 支持多种凭据类型，包括但不限于基本 HTTP 代理、Windows 账户服务等。它还提供了一种配置代理的方式，以便在需要通过代理网络访问 Git 服务器时进行设置。<br/><br/>此外，GCM 还有一个项目路线图，展示了未来可能添加的功能和改进方向。对于想要贡献代码或提出建议的开发者来说，这是一个了解项目进展的好地方。 |
| [practical-tutorials/project-based-learning](https://github.com/practical-tutorials/project-based-learning) | 本文主要介绍了几个编程语言的学习资源，包括但不限于：<br/><br/>1. **Rust**:<br/>   - 学习 Rust的博客文章：`Create a simulation of evolution using neural network and genetic algorithm, and compile the application to WebAssembly`<br/>   <br/>2. **Scala**：<br/>   - 使用Hacking with Swift学习Scala的项目：`Hacking with Swift 39 projects - Learn Swift by doing`<br/>   <br/>3. **Swift**：<br/>   - 学习Swift的第一人称射击游戏，完全从零开始：`Retro first-person shooter from scratch in Swift`<br/>   <br/>4. **额外资源**：<br/>   - 推荐网站如Udemy、Full Stack Python等提供编程课程。<br/>   - 例如ScotchIO的博客文章链接，以及提供练习和项目实战的平台如Exercism、Egghead.io等。<br/><br/>这些资源可以帮助初学者快速入门编程语言，并通过实践不断提升技能。 |
| [krahets/hello-algo](https://github.com/krahets/hello-algo) | 本书致力于打造一本面向初学者的开源数据结构与算法教程。全书采用动画图解的方式，旨在让学习过程更加清晰易懂，降低入门门槛。<br/><br/>源代码部分支持一键运行，帮助读者在实践中提升编程技能，并理解算法的工作原理和数据结构底层实现。<br/><br/>鼓励读者参与内容修正、代码翻译等贡献活动，共同推动书籍质量的提升。<br/><br/>本书还特别感谢每一位撰稿人的无私奉献，他们的辛勤工作让这本书更加完善。 |
| [neo4j-labs/llm-graph-builder](https://github.com/neo4j-labs/llm-graph-builder) | 这段文字是关于一个名为LLM Knowledge Graph Builder Application的工具或服务的介绍。它提供了如何连接到Neo4j Aura实例，选择数据源，配置LLM模型，定义实体图谱，以及如何通过应用查看和预览生成的图形等内容。最后还提到了联系支持的方式。 |
| [goldmansachs/gs-quant](https://github.com/goldmansachs/gs-quant) | "GS Quant"是一个由高盛公司内部量化开发者创建的Python金融量化工具包。它基于全球大型风险转移平台，旨在加速量化交易策略开发和衍生产品风险管理解决方案的设计。<br/><br/>要使用GS Quant，首先需要一个客户端ID和秘密，这些通常只提供给高盛的机构客户。获取更多信息可以联系销售覆盖或Marquee Sales。<br/><br/>此外，GS Quant还提供了详细的安装指南、示例代码以及贡献者指南等资源。如果你有任何问题或者建议，可以直接通过邮件与他们联系。" |
| [pytube/pytube](https://github.com/pytube/pytube) | 本文是一个关于pytube轻量级Python YouTube视频下载库的介绍。它详细描述了如何安装和使用这个库，包括在Python脚本中导入YouTube类并下载视频的方法，以及通过命令行接口进行操作的步骤。此外，还提到了对完整播放列表的下载支持。 |
| [langflow-ai/langflow](https://github.com/langflow-ai/langflow) | 本文是关于Langflow CLI参数和环境变量的详细指南。参数包括设置后端只运行服务器而不加载前端的功能，以及用于存储功能的选项。环境变量则允许用户通过操作系统或`.env`文件来配置这些参数。<br/><br/>此外，文章还提到了如何贡献到Langflow项目，以及查看项目的贡献者列表。<br/><br/>总的来说，本文为开发者提供了理解和使用Langflow CLI参数和环境变量的详细指南。 |
| [mem0ai/mem0](https://github.com/mem0ai/mem0) | Mem0是一个用于大型语言模型的智能记忆层。它提供多级记忆功能，包括用户、会话和AI代理的记忆保留。Mem0还具备自我学习和适应个性化的能力。<br/><br/>开发者可以通过Mem0的API简单地将其集成到各种应用中。跨平台一致性也确保了在不同设备上的一致行为。<br/><br/>此外，Mem0还支持将数据存储在Qdrant这样的向量存储服务中，这对于生产环境来说是一个选项。<br/><br/>总之，Mem0提供了一种先进的记忆解决方案，适用于大型语言模型的个性化需求。 |
| [oceanbase/oceanbase](https://github.com/oceanbase/oceanbase) | OceanBase数据库是一款开源的实时分析型数据库，它支持MySQL兼容，并且在性能、扩展性和安全性方面具有优势。<br/><br/>本文档主要介绍了如何快速部署OceanBase数据库实例，包括使用Docker和Kubernetes两种方式。同时，也提供了关于系统架构和贡献指南的详细信息。<br/><br/>对于想要深入了解OceanBase或者参与社区贡献的开发者，本文档是一个很好的起点。 |
| [actions/runner-images](https://github.com/actions/runner-images) | GitHub Actions 镜像提供了哪些服务？如何找到我正在使用的镜像版本？如果需要其他Linux发行版，怎么办？如何请求将新工具预安装在镜像中？以及关于使用特定分支构建自定义镜像的建议。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [36氪独家｜腾讯手游《元梦之星》DAU有大幅波动，日均千万级别](https://www.36kr.com/p/2863388872968832) | 1. 腾讯手游《元梦之星》的DAU数据受到关注，春节期间一度反超《蛋仔派对》，后稳定在1000万以下。<br/><br/>2. 两款游戏的广告投放相当激烈，春节期间分别进入国产游戏买量排行榜前三。<br/><br/>3. 《元梦之星》的营销费用也不少，这在一定程度上侵蚀了网易游戏的利润。<br/><br/>4. 两款游戏并非要彻底竞争，它们在平台和用户群体上有一定的差异点。 |
| [免费代炒，菜市场抢餐饮小店的生意，一批老板慌了](https://www.36kr.com/p/2867232891591041) | 这篇文章讨论了餐饮行业中的跨界竞争现象。传统菜市场、便利店和大型商超都在尝试通过开设食堂或提供现炒服务来吸引消费者。<br/><br/>文章指出，这些跨界选手不仅利用自身的资源布局餐饮业务，还可能探索出新的业务增长路径。然而，随着市场竞争的升级，餐饮行业的内卷也在持续加剧。<br/><br/>文章最后提到，无论是抵抗“外卷”，还是应对内部竞争，餐饮品牌都需要不断提升服务质量、产品性价比以及运营效率，以适应不断变化的市场环境。 |
| [小米、王田苗、智源，投了一家具身智能公司｜36氪独家](https://www.36kr.com/p/2866102868085639) | 小米集团和机器人泰斗王田苗共同投资了一家名为「小雨智造」的具身智能科技公司。该公司在2023年2月成立，已经完成了亿元种子轮融资，并与亦庄国投的战略投资有所关联。<br/><br/>「小雨智造」的核心创始团队来自小米、华为等大厂，其产品主要打造“一脑多形”的具身智能机器人，应用于工业领域。<br/><br/>此外，小米还在内部布局了具身智能业务，包括人形机器人CyberOne的研发和应用。<br/><br/>总的来说，小米通过外部投资和内部项目的方式，在具身智能领域积极布局，以期抓住人工智能下一波浪潮的机会。 |
| [进口小包裹超20亿件，欧盟对Temu、SHEIN“出重拳”｜焦点分析](https://www.36kr.com/p/2863392212880008) | 这段内容是关于欧洲海关改革以及美国对跨境电商的审查情况。主要内容包括：<br/><br/>1. 欧洲海关面临的压力：由于电子商务的指数级增长，海关当局承受巨大压力。<br/><br/>2. 2023年欧盟海关法改革草案：旨在缓解压力，提出取消150欧元免税门槛等措施。<br/><br/>3. 美国对跨境电商审查的收紧：SHEIN和Temu面临更严格的指控，包括剥削劳工、逃避关税等问题。<br/><br/>4. 市场反应：巴西和南非政府的政策调整反映了本土保护的趋势，这对SHEIN和Temu等外来电商来说是一个挑战。 |
| [BBA 退出价格战，反向操作保利润](https://www.36kr.com/p/2866512520630405) | 文章讨论了传统豪华品牌在高端市场面临价格战的困境。广汽曾庆洪的观点认为企业目的是盈利，但盈利应为社会做贡献。文章还提到了新能源渗透率可能成为打破平衡的新契机。<br/><br/>总结来说，文章分析了传统豪华品牌面临的挑战，并提出了通过社会责任和新能源发展寻求新平衡的可能性。 |
| [8点1氪｜李佳琦方回应直播间卖假和田玉传闻；特朗普遭刺杀后支持率未显著领先；多家大模型测不出9.11和9.9哪个大](https://www.36kr.com/p/2867003680985219) | 以下是关于最近一些科技、投融资和奥运新闻的简要概述：<br/><br/>1. **科技公司动态**：<br/>   - **天府逍遥科技完成融资**：这家公司完成了数亿元人民币的新一轮融资，投资方包括沃衍资本和纽尔利资本等。<br/>   - **嘉轩智能完成新一轮融资**：永磁驱动装备创新企业嘉轩智能也宣布完成亿元级天使+轮融资。<br/><br/>2. **奥运新闻**：<br/>   - **巴黎市长为奥运会下河游泳**：巴黎市长在为奥运会做准备时，表示愿意亲自体验一下游泳这项运动。<br/>   - **塞纳河游泳安全质疑**：这一行为引发了关于河流清洁度和游泳安全性的讨论。<br/><br/>3. **投融资简述**：<br/>   - **耀速科技Xellar Biosystems融资情况**：公司完成了亿元级人民币的天使+轮融资，投资方包括鼎泰集团等。<br/>   - **嘉轩智能融资规模**：嘉轩智能的融资规模达到了数亿元人民币级别。<br/><br/>以上信息是基于公开报道和资料整理而成，具体细节可能会有所出入。 |
| [萨莉亚用业绩给餐饮人上了一课：中国市场好得很](https://www.36kr.com/p/2866394400151941) | 这篇文章讨论了餐饮品牌萨莉亚在中国市场的成功复制问题。文章指出，尽管一些萨莉亚的员工尝试复刻其模式，但复制并非易事，存在诸多挑战。<br/><br/>首先，萨莉亚在食材采购上的优势难以复制。它能直供挪威虾、澳大利亚酱等进口食材，并且价格有竞争力。<br/><br/>其次，萨莉亚供应链管理的强大也难以复制。它对供应链的精细化控制，包括原料的稳定性、加工流程的高效性等方面，都是其他品牌难以比拟的。<br/><br/>最后，文章提到萨莉亚的成功源于其初心——服务社会和贡献社会价值。这表明在复制过程中，保持初心和价值观的重要性。<br/><br/>总结来说，尽管萨莉亚在中国市场的成功复制吸引了一些餐饮创业者，但复制并非易事，需要考虑诸多因素并保持核心竞争力。 |
| [全球顶尖资本豪赌小红书](https://www.36kr.com/p/2866435512684678) | 小红书正在经历人员优化和市场策略快速变动的阶段。公司通过挖人加码电商、商业化和产品增长等行动来提升效率。<br/><br/>目前，小红书估值提升被视为一个积极信号，但要创造新的资本神话，公司还需要用实际行动证明其价值和潜力。<br/><br/>总之，小红书正面临挑战与机遇并存的局面，如何抓住机会并应对挑战将是公司未来的关键。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024](https://arxiv.org/abs/2407.12038) | 1. 提出Inspiration and Convincing Audio Generation Challenge 2024（ICAGC 2024），作为ISCSLP 2024竞赛和挑战的一部分。<br/><br/>2. 描述了当前文本到语音技术（TTS）的优点，即能生成高质量音频。然而，它在传达复杂情感和控制细节内容方面的能力有限。<br/><br/>3. 强调了这种限制导致的实际应用中合成音频与人类主观感知之间存在差距，例如陪伴儿童的机器人和营销机器人等场景。<br/><br/>4. 认为问题的核心在于高质量音频生成与最终人类主观体验之间的不一致性。<br/><br/>5. 因此，这个挑战的目标是提升合成音频的说服力和接受度，重点在于实现人机一致的、具有感染力和说服力的音频生成。 |
| [Semantic Communication for the Internet of Sounds: Architecture, Design Principles, and Challenges](https://arxiv.org/abs/2407.12203) | 1. 提出互联网声音（IoS）的概念，强调结合声感知、处理和传输技术实现多设备间的协作。<br/><br/>2. 确立了在IoS中实现声音同步的必要性，指出需要精确同步三个关键因素：音质、时间以及行为控制。<br/><br/>3. 指出传统的基于比特的通信方式可能无法满足动态通信环境下的这些同步要求。<br/><br/>4. 提出使用语义通信（SC）作为解决IoS同步挑战的一种方法。SC能够捕获和利用数据源中的逻辑关系。<br/><br/>5. 详细阐述了一种以IoS为中心的SC框架，包括编码器的设计，它能从多样化的源提取语义信息并进行传输。<br/><br/>6. 探讨了如何通过编码器将重要语义信息提炼出来，以减少传输延迟，用于时间同步。<br/><br/>7. 在接收端，描述了基于上下文和知识推理的解码器工作原理，旨在重建和整合声音，实现音质同步。<br/><br/>8. 提出SC模型可以通过定期共享知识的方式进行更新，以优化其同步行为。<br/><br/>9. 最后，论文探讨了一些关于数学模型、资源分配以及跨层协议等开放性问题。 |
| [Laugh Now Cry Later: Controlling Time-Varying Emotional States of Flow-Matching-Based Zero-Shot Text-to-Speech](https://arxiv.org/abs/2407.12229) | 1. 介绍EmoCtrl-TTS，一个零样本情感可控的TTS系统。<br/><br/>2. EmoCtrl-TTS具备生成具有丰富情绪（包括NVs）语音的能力，适用于任何说话者的场景。<br/><br/>3. 系统利用唤醒和价值值、笑声嵌入等信息来调节零样本流匹配为基础的TTS流程。<br/><br/>4. 为了实现高质量情感语音生成，EmoCtrl-TTS使用基于伪标签的大量表达性数据进行训练，超过270,000小时的数据。<br/><br/>5. 综合评估证明，EmoCtrl-TTS在口译场景中出色地模仿音频提示的情感，同时展示了其捕捉情绪变化、强烈表达情感和生成各种NVs的能力。 |
| [PCQ: Emotion Recognition in Speech via Progressive Channel Querying](https://arxiv.org/abs/2407.12380) | 1. 提出PCQ方法：该方法是一种创新的SER途径，通过逐步在通道维度进行层叠查询来动态建模情感的长期上下文信息。<br/><br/>2. 解决传统方法局限：传统的SER技术往往难以捕捉复杂情绪表达中的长期时间相关性和动态变化。<br/><br/>3. 实验结果显著提升性能：实验结果显示，使用PCQ方法的模型在IEMOCAP和EMODB两个数据集上分别提高了WA和UA精度，且显著超过了基线水平。 |
| [BSC-UPC at EmoSPeech-IberLEF2024: Attention Pooling for Emotion Recognition](https://arxiv.org/abs/2407.12467) | 1. 提出使用SER结果与西班牙语 corpus结合的挑战应对策略。<br/>2. 描述了系统架构，主要由预训练的语音和文本模型组成，用于提取两种模态的特征，并利用注意力池化机制进行整合。<br/>3. 系统在挑战中取得了第一名，具体表现为86.69%的Macro F1-Score。 |
| [TTSDS -- Text-to-Speech Distribution Score](https://arxiv.org/abs/2407.12707) | 1. 提出对Text-to-Speech（TTS）系统评估的反思，以适应新架构和数据集带来的变化。<br/><br/>2. 建议将合成语音的质量评价作为多个因素的组合，包括语调、说话者身份以及理解能力等。<br/><br/>3. 描述了一种评估方法，通过获取每个因素的对应指标，并测量它们与真实语音数据集和噪声数据集的距离来实现。<br/><br/>4. 该研究还进行了基准测试，对比了2008年至2024年间开发的35个TTS系统，证明其提出的评分方法与各时期的人类评估高度相关。 |
| [TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE 2024](https://arxiv.org/abs/2407.12743) | 1. 提供了团队TalTech-IRIT-LLIS在DISPLACE 2024挑战中提交的演讲者分段和语言分段的详细描述。<br/><br/>2. 描述了他们参与的两个赛道的具体工作：在演讲者分段赛道，他们的最佳系统是基于pyannote.audio的演讲者分段管道的集合，并结合了powerset训练和他们最近提出的PixIT方法。在语言分段赛道，他们对预训练的Wav2Vec2-BERT语言嵌入模型进行了微调，并使用AHC和VBx对短片段进行聚类，基于LDA/PLDA计算的相似性分数。<br/><br/>3. 提供了他们在两个挑战赛道上的最终结果：演讲者分段赛道上，他们的系统实现了27.1%的分段错误率；语言分段赛道上，他们获得了27.6%的语言分段错误率。这些成绩在各自的挑战中排名第一。 |
| [Flowers Revisited: A Preliminary Replication of Flowers et al. 1997](https://arxiv.org/abs/2407.11992) | 1. 该论文的中文贡献点在于对原研究（Flowers等人在1997年发表的论文）的复制和初步结果分析。<br/><br/>2. 研究者在实验中引入了音频视觉（audiovisual）scatterplots作为第三种条件，这是对原研究方法的扩展。<br/><br/>3. 该研究的初步结果显示与原研究相似的结果，这为后续深入探讨提供了依据。<br/><br/>4. 通过这个延长摘要，作者还希望引发关于重复研究对于整个研究社区重要性的讨论。 |
| [The Kolmogorov Complexity of Irish traditional dance music](https://arxiv.org/abs/2407.12000) | 1. 使用Lempel-Ziv压缩估计爱尔兰传统舞音乐旋律的算法复杂性。<br/><br/>2. 提供ABC notation，这是一种无节奏变化的音乐表示方式，所有音符长度相同。<br/><br/>3. 利用算法复杂性估测来区分简单或容易学习的曲调（重复多）与难度较大的曲调（重复少）。<br/><br/>4. 进一步对比两种舞曲类别——Reels和Jigs——在复杂性方面的差异。 |
| [A Language Modeling Approach to Diacritic-Free Hebrew TTS](https://arxiv.org/abs/2407.12206) | 1. 提出针对希伯来语文本到语音（TTS）任务的解决方案。<br/>2. 推荐采用一种基于语言建模的无标点符号的Diacritics-Free方法。<br/>3. 该模型处理的是离散的语音表示，并且依赖于词块分词器进行条件化。<br/>4. 利用野外弱监督数据对提出的模型进行了优化，并与多种基于标点符号的希伯来语TTS系统进行了比较。<br/>5. 结果表明，无论是在内容保真还是生成语音的自然性方面，提出的无标点符号Diacritics-Free方法都优于评估的基线系统。 |
| [Audio Conditioning for Music Generation via Discrete Bottleneck Features](https://arxiv.org/abs/2407.12563) | 1. 提出基于音频输入对音乐生成语言模型进行条件的新策略。<br/>2. 实验涉及两种不同的方法：文本反转（Textual Inversion）和从零开始训练的音乐语言模型。<br/>3. 在推理时，允许混合文本和音频条件，并通过一种新型的双分类器自由指导方法平衡它们。<br/>4. 进行自动和人工研究以验证这种方法的有效性。<br/>5. 将代码开放，并在GitHub上提供音乐样本链接，以展示模型生成的质量。 |
| [GraphMuse: A Library for Symbolic Music Graph Processing](https://arxiv.org/abs/2407.12671) | 1. 提供了GraphMuse，一个用于音乐图处理和符号音乐任务的GNN训练的统一框架和库。<br/><br/>2. 通过提出针对音乐分数中有意义行为的新邻居采样技术，增强了音乐图处理的效率和准确性。<br/><br/>3. GraphMuse还整合了层次建模元素，这有助于提升GNN在音乐任务中的表达能力和能力。<br/><br/>4. 实验结果证明GraphMuse在两个具体音乐预测任务（音高拼写和节奏检测）上显著优于先前方法，为符号音乐处理领域带来了标准化的可能。 |
| [Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors](https://arxiv.org/abs/2407.11828) | 1. 创立了Vibravox数据集，该数据集符合GDPR规定，包含使用五种不同身体传导音频传感器录制的音频样本。<br/><br/>2. 数据集不仅包括来自空中麦克风的参考音频数据，还包含了参与者在不同声学条件下录制的各种生理声音和言语样本。<br/><br/>3. 通过实验系列，研究者在诸如语音识别、语音增强和说话人验证等与语音相关的任务上进行了应用。<br/><br/>4. 这些实验使用了最先进的模型来评估和比较它们在使用不同音频传感器捕捉的信号上的性能。<br/><br/>5. 目的是更深入地理解这些传感器各自的特点以及它们对语音处理任务的影响。 |
| [Cross-modal Cognitive Consensus guided Audio-Visual Segmentation](https://arxiv.org/abs/2310.06259) | 1. 提出了一种名为C3N的跨模态认知共识引导网络，用于音频-视觉分割任务。<br/><br/>2. 设计了C3IM模块，用于提取统一的多模态标签，通过整合音频/视觉分类的信心和模态无关标签嵌入的相似性来实现。<br/><br/>3. 利用CCAM模块，将统一的多模态标签作为显式语义级别的指导输入到视觉 backbone中，通过认知共识引导注意力机制突出感兴趣对象的局部特征。 <br/><br/>4. 通过在AVSBench数据集上进行的单音源分割（S4）和多音源分割（MS3）设置实验，证明了C3N方法的有效性，并且达到了最先进的性能水平。<br/><br/>5. 提供了代码链接：https://github.com/ZhaofengSHI/AVS- C3N。 |
| [Towards Weakly Supervised Text-to-Audio Grounding](https://arxiv.org/abs/2401.02584) | 1. 引入并研究了弱监督文本到音频定位（WSTAG）任务，这是一个挑战性的多模态信息检索应用。<br/><br/>2. 对之前WSTAG方法中使用的平均池化策略的局限性进行了分析，并探讨了不同池化策略的效果。<br/><br/>3. 提出了基于短语级别的WSTAG框架，通过音频片段和短语之间的匹配标签进行训练。<br/><br/>4. 为增强弱标签的准确性并提供伪强标签，提出了先进的负样本采样策略以及自我监督方法。<br/><br/>5. 实验结果表明，提出的系统显著超越了之前WSTAG领域的最佳性能（SOTA）。<br/><br/>6. 最后，进行了广泛的实验分析，探讨了短语级别WSTAG框架中多个因素的影响。提供了代码和模型的链接供进一步研究。 |
| [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](https://arxiv.org/abs/2404.09956) | 1. 提出研究假设：关注音频生成中概念或事件的时空顺序对音频质量的影响，尤其是在数据有限的情况下。<br/><br/>2. 创造偏好学习数据集：使用现有模型Tango，通过合成方式为每个文本提示创建赢家和输家音频输出，供模型学习。<br/><br/>3. 实施优化训练：采用扩散-直接偏好优化（diffusion-DPO）损失在偏好数据集上对Tango模型进行微调。<br/><br/>4. 比较实验结果：通过自动评估和手动评估指标对比，展示优化后的音频质量相对于基础模型Tango和AudioLDM2有所提升。 |
| [Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models](https://arxiv.org/abs/2405.06134) | 1. 提出Whisper等大型语音基础模型广泛使用的特殊令牌（如$\texttt{}$}）。<br/><br/>2. 展示这些特殊令牌在对抗性攻击中可以被利用，以操纵模型的行为。<br/><br/>3. 提出一种简单但有效的方法来学习一个通用的声学表示，用于消除特定模型对特殊音频段的反应。<br/><br/>4. 实验结果表明，相同的、通用的0.64秒对抗性音频段能够成功地使目标模型沉默超过97%的语音样本。<br/><br/>5. 发现这种通用的对抗性音频段往往能转移到新的数据集和任务中。<br/><br/>6. 提出这项工作展示了Whisper等模型对“沉默”攻击的脆弱性，同时也提出了可能的风险和潜在好处，在现实世界场景中应用时：例如可以用来绕过语音内容审核系统，或者反过来也可以用来保护个人隐私语音数据。 |
| [PicoAudio: Enabling Precise Timestamp and Frequency Controllability of Audio Events in Text-to-audio Generation](https://arxiv.org/abs/2407.02869) | 1. 提出了一种名为PicoAudio的时空控制音频生成框架。<br/>2. PicoAudio通过设计专门的模型，整合了时间信息来指导音频生成。<br/>3. 利用数据爬取、分割、过滤和模拟等手段处理精细的时间-空间对齐的音频-文本数据。<br/>4. 通过主观和客观评估，证明PicoAudio在时间戳控制和事件发生频率控制方面显著超越了当时的最先进的生成模型。<br/>5. 生成样本可在演示网站https://zeyuxie29.github.io/PicoAudio.github.io/获取。 |
| [GROOT: Generating Robust Watermark for Diffusion-Model-Based Audio Synthesis](https://arxiv.org/abs/2407.10471) | 1. 提出了一种名为Groot的生成性鲁棒音频水印方法，作为对抗合成音频伪造的先驱。<br/><br/>2. Groot提出了一种同时进行水印生成和音频合成的并行处理方式，利用固定参数的扩散模型和专用编码器来实现这一过程。<br/><br/>3. 水印嵌入音频中，并通过轻量级解码器进行后续提取。实验结果表明Groot在抗攻击能力、特别是复合攻击下的鲁棒性方面表现出色，平均水印提取准确率接近95%。 |
| [Knowledge boosting during low-latency inference](https://arxiv.org/abs/2407.11055) | 1. 提出知识增强（Knowledge Boosting）技术，用于解决大型模型与小型设备之间资源限制的问题。<br/><br/>2. 设计并评估使用时间延迟输入的流式神经网络，处理8毫秒的帧。<br/><br/>3. 在不同通信延迟条件下，研究语音分离和增强任务，对比大型模型和小型模型的表现。<br/><br/>4. 结果表明，在性能差距较大的情况下，知识增强技术能带来更大的增益，为大型-小型模型协作提供了一种有前景的方法。 |
| [Statistics-aware Audio-visual Deepfake Detector](https://arxiv.org/abs/2407.11650) | 1. 提出统计特征损失，增强模型的区分能力，而非单纯依赖特征距离。<br/><br/>2. 采用波形描述音频，替代基于频率的表示，有助于音频信息的更自然处理。<br/><br/>3. 提出后处理的伪造分数标准化，消除因原始评分不同造成的比较偏差。<br/><br/>4. 使用较浅的网络结构以降低计算复杂度，适应对模型性能和资源消耗要求较高的场景。 |
