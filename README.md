# 五里墩茶社
---
| Title | Date | Summary |
| --- | --- | --- |
# 小工蚁创始人
---
| Title | Date | Summary |
| --- | --- | --- |
| [哪里找海量训练数据？ 大模型训练数据宝藏全公开！](https://www.bilibili.com/video/BV16gUhY7EkQ) | 2024-11-20 08:15:00 | |
| [抱抱脸开源SmolLM2 小模型运行在各种终端设备上](https://www.bilibili.com/video/BV1FQUhYJERx) | 2024-11-19 08:15:00 | 抱抱脸开源的SmolLM2小模型，适用于各种终端设备。该模型性能优异，适合进行文字处理和智能体应用。与同类模型相比，SmolLM2在多项性能指标上领先，尤其在语言文字处理方面表现突出。该模型有三个版本，分别包含135 million、360 million和1.7 billion参数，适用于不同终端设备。该模型的发布标志着小模型在性能上的不断提升，未来可能在手机上实现更多高级功能。<br/>哈根face开源小模型，性能出众，适合边缘计算。<br/>0:01 介绍SmolLM2,一个1.7B的小模型,适合边缘计算设备,如手机与PC,用于文本处理和生成。<br/>0:40 SmolLM2在多项性能测试中领先,除数学外,在语言处理上表现优异,哈根费斯提供微调脚本。<br/>1:02 SmolLM系列有三种模型,135M、360M和1.7B,适合各种终端设备,推动小模型高性能的发展趋势。<br/>抱抱脸开源SmolLM2小模型在手机端应用能力增强。<br/>2:00 小模型在手机端能力增强，未来可运行简单应用和智能体。<br/>2:13 手机上的app将能运行小模型，需更高级功能时再与服务器沟通。<br/>2:24 抱抱脸开源SmolLM2小模型能力介绍，科技巨头纷纷发力。<br/>|
| [MOICL：无需微调，通过分组上下文学习提升模型泛化能力](https://www.bilibili.com/video/BV1uYUhYaEa1) | 2024-11-18 08:15:00 | MOICL算法，无需微调，通过分组上下文学习提升模型泛化能力。爱丁堡大学的研究团队提出了一种新的方法，通过将问题和答案分组，提高回答问题的准确度。实验表明，这种方法在无需微调的情况下，性能提升了13%。关键在于，通过学习每个分组的例子，并将其权重加到模型的预测中，提高了模型的准确度。<br/>通过分组上下文学习，提升模型泛化能力。<br/>0:01 探讨在无法微调模型或微调代价高昂的情况下，提升模型准确度的方法。<br/>1:07 介绍MOICL算法，通过混合上下文学习提升模型泛化能力，性能较传统方法提升13%。<br/>3:22 详细解释MOICL算法的分组上下文学习机制，强调通过不同分组方式（静态、随机、BM25）和权重函数（均匀、向量化）提升模型回答问题的准确度。<br/>无需微调，分组上下文学习提升模型泛化能力。<br/>5:00 通过分组上下文学习，无需微调提升模型泛化能力，实验显示K=30分组效果最佳。<br/>7:00 两种输出值对比，直接输出值在大模型预测中表现更优，置信度值经过soft max处理。<br/>9:00 混合上下文学习方案，适合大模型无法微调的场景，有效提升模型推理性能。<br/>|
| [降本增效，安全可靠！ AI本地部署 打造你的专属编程助手](https://www.bilibili.com/video/BV1JYUrYVEM4) | 2024-11-17 14:38:37 | AI本地部署的重要性，以及如何通过AI助手来提高编程效率。视频中特别推荐了通义千问2.5的Instruct模型，这是一个专为工程师设计的代码生成模型，具有128K的上下文长度和出色的性能。该模型通过文件级别的预训练和项目级别的预训练，能够理解代码的语义和结构，从而生成高质量的代码。此外，该模型还结合了文本和数学题目的训练数据，使得其在代码生成、语义理解和数学能力方面都表现出色。<br/>AI本地部署，专属编程助手，降本增效，安全可靠。<br/>0:01  通义千问2.5 Instruct模型适合代码生成，上下文达128K，性能优秀。<br/>1:11  通义千问2.5 Instruct32B模型在代码生成任务中表现优异，性能超过开源和商业模型。<br/>3:06  通义千问2.5模型通过文件和项目级别的预训练，掌握大量代码知识，提升生成能力。<br/>AI本地部署，降本增效，安全可靠。<br/>7:20 介绍了一个未微调的模型与open code 8b base模型的对比，未微调模型在human error方面表现较好，但在DPP和big code bench方面表现领先。<br/>8:10 推荐使用同1000万2.5code 32B instruct模型作为工程师辅助开发的模型，其在代码生成、解释和修复方面表现优秀。<br/>12:47 介绍了如何本地部署同1000万2.5code 32B instruct模型，包括下载模型、使用VAIM进行部署和配置模型参数。<br/>|
| [上海AI创业团队开源OpenCoder代码生成大模型](https://www.bilibili.com/video/BV125mdYoEEW) | 2024-11-17 08:15:01 | 上海AI创业团队开源的OpenCoder代码生成大模型。该模型基于拉玛38B模型进行微调，主要应用于生成代码。团队在数据处理和模型训练方面进行了大量工作，使得模型在生成代码方面的性能显著提升。OpenCoder模型支持多种编程语言和脚本，包括HTML、Java和Python等。此外，该团队还公开了数据处理的详细流程和数据集，为后续的研究和应用提供了便利。<br/>上海AI团队开源OpenCoder，基于拉玛38B微调生成代码模型，性能优异。<br/>0:01 上海AI团队开源OpenCoder代码生成大模型，基于拉玛38B模型微调。<br/>1:07 OpenCoder模型性能优异，生成代码能力超过同类6B模型，达到66.05分。<br/>2:45 OpenCoder项目开源数据处理pipeline，便于进一步理解和优化。<br/>上海AI团队开源高质量代码生成大模型，适合小模型和个人用户。<br/>3:33 OpenCoder通过过滤负样本，提取与代码领域相关的数据，生成高质量数据集，用于训练模型。<br/>4:24 OpenCoder支持多种语言和脚本，HTML、Java和Python数据量较多，性能较强。<br/>6:49 OpenCoder的1.5B和8B模型在human ever评测中表现良好，适合小模型和个人用户使用。<br/>|
| [打造专属AI+开发工作室OpenWebUI #小工蚁](https://www.bilibili.com/video/BV1r4U8Y2EWj) | 2024-11-16 18:15:01 | 关于开源项目OpenWebUI的介绍。该项目是一个可以独立部署的AI工具，用户可以在本地部署模型。视频中展示了如何部署同1000万2.5code7B的模型，并进行了功能测试。OpenWebUI具有与大模型交互、语音识别和语音合成等功能。该项目在GitHub上非常流行，拥有4.7万颗星星。视频还简单介绍了如何配置和使用OpenWebUI，包括设置环境变量和使用特定的镜像。最后，视频邀请有兴趣的观众留言交流。<br/>介绍开源项目OpenWebUI，支持AI开发，功能强大。<br/>0:01 介绍开源项目OpenWebUI，一个可以独立部署的AI工具，支持本地模型部署。<br/>0:25 OpenWebUI支持与大模型进行聊天和交互，具备语音和TTS功能，项目受欢迎，4.7万颗星。<br/>1:14 演示OpenWebUI与通千万2.5G模型结合，解释DOCKFIVE功能，展示高级对话功能。<br/>OpenWebUI工作室在8000端口运行，使用Instruct模型，性能优越。<br/>2:02 通过设置环境变量，使用特定端口的OpenAI API，启动OpenWebUI。<br/>2:11 借助1000万2.5code7B的Instruct模型，运行在4090两块GPU上，上下文为32K，性能优越。<br/>2:35 项目介绍完毕，欢迎留言交流。<br/>|
| [开源变声大模型Seed-VC 无需训练支持对话和唱歌声音变声](https://www.bilibili.com/video/BV1c2UKY2ETF) | 2024-11-16 08:15:00 | 开源变声大模型Seed-VC，无需训练支持对话和唱歌声音变声的功能。项目名为CDEC，通过Zero-shot技术，用户只需提供参考音频和原始声音，即可实现声音的转换。模型基于diffusion训练，支持实时声音转化，并提供了音质和延时的参数调整。项目在PTAP和Hugging Face上开源，适合播客和音频讲座使用。<br/>开源变声模型Seed-VC支持对话和唱歌声音变声，效果良好。<br/>0:01 Seed-VC是一个无需训练的变声软件，支持对话和唱歌声音变声。<br/>1:04 该模型使用diffusion模型训练，可以通过调整参数来控制声音的感染力和创造力。<br/>1:43 Seed-VC在声音变化和角色变化方面具有良好应用，论文对比了通义千问的cosy voice模型，显示更强性能。<br/>开源变声模型支持实时对话和唱歌声音变声，无需训练。<br/>2:02 Seed-VC 项目提供了实时声音转换工具，支持声音实时转化，音质与推理时间成正比。<br/>3:03 项目支持声音克隆和唱歌声音转化，无需训练，零shot即可。<br/>3:25 项目名为Seed-VC，已在PTAP开源，适合播客和音频讲座使用。<br/>|
| [Qwen2.5-Coder阿里开源代码生成大模型 #小工蚁](https://www.bilibili.com/video/BV1jtmbYPEEV) | 2024-11-15 08:15:01 | Qwen2.5-Coder阿里开源代码生成大模型 #小工蚁 的相关信息。该模型在11月12日正式发布，最大的模型达到了32个币，是目前开源模型中性能最强的。与DeepSickCodeV2和VR模型相比，Qwen2.5Code在代码生成方面表现出色，尤其是在代码修复和推理方面。该模型支持40多种编程语言，包括Java、Python、JavaScript等，应用场景广泛。在人类目标对齐方面，Qwen2.5Code的胜率也比较高。该模型基于Apache2.0开源，可免费商用，上下文在7B及以上的模型达到了128K，3B以下模型为32K。<br/>阿里开源32B代码生成大模型，性能最强。<br/>0:01 通义千问2.5代码生成大模型于11月12日发布，最大模型达32B，性能最强。<br/>1:01 通义千问2.5code模型在代码生成、修复和推理方面表现出色，能力接近商业版GD4O。<br/>1:21 该模型支持约40种编程语言，应用场景广泛，包括编程语言之间的翻译。<br/>阿里开源代码生成大模型，性能强劲，适合开发使用。<br/>2:01 Qwen2.5-Coder阿里开源代码生成大模型在胜率上表现优异，可与GB4O和cloud3.5媲美，cloud3.5是工程师的首选。<br/>2:28 Qwen2.5-Coder阿里开源代码生成大模型提供了多种模型，包括7B、14B和32B，均基于阿帕奇2.0开源，免费商用。<br/>3:12 Qwen2.5-Coder阿里开源代码生成大模型在开发中表现优异，尤其在生成质量上，32B与7B有显著差异。<br/>|
| [介绍GPU最新内核优化GEMM原理 #小工蚁](https://www.bilibili.com/video/BV1NmmBYGEah) | 2024-11-14 08:15:00 | GPU内核优化GEMM原理。主要介绍了英伟达Cudalibrary中的GEMM优化，基于英伟达的HBM和SRAM的高性能内存结构，通过减少数据搬运和融合计算来提高GEMM的计算效率。文中还提到了Tensor Core在GEMM计算中的作用，以及Cudalibrary在GEMM计算中的性能优势。最后，文章还展望了未来GPU在GEMM计算中的发展方向。<br/>GPU内核优化GEMM原理，提升计算效率。<br/>0:01 介绍英伟达科特莱斯库的GEMM优化原理，强调减少内存数据搬运和融合计算的重要性。<br/>2:00 对比FP8量化操作，展示科特莱斯在百和co GPU上的性能优势，依赖KDA库。<br/>3:00 介绍科特莱斯的内存管理器，通过TMA加速器协同tensor CORE并行计算，优化矩阵乘法。<br/>GPU优化GEMM原理，减少内存搬运，提高效率。<br/>4:19 通过Tensor Core计算，减少全局内存搬运，提高效率。<br/>5:08 优化GEMM原理，利用SRAM处理小矩阵，提高计算效率。<br/>6:04 FP8 GEMM矩阵乘法实验，CUTLESS算法延迟最低，性能最佳。<br/>|
| [ClickHouse和OpenTelemetry构建一套性能日志观测平台](https://www.bilibili.com/video/BV19xmiYmE3f) | 2024-11-13 08:15:00 | ClickHouse和OpenTelemetry如何结合构建一套性能日志观测平台。OpenTelemetry是一个云原生的标准，能够从服务或软件中生成并收集数据，转发给需要的平台和分析工具。ClickHouse则作为数据存储，能够高效地处理海量数据，提供快速的查询能力。两者结合，能够实现对复杂系统性能的跟踪和错误追溯，构建一个可观测的系统。此外，视频还详细介绍了ClickHouse的性能优势，以及OpenTelemetry与ClickHouse结合的具体实现和应用。<br/>ClickHouse与OpenTelemetry结合，构建高性能日志观测平台。<br/>0:01 ClickHouse和OpenTelemetry可以构建一套可观测的系统，帮助了解复杂系统的性能、错误和组件状态。<br/>1:01 OpenTelemetry是一个云原生标准，帮助收集和转发数据到分析工具，支持多种语言和系统，开源且中立。<br/>2:06 ClickHouse作为存储，结合OpenTelemetry，能够快速构建性能日志观测平台，支持实时查询和报警。<br/>OpenTelemetry与ClickHouse构建性能日志观测平台，支持高并发日志收集与快速查询。<br/>3:05 多种应用可统一跟踪系统性能，日志可统一收集至ClickHouse。<br/>3:38 ClickHouse支持物化视图，快速查询，数据压缩存储空间小。<br/>4:42 OpenTelemetry与ClickHouse结合，处理每秒1000万到2000万记录，支持高并发。<br/>|
| [腾讯开源混元大模型 MoE架构389B参数 #小工蚁](https://www.bilibili.com/video/BV13uDYYCEJD) | 2024-11-12 08:15:00 | 腾讯开源的混元大模型MoE架构389B参数。该模型基于transformer的混合专家模型，具有256K的上下文能力。腾讯通过合成数据进行预训练，使用了高质量的合成数据集。该模型在推理时较为轻量，但仍需80GB的显卡进行加载。腾讯的混元大模型在多个评测中表现出色，尤其是在MMLU评测中达到了88.4分。该模型可以免费商用。<br/>腾讯开源混元大模型，性能对标拉玛3.1405B，采用MOE架构，参数量389B。<br/>0:01 腾讯开源混元大模型，性能对标拉玛3.1405B，领先DeepMind和Mixture。<br/>1:16 混元大模型上下文达到256K，实际有效128K，使用合成数据进行预训练。<br/>2:02 混元大模型通过精简KD Catch，节省95%的KV Catch，提高模型效率。<br/>腾讯开源混元大模型，参数389B，性能优异。<br/>3:18 腾讯混元大模型包含17个活跃专家，推理时使用2个专家进行决策。<br/>4:07 混元大模型采用MOE架构，通过GQA和GLA方式，减少KV catch的使用，同时保持模型性能。<br/>5:04 混元大模型在通1000分、MMLU等评估中表现优异，分数较高。<br/>|
| [TableGPT2针对表格问答场景开源大模型，性能超GPTo](https://www.bilibili.com/video/BV1UtDDYWE3t) | 2024-11-11 08:15:00 | 浙江大学联合发布的TableGPT2模型，该模型在处理表格数据方面表现出色。基于10000000GB和72B的模型，TableGPT2在表格数据理解上相较于之前的7B和72B模型，准确率提升了35%和49%。该模型借鉴了视觉模型的大模型，开发了一个专门针对表格的编码器，增强了对表格语义的理解能力。TableGPT2在32个评测中表现优异，尤其是在表格理解方面，提升了近50%的准确率。此外，该模型还开源了一个A进程框架和一个TableGPT2 Agent，进一步增强了模型的实用性。<br/>TableGPT2开源模型，提升表格数据理解准确率。<br/>0:01  TableGPT2针对表格问答场景的开源大模型，性能超GPTo，提升35%和49%的准确率。<br/>1:17  TableGPT2通过视觉模型的table in encoder编码器，增强表格语义理解能力。<br/>3:55  TableGPT2在训练过程中使用同1000万2.5和7B的模型，持续预训练，加强文本、代码和数学公式的理解。<br/>TableGPT2在表格问答场景中表现优异，性能超GD4O。<br/>5:03 预训练、单轮和多轮问答训练。<br/>6:10 TableGPT2擅长多轮对话，特别是处理发票金额和税款等复杂问题，拥有16万条多轮对话数据。<br/>9:41 TableGPT2在表格问答、文本转SQL、生成Python代码和图表生成方面表现优异，性能超过GD4O，且对自然语言理解能力不差。<br/>|
# AIGCLINK
---
| Title | Date | Summary |
| --- | --- | --- |
# 技术爬爬虾
---
| Title | Date | Summary |
| --- | --- | --- |
# 秋芝2046
---
| Title | Date | Summary |
| --- | --- | --- |
# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [trungdq88/Awesome-Black-Friday-Cyber-Monday](https://github.com/trungdq88/Awesome-Black-Friday-Cyber-Monday) | 这是一篇关于黑五和Cyber Monday促销活动的列表。每个条目都提供了一个链接到具体的网站或应用，以及一些简短的信息描述。<br/><br/>例如：<br/>1. 一个博客平台应用，提供个性化的数字照片框服务。<br/>2. 一个发现并连接 Shopify卖家的数据库服务。<br/>3. 提供优惠折扣代码的黑五促销信息。<br/><br/>这些条目旨在帮助读者找到他们可能感兴趣的特定产品或服务，并在黑五和Cyber Monday这样的购物高峰期获取优惠。 |
| [xtekky/gpt4free](https://github.com/xtekky/gpt4free) | 这段代码是关于一个名为`gpt4free`的GitHub项目。该项目包含了一个或多个与GPT-4（一种人工智能语言模型）相关的文件和代码。<br/><br/>具体操作包括：<br/><br/>1. `Vercel.py`：可能是一个用于部署到Vercel（一个云托管平台）的服务或API。<br/><br/>2. `har_file.py`：输入可能来自一个处理Har格式（通常用于聊天机器人）的文件。<br/><br/>3. 其他文件如`MetaAI.py`、`Gemini.py`等，它们可能是与特定AI服务或API相关的代码。<br/><br/>4. 项目整体遵循`GNU_GPL_v3.0`许可证，这意味着该项目是开源的，并且用户可以自由地使用、修改和分发该代码。 |
| [excalidraw/excalidraw](https://github.com/excalidraw/excalidraw) | 这段文字是关于Excalidraw项目的一段介绍。它首先提到Excalidraw是一个在线绘图工具，用户可以在浏览器中直接操作画布。<br/><br/>接着，文本提到了赞助者和合作公司的信息，这些公司为Excalidraw提供了免费的服务。<br/><br/>最后，还特别提到了Vercel、Sentry和Crowdin这三家公司在项目中的支持。<br/><br/>总结来说，这段文字主要介绍了Excalidraw项目的运营情况，包括其功能、合作伙伴以及服务模式等。 |
| [ai16z/eliza](https://github.com/ai16z/eliza) | 该README文件是Eliza，一个全功能的Discord、Twitter和Telegram聊天机器人项目的介绍。它包含了如何设置项目、启动Eliza、以及额外安装Sharp软件的要求。<br/><br/>此外，README还提到了社区联系的方式，包括GitHub Issues和Discord频道，这对于遇到问题或想要分享应用的用户来说非常重要。 |
| [blacklanternsecurity/bbot](https://github.com/blacklanternsecurity/bbot) | BBOT（Black Lantern Security的Bot工具）是一个由社区贡献的网络安全机器人工具。它旨在不断改进，提供强大的功能。<br/><br/>我们欢迎所有形式的贡献，不仅仅是代码，还有新的想法和功能建议。如果你有一个关于新特性或现有功能优化的想法，可以在  <a href="https://github.com/blacklanternsecurity/bbot/discussions">Discussions</a> 中提出。<br/><br/>此外，我们还提供了详细的  <a href="https://www.blacklanternsecurity.com/bbot/Stable/dev/">开发者文档</a> 来帮助你开始编写BBOT模块。如果你对编程或BBOT的内部工作感到困惑，这些资源将对你有所帮助。<br/><br/>最后，我们要特别感谢以下贡献者：<br/><br/>1. @TheTechromancer：创建BBOT项目<br/>2. @liquidsec：为BBOT的web黑客功能提供了大量工作，包括badsecrets和baddns模块<br/>3. Steve Micallef (@smicallef)：创建Spiderfoot工具<br/>4. @kerrymilan：拥有Neo4j和Ansible的专业知识<br/>5. @domwhewell-sage：家族成员，编写了一系列强大的代码窃取模块<br/>6. Aleksei Kornev (@alekseiko)：授予BBOT Pypi仓库所有权，这代表了社区对项目的贡献认可<br/>这些杰出的贡献者为BBOT的发展做出了重要贡献。 |
| [libsdl-org/SDL](https://github.com/libsdl-org/SDL) | 这是SDL 3.0版本的README文件，包含了关于Simple DirectMedia Layer（SDL）的基本信息和文档链接。该库是一个跨平台开发工具，用于提供音频、键盘输入、鼠标操作、joystick控制以及图形硬件访问等低级功能。它常被视频播放软件、游戏和模拟器使用。 |
| [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) | 这个仓库是一个由多个贡献者共同创建和维护的项目。它最初是由丹尼尔·斯特凡诺维奇发起的，现在由CodeCrafters, Inc.进行管理和更新。<br/><br/>根据提供的英文许可信息，CodeCrafters, Inc.已经放弃了所有版权和其他相关或邻接的权利，对于这项工作进行了豁免。 |
| [ItzCrazyKns/Perplexica](https://github.com/ItzCrazyKns/Perplexica) | Perplexica是一个AI驱动的搜索引擎，旨在提供更强大的搜索体验。它不仅提供了传统搜索引擎的功能，还通过使用大型语言模型来理解和回答用户的问题。<br/><br/>对于开发者和贡献者来说，Perplexica提供了API支持，允许他们集成到自己的应用中。同时，GitHub Issues是报告问题和提出建议的地方，鼓励用户参与改进过程。<br/><br/>总的来说，Perplexica是一个不断进步的AI搜索引擎，它不仅提供强大的搜索功能，还为开发者和用户提供了一个互动和贡献的平台。 |
| [f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts) | 这段文本是关于多个AI角色的贡献列表。每个AI角色（whisperers）都被标记为他们的GitHub链接，这表明他们参与了一个名为"f/awesome-chatgpt-prompts"的项目，该项目专注于ChatGPT聊天机器人生成的提示和问题的收集和整理。<br/><br/>最后，文本提到所有这些贡献都是无版权（CC-0）的，这意味着任何基于这些内容的行为都不会受到版权法律的限制。 |
| [motiondivision/motion](https://github.com/motiondivision/motion) | 这段文本是关于一个GitHub仓库的贡献者列表。每个链接代表一个个人开发者账户，他们的用户名包括"Nusu"、"OlegWock"等。这些账号可能是为了维护或更新这个GitHub仓库的内容而存在的。 |
| [leaningtech/webvm](https://github.com/leaningtech/webvm) | 这段话是关于WebVM项目的版本控制、依赖关系以及许可证信息的概述。<br/><br/>1. 版本控制：WebVM依赖于CheerpX，这是一个包含在项目中的x86-到-WebAssembly虚拟化技术。NPM包会随着每次发布更新。<br/><br/>2. 依赖关系：WebVM构建的基础是lwIP，这是一个用于TCP/IP协议栈的Web可访问版本。<br/><br/>3. 许可证信息：WebVM遵循Apache License Version 2.0，这意味着内容可以自由使用、修改和分发。但组织使用，包括非营利、学术和公共部门，需要获得许可。 |
| [krahets/hello-algo](https://github.com/krahets/hello-algo) | 本书致力于打造一本面向初学者的开源数据结构与算法教程。全书采用动画图解，语言通俗易懂，旨在降低学习曲线，引导读者探索算法和数据结构的世界。<br/><br/>源代码可一键运行，帮助读者在实践中提升编程技能，理解算法的工作原理和数据结构底层实现。<br/><br/>本书提倡互助学习，鼓励读者在评论区提问与分享见解。通过交流讨论，共同进步。<br/><br/>如果你对本书有所启发，不妨给项目点个 Star 支持一下。你的支持将激励我们持续改进内容，为更多读者提供更好的学习资源。 |
| [DataExpert-io/data-engineer-handbook](https://github.com/DataExpert-io/data-engineer-handbook) | 这段英文内容是关于数据工程师相关的课程和认证信息的概述。以下是简要的中文摘要：<br/><br/>**课程与认证**<br/><br/>- **Google Cloud专业数据工程师认证**：提供谷歌云数据工程师的专业资格。<br/>- - **Databricks Apache Spark开发者助理认证**：针对使用Apache Spark进行开发的Databricks认证。<br/>- - **Databricks 数据工程师助理认证**：入门级Databricks数据工程师职位的认证。<br/>- - **Databricks 数据工程师专业认证**：高级Databricks数据工程师的专业资格认证。<br/>- - **AWS Certified Data Engineer - Associate**：亚马逊AWS认证的数据工程师助理资格。<br/><br/>这些课程和认证旨在帮助数据工程师提升技能，获得行业认可的职业资格。 |
| [freqtrade/freqtrade](https://github.com/freqtrade/freqtrade) | 这段文字是关于一个项目或工具的特定要求。主要关注点包括：<br/><br/>1. **精确的时间同步**：系统需要一个准确且频繁与NTP服务器同步的时钟，以避免通信问题。<br/><br/>2. **硬件需求**：推荐使用至少2GB RAM、1GB硬盘空间和2个vCPU的云实例来运行这个项目。<br/><br/>3. **软件要求**：列出了一系列必需的软件，如Python 3.10以上版本、pip、git、TA-Lib以及虚拟env（推荐）。<br/><br/>总结来说，要成功运行这个项目，你需要满足一系列特定的硬件和软件配置要求。 |
| [NVIDIA/garak](https://github.com/NVIDIA/garak) | 本文是关于代码库`garak`的介绍。`garak`是一个用于安全探测大型语言模型（LLMs）的框架。开发者Leon Derczynski和团队提供了多种插件类型，如探针（probes）、检测器（detectors）和生成器（generators）。<br/><br/>使用`garak`时，可以通过命令行参数来指定要使用的探针或检测器，并进行相应的安全探测。此外，代码参考文档可以在`readthedocs.io`找到。<br/><br/>总之，`garak`是一个用于安全测试大型语言模型的框架，开发者提供了丰富的插件类型供用户选择和使用。 |
| [lvgl/lvgl](https://github.com/lvgl/lvgl) | LVGL是一个开源项目，欢迎贡献。贡献的方式多种多样，包括但不限于：分享关于项目的信息、编写示例代码、改进文档、修复bug或甚至自己创建一个基于LVGL的项目并加入LVGL组织。<br/><br/>超过300人已经在LVGL上留下了指纹。成为他们中的一员吧！在这里见到你！😊<br/><br/>此外，还提供了贡献者图表，直观展示了哪些人对LVGL做出了贡献。 |
| [olimorris/codecompanion.nvim](https://github.com/olimorris/codecompanion.nvim) | 这段代码是用于一个名为CodeCompanion的Neovim插件。插件提供了多种功能，如聊天缓冲区、文件差异工具、LSP助手等。<br/><br/>首先，插件定义了静态数据块（static data block）来存储一些配置信息和依赖检查结果。<br/><br/>然后，插件提供了一个更新处理函数（update handler function）来监控用户请求的特定模式。当这些模式匹配时，会调用相应的回调函数进行处理。<br/><br/>最后，插件还包含了一些工具的实现，如xml2lua库用于工具的脚本转换，以及Dante.nvim等简单但实用的diff工具。<br/><br/>总的来说，这段代码是构建一个功能丰富的Neovim插件的核心部分。 |
| [comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 以下是关于如何使用TLS/SSL以及支持和开发渠道的简要概述：<br/><br/>1. **支持与开发频道**：通过Matrix空间（#comfyui_space:matrix.org）进行交流，这是一个类似Discord但开源的平台。<br/><br/>2. **报告问题和请求新功能**：如果你遇到前端的问题或想要新的功能，使用`Comfy-Org/ComfyUI_frontend@latest`命令行参数来指定版本并提交问题。<br/><br/>3. **获取最新前端**：为了获得最新的前端版本，你可以添加`--front-end-version Comfy-Org/ComfyUI_frontend@latest`到你的命令中。这将使用每天发布的最新稳定版。<br/><br/>4. **访问旧版前端**：如果你需要使用旧版前端，可以使用`--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest`命令行参数来指定这个版本。<br/><br/>通过这些步骤，你可以轻松地在不同的前端版本之间切换，并报告和请求新的功能。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [雷军摸高，终于成了？](https://www.36kr.com/p/3043164347173509) | 小米集团在智能大家电、小米汽车等领域的成功，不仅推动了高端化的新路径，还吸引了包括女性用户在内的更多用户群体。卢伟冰表示，小米将继续加大研发投入，以AI技术为核心竞争力，提升用户体验，从而实现高端化的持续深化和市场拓展。 |
| [可拆卸显卡模具现身，模块化笔记本电脑2.0来了？](https://www.36kr.com/p/3042695591214601) | 模块化设计在游戏本领域的应用被讨论。这种设计可以提高显卡满功耗运行的可能性，同时降低CPU功耗，但散热问题仍需关注。<br/><br/>价格方面，火影RTX 4060笔记本电脑售价较低，而采用模块化设计的产品价格相对较高，这可能会影响消费者的购买决策。<br/><br/>对于用户来说，是否愿意为升级潜力付出更高的初始成本是一个值得思考的问题。如果同方的GX2.0能解决这些问题或部分问题，那么它将对笔记本电脑市场产生革命性影响。 |
| [三星AI新功能曝光，“重点通知”将成AI OS杀手锏功能？](https://www.36kr.com/p/3042712457494023) | 这篇文章讨论了未来手机操作系统（AI OS）的发展趋势，特别是系统级人工智能（AI）的应用。文章指出，AI在通知整合、语义理解等方面已经有所体现，未来将向全局任务管理、跨设备协作甚至情感交互等更深层次的进化。<br/><br/>此外，文章提到，AI OS的进化不仅是技术层面的进步，更是用户体验需求驱动下的交互变革。谁能在这场AI OS大战中实现这一转变，就有可能成为最终胜利者。<br/><br/>总结来说，这篇文章探讨了AI在AI OS中的应用前景，以及AI OS未来可能经历的交互变革。 |
| [直男小米，开始男女通吃](https://www.36kr.com/p/3042778023263745) | 本文主要讲述了小米在女性市场尝试和失败的案例，包括CC9与CIVI以及SU7等产品的表现。同时提到了一些女性用户对产品功能需求的真实反馈，以及小米在产品设计上向“女性友好”倾斜的做法。<br/><br/>总结来说，文章通过小米的女性市场策略分析，强调了尊重用户需求、提供情感价值的产品策略的重要性。 |
| [盒马来得太晚了](https://www.36kr.com/p/3041952096256137) | 这篇文章的摘要可以这样提炼：<br/><br/>盒马再变革：品质向上、价格向下<br/>侯毅对话远川研究所：与山姆、Costco比，我们仍学生态<br/><br/>内容围绕盒马这家零售企业进行改革升级的策略，以及其背后的领导者侯毅对于企业发展理念的解读。同时，文章还提到了盒马与行业标杆如山姆、Costco的对比，暗示了盒马在市场中的位置和自我定位。 |
| [几百万理发师，为什么总是听不懂话？](https://www.36kr.com/p/3041925952127109) | 这篇文章主要讲述了理发师晓华凭借精湛技艺和优质服务走红全网的故事。小栗旬也慕名而来，表达了对晓华的认可和敬意。<br/><br/>文章通过晓华的案例，展现了理发行业的本质——听得懂话，剪得好发。同时，晓华的成功也反映了消费者对于匠人精神和技术质量的追求。<br/><br/>总的来说，这篇文章提供了一个关于理发师成功故事的观察角度，同时也揭示了行业发展的某些趋势。 |
| [华为Mate 70定档，能否再度“王者归来”？](https://www.36kr.com/p/3041844428750338) | 这篇文章讨论了华为与苹果在中国高端手机市场的竞争态势。文章指出，华为在经历了供应链危机后的复苏，使其旗舰手机销量与苹果持平甚至超越。而苹果在国内销量下滑的趋势明显，AI技术优势相对减弱。<br/><br/>文章还提到，华为凭借品牌影响力、硬件参数和产品价格等多方面因素，有机会进一步提升市场份额。而其他安卓厂商则可以利用苹果与华为的对决，通过营销策略抢占市场机会。<br/><br/>总的来说，这篇文章分析了华为与苹果在中国高端手机市场的竞争态势以及各自的优势和挑战。 |
| [国产大模型独角兽，困在光环里](https://www.36kr.com/p/3042093782597767) | 本文主要围绕大模型产业的发展趋势、企业面临的挑战以及行业未来的可能性进行了探讨。<br/><br/>1. **概念与现实脱节**：尽管大模型技术发展迅速，但其实际应用和商业盈利模式尚未完全成熟，存在一定的认知偏差。<br/><br/>2. **资金压力与造血能力**：大模型公司需要大量投入进行技术研发，同时面临用户转化成本上升的压力。如何证明自身具有持续的造血能力成为关键问题。<br/><br/>3. **产业祛魅与长期价值**：随着产业对大模型的认知逐渐理性化，市场对于这类技术的期待和投资热情可能会有所降温。但长期来看，大模型作为人工智能的重要组成部分，其价值和潜力依然值得期待。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Bilingual Text-dependent Speaker Verification with Pre-trained Models for TdSV Challenge 2024](https://arxiv.org/abs/2411.10828) | 1. 提交了参加伊朗分部2024年文本依赖的说话人验证挑战(TdSV)的投稿。<br/><br/>2. 开发了两个独立的子系统，基于预训练模型：一个用于短语验证，通过词类分类器排除错误短语；另一个用于说话人验证，使用预训练ResNet293进行领域适应提取说话人特征。<br/><br/>3. 评估了Whisper-PMFA，一种预训练的ASR模型，经过适配用于说话人验证，并发现尽管它优于随机初始化的ResNets，但它在性能上仍落后于预训练ResNets，强调了大规模预训练的重要性。<br/><br/>4. 结果表明，在不联合建模说话者和文本的情况下，实现TdSV上的竞争力是可能的。他们最好的系统在评估子集上实现了MinDCF为0.0358，并赢得了挑战。 |
| [Explainable DNN-based Beamformer with Postfilter](https://arxiv.org/abs/2411.10854) | 1. 提出了一种基于深度神经网络（DNN）的可解释性多通道信号处理束形成器，结合后滤器（ExNet-BF+PF）。<br/><br/>2. 该方法将U-Net网络结构与束形成器结构相结合，以解决多通道信号处理问题。<br/><br/>3. 研究涉及两阶段处理流程：第一阶段应用时间不变权重构建多通道空间滤波器（即束形成器）；第二阶段在束形成器输出上应用时间变化的单通道后滤器。<br/><br/>4. 为了进一步改善语音增强，研究中引入了注意力机制，灵感来源于其在嘈杂和回声环境中的成功应用。<br/><br/>5. 实验结果表明，这种方法不仅训练简单，而且性能优越，无需对说话者活动有预先知识。这填补了现有文献中关于网络性能空间分析的空白。 |
| [Uncovering the role of semantic and acoustic cues in normal and dichotic listening](https://arxiv.org/abs/2411.11308) | 1. 该研究提出了一种理解复杂语音感知任务中声学和语义线索编码的框架。<br/><br/>2. 使用匹配-不匹配（MM）分类任务作为分析工具，研究者观察到：<br/><br/>   a) 基于词边界，语音感知是片段化的。<br/>   <br/>   b) 在自然听力条件下，声学和语义线索提供了相似的MM任务性能。<br/>   <br/>   c) 在双耳分听任务中，语义线索显著优于声学线索在MM分类上。<br/><br/>3. 研究还提供了右耳优势在双耳分听任务中的证据。 |
| [An Investigation of Reprogramming for Cross-Language Adaptation in Speaker Verification Systems](https://arxiv.org/abs/2411.11353) | 1. 研究了语言交叉适应中，对抗性重编程（Adversarial Reprogramming, AR）对模型性能的影响。<br/><br/>2. 探讨了重编程中填充学习参数的数量与模型性能之间的关系。进行了大规模的实验，使用不同规模的SV模型和数据集。<br/><br/>3. 结果表明，AR重编程能够一致地提高跨语言SV系统的性能，但改进的程度在使用更大填充长度时会饱和甚至下降。<br/><br/>4. 研究发现，模型原始能力（而非填充参数的数量）是决定性能的主要因素。更大的规模SV模型具有更高的上限性能，并能承受更长的填充而不降低性能。 |
| [A Bandpass Twin-T Active Filter Used in the Buchla 200 Electric Music Box Synthesizer](https://arxiv.org/abs/2411.11358) | 1. 分析了一种罕见的主动带通滤波器，它被用于Buchla Model 295的10通道组合滤波器模块中。<br/><br/>2. 滤波器的设计独特，是经典双T配置元素的一种非典型排列方式。到目前为止，这种设计在文献中尚未得到专门探讨。<br/><br/>3. 提供了一个具体应用的例子，即该滤波器如何在Model 295这个合成器模块中发挥作用。 |
| [BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization](https://arxiv.org/abs/2411.10879) | 1. 论文关注于识别孟加拉国方言并将其转换为标准的孟加拉语演讲。<br/><br/>2. 研究领域涉及方言语言，这些是特定地理位置使用的语言变体，通过其语音、发音和词汇来识别。<br/><br/>3. 文章提出了一种端到端的管道，用于将方言的诺亚利语（Noakhali dialect）转换为标准孟加拉语。<br/><br/>4. 实验部分展示了对Whisper ASR模型进行微调可以达到0.8%的词错率和1.5%的字错率，以及BanglaT5模型在方言到标准文本翻译上的41.6% BLEU分数。 |
| [Inter-linguistic Phonetic Composition (IPC): A Theoretical and Computational Approach to Enhance Second Language Pronunciation](https://arxiv.org/abs/2411.10927) | 1. 描述了第二语言学习者在学习过程中，常常无意识地用母语的相似音替换陌生的第二语言音素的现象。<br/><br/>2. 提出问题：这种音素替代会导致第二语言标准语音模式的偏离，对学习者的准确发音造成挑战。<br/><br/>3. 创新方法：提出一种名为“Inter-linguistic Phonetic Composition”（IPC）的新计算方法。IPC旨在通过复合声的生成来减少错误的音素转移，即重建第二语言音素为由多个母语音素组成的复合声音。<br/><br/>4. 实验验证：通过与两个自动语音识别模型的测试对比，证明当第二语言使用者发出IPC生成的复合声时，目标第二语言音素的识别率比受原始音素转移模式影响的发音提高了20%。这表明IPC方法能够快速帮助学习者掌握复合声的发音。 |
| [Pitch-and-Spectrum-Aware Singing Quality Assessment with Bias Correction and Model Fusion](https://arxiv.org/abs/2411.11123) | 1. 该论文参与了VoiceMOS Challenge 2024的第二赛道，目标是预测歌唱样本的平均意见分数（MOS）。<br/><br/>2. 提交的解决方案在所有参赛团队中获得第一名，排除官方基线。<br/><br/>3. 在本篇论文中，作者进一步改进了他们的提交，并提出了一个新颖的名为PS- SQA（基于自监督学习的MOS预测器的音质评估方法）的歌唱质量评估方法。<br/><br/>4. PS- SQA设计基础是SSL MOS预测器，它结合了歌唱的音高和频谱信息。这些信息通过使用音高直方图和非量化神经编码器提取而来。<br/><br/>5. 该方法还引入了一种偏差校正策略，以应对由于低资源训练样本导致的预测偏见问题。<br/><br/>6. 此外，PS- SQA采用了模型融合技术来进一步提高预测准确性。<br/><br/>7. 实验结果证明，提出的PS- SQA显著优于所有竞争对手系统，在所有系统级指标上都表现出色，验证了其强大的音质评估能力。 |
| [The Sound of Water: Inferring Physical Properties from Pouring Liquids](https://arxiv.org/abs/2411.11222) | 1. 理论上证明，液体倒入容器的物理属性（如液位、容器形状和尺寸等）可以从基本频率（音高）中推断出来。<br/><br/>2. 实训模型训练：设计并使用模拟数据和包含视觉信息的物理启发式目标来训练一个音高检测模型。这意味着通过监督学习，模型能够从模拟液体倒入的声音中提取音高特征。<br/><br/>3. 新大型真实视频数据库：引入一个新的大型现实液体倒入视频库，用于系统性研究液体倒入的多感官感知问题。<br/><br/>4. 模型在真实数据上的应用验证：展示训练好的音高检测模型能够在真实液体倒入的视频上准确推断出物理属性。<br/><br/>5. 强泛化能力验证：证明模型不仅对特定容器形状有良好适应，还能扩展到其他数据集和实际YouTube视频中。 |
| [SAMOS: A Neural MOS Prediction Model Leveraging Semantic Representations and Acoustic Features](https://arxiv.org/abs/2411.11232) | 1. 提出SAMOS，一个基于语义和声学信息的MOS预测模型。<br/>2. 利用预训练的wav2vec2提取语义特征，使用预训练的双向变频器（BiVocoder）的特征提取器获取声学特征。<br/>3. SAMOS模型包括多任务头部和聚合层，用于从这些特征中获得最终的MOS评分。<br/>4. 实验结果表明，SAMOS在BVCC数据集上超越了当前最先进的MOS预测模型，并且在BC2019数据集上的性能相当。 |
| [ESTVocoder: An Excitation-Spectral-Transformed Neural Vocoder Conditioned on Mel Spectrogram](https://arxiv.org/abs/2411.11258) | 1. 提出ESTVocoder，一种基于源滤器理论的新型神经声码器。<br/><br/>2. ESTVocoder通过神经滤波器将激发信号的幅度和相位谱转换为相应的语音幅度和相位谱。<br/><br/>3. 该方法利用了ConvNeXt v2块作为滤波器的后端，以提供更好的频率响应。<br/><br/>4. 最终，通过短时Fourier变换（ISTFT）的逆运算重建出语音波形。<br/><br/>5. ESTVocoder的设计考虑到了激发信号与期望语音之间的关系，旨在减少建模难度并提高合成语音质量。 |
| [Study of the Performance of CEEMDAN in Underdetermined Speech Separation](https://arxiv.org/abs/2411.11312) | 1. 提出对CEEMDAN算法在音频源分离中效果的研究，以了解其工作极限。<br/><br/>2. 结论指出，要使用CEEMDAN成功分离混合信号中的声音，需要满足两个条件：一是频率特征，二是幅度特性。<br/><br/>3. 研究还关注了CEEMDAN对噪声与语音分离、以及不同个体间的语音分离的效果。<br/><br/>4. 实验环境选择Matlab，并利用Noizeus数据库进行模拟。 |
| [Using voice analysis as an early indicator of risk for depression in young adults](https://arxiv.org/abs/2411.11541) | 1. 该研究探讨了语音分析作为早期预警信号的可能性，用于预测年轻人情绪障碍的发展。<br/><br/>2. 研究部分属于一个大型跨学科欧洲研究项目（ECoWeB），该项目旨在通过网络预防项目来降低年轻成年人抑郁症的风险。<br/><br/>3. 研究者收集了大量的参与者在特定一天表达情绪时的语音特征。他们发现了一些显著的声学差异，特别是在声音频谱中的能量分布上。<br/><br/>4. 这些结果鼓励进一步的研究努力，开发出非侵入性的、正常说话声音中的潜在风险指标。<br/><br/>5. 对于年轻人来说尤其重要，因为他们不太可能表现出抑郁症的标准风险因素，如负面的生活经历。 |
| [Do Captioning Metrics Reflect Music Semantic Alignment?](https://arxiv.org/abs/2411.11692) | 1. 提出音乐captioning作为新兴任务的观点。<br/>2. 强调当前音乐captioning评估依赖于传统语言评价指标，如BLEU、METEOR和ROUGE。<br/>3. 描述这些指标在音乐captioning中可能存在的问题，例如对语法变化的敏感性不足。<br/>4. 提供实例证明传统指标与人类判断的相关性不高。<br/>5. 目标是强调音乐captioning评估方法需要重新审视，并提出更符合任务特性的评价标准。 |
| [To what extent can ASV systems naturally defend against spoofing attacks?](https://arxiv.org/abs/2406.05339) | 1. 该研究探讨了自动演讲验证（ASV）系统是否能通过零样本能力轻松获取对语音冒充攻击的鲁棒性。<br/><br/>2. 研究者系统地探索了多种类型的ASV系统和冒充攻击，包括传统技术和前沿技术。<br/><br/>3. 通过在八个不同的ASV系统和二十九个不同类型的冒充攻击系统上进行详尽分析，研究者证明了ASV系统的进化内在包含了对抗语音冒充攻击的防御机制。<br/><br/>4. 然而，研究也指出，尽管ASV系统在应对冒充攻击方面有所进步，但冒充技术的发展速度更快，这需要进一步的研究来开发更鲁棒的ASV方法。 |
| [Self-supervised Multimodal Speech Representations for the Assessment of Schizophrenia Symptoms](https://arxiv.org/abs/2409.09733) | 1. 提出了一种用于识别和预测精神分裂症症状严重程度的评估系统。<br/><br/>2. 开发了基于Vector Quantized Variational Auto-Encoder (VQ-VAE)的多模态学习模型，用于从TVs和FAUs提取语音特征。<br/><br/>3. 这个框架采用了多任务学习(MTL)，将语音特征用于下游预测模型，以获得类别标签和整体严重程度评分。<br/><br/>4. 该系统在多种评估指标下（如加权F1分数、AUC-ROC得分和加权准确性）超越了先前的工作，证明其在精神分裂症症状分类任务上的有效性。 |
| [DARNet: Dual Attention Refinement Network with Spatiotemporal Construction for Auditory Attention Detection](https://arxiv.org/abs/2410.11181) | 1. 提出了一种名为DARNet的双注意力精炼网络，用于音频注意力检测(AAD)。<br/><br/>2. DARNet设计了时空构造模块，旨在通过捕捉EEG信号的空间分布特性，构建更具有表达力的时间-空间特征表示。<br/><br/>3. 网络中还包含双注意力精炼模块，目的是提取不同层次的EEG时间序列模式，并增强模型捕获长距离潜在依赖的能力。<br/><br/>4. 最后是特征融合与分类器模块，它负责整合不同层次的特征和依赖关系，并输出最终的分类结果。<br/><br/>5. 实验结果显示，DARNet相对于最先进的模型，在DTU数据集上实现了平均分类准确率提升5.9%、4.6%和3.9%（分别对应0.1s、1s和2s的时间窗口）。<br/><br/>6. 除了优秀的分类性能外，DARNet还显著减少了所需参数的数量。与最先进的模型相比，DARNet的参数数量减少了91%。代码链接：https://github.com/... |
| [Speech-Based Estimation of Schizophrenia Severity Using Feature Fusion](https://arxiv.org/abs/2411.06033) | 1. 开发了一种深度学习框架，用于通过语音估计精神分裂症严重评分。<br/><br/>2. 提出了一种基于自编码器的自我监督表示学习框架，用于从语音中提取紧凑的 articulatory embeddings。<br/><br/>3. 利用特征融合方法，将articulatory特征与不同预训练音频模型提取的多种自我监督语音特征相结合。<br/><br/>4. 通过对比，展示了该研究中基于语音的融合模型（带Multi-Head Attention）在精神分裂症严重评分估计上相对于先前结合了语音和视频输入的模型有显著的降低MAE和RMSE。 |
| [Periodicity Pitch Detection in Complex Harmonies on EEG Timeline Data](https://arxiv.org/abs/2002.04990) | 1. 研究声学刺激，如音乐和谐，如何在人耳和大脑的听觉处理流中以非线性方式转换。<br/><br/>2. 使用频率跟踪响应(FFR)来分析这种转换过程中的频率谱变化。这是通过EEG（脑电图）数据获取的。<br/><br/>3. 对合成的古典钢琴三和弦以及单音进行研究，这些刺激具有300ms的刺激时间和100ms的间隔时间。<br/><br/>4. 通过对响应 EEG 的 FFT 分析，发现之前计算出的±3Hz的周期性频率在一定程度上准确出现。然而，这里存在抖动问题。<br/><br/>5. 值得注意的是，这些寻求的周期性频率实际上并不存在于刺激的频率谱中。 |
| [Audio Deepfake Attribution: An Initial Dataset and Investigation](https://arxiv.org/abs/2208.10489) | 1. 该论文设计了首个针对音频生成工具归属（Attribution of Audio Generation Tools）的深度伪造音频数据集，名为Audio Deepfake Attribution (ADA)。<br/><br/>2. 论文进行了全面的系统指纹研究，以解决在现实世界中对不断涌现未知音频生成工具进行归属识别的挑战。<br/><br/>3. 提出了Class-Representation Multi-Center Learning (CRML)方法，用于开放集音频深度伪造归属（Open-set Audio Deepfake Attribution, OSADA）。<br/><br/>4. 实验结果证明了CRML方法有效应对了现实世界中开放集风险的音频深度伪造归属问题。 |
