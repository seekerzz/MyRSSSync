# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [Grasscutters/Grasscutter](https://github.com/Grasscutters/Grasscutter) | Grasscutter是一个项目，目标是提供一个基于Java的游戏开发环境。它使用Gradle来管理依赖项和构建过程。<br/><br/>要开始使用Grasscutter，首先需要满足一些系统要求，包括安装Java Development Kit 17或更高版本的Java。<br/><br/>然后通过克隆Git仓库并进入项目目录来初始化项目。接着执行`gradlew jar`命令来编译生成jar文件。<br/><br/>如果想要手动生成手册，可以使用Gradle的`generateHandbook`任务，或者使用NPM（Node Package Manager）进行手册的构建和安装。<br/><br/>在遇到问题时，建议加入Grasscutter项目的Discord服务器，在支持频道寻求帮助。 |
| [EbookFoundation/free-programming-books](https://github.com/EbookFoundation/free-programming-books) | 这个页面是关于编程学习平台的介绍。它提供了免费编程书籍、编程教程、在线代码编辑器等服务，用户可以在浏览器中直接编写和运行代码。<br/><br/>此外，页面还提到了翻译的重要性，鼓励有兴趣的人通过贡献翻译来帮助扩展语言覆盖范围。<br/><br/>最后，页面明确指出每个文件都遵循CC BY License许可协议。 |
| [lyswhut/lx-music-desktop](https://github.com/lyswhut/lx-music-desktop) | 洛雪音乐桌面版项目协议，主要概述了数据来源、版权保护、非商业性质以及接受协议等内容。使用者需在24小时内清除产生的版权数据，并对可能的违法违规行为负责。同时，本项目不接受任何形式的商业合作和捐赠。如有任何疑问，建议邮件联系官方邮箱。 |
| [godotengine/godot](https://github.com/godotengine/godot) | Godot Engine 是一个跨平台的2D和3D游戏引擎。它提供了一个功能丰富的、统一接口的游戏开发环境，支持用户从单一源创建、编辑和导出游戏。<br/><br/>引擎的核心特性包括：免费且开源（MIT许可证），具有高度模块化的设计，丰富的内置工具和脚本语言支持，以及广泛的社区支持和资源分享。<br/><br/>除了官方文档和学习资源外，Godot Engine 还有一个活跃的社区，用户可以在那里提问、交流经验和分享代码。 |
| [donnemartin/system-design-primer](https://github.com/donnemartin/system-design-primer) | 这个仓库包含了多个系统设计相关的博客文章和资源。作者Donne Martin提供了代码和资料，许可为Creative Commons Attribution 4.0 International License（CC BY 4.0）。<br/><br/>如果你对系统设计或者相关技术有兴趣，可以通过阅读这些博客来学习。同时，也可以通过GitHub页面上的联系方式与作者交流。 |
| [albertobsd/keyhunt](https://github.com/albertobsd/keyhunt) | 这段文字是关于一个名为"keyhunt"的程序，它是一个用于查找特定类型密钥（如ICELand或特定用户地址）的工具。这个程序需要用户的Windows版本，并且不能依赖任何外部库。<br/><br/>此外，开发者还提到需要在测试网络（Testnet）上进行一些测试，如果有人愿意提供测试网上的捐款，那么这些捐款将被用来优化Windows本地版本，或者购买一台价格适中、配备良好GPU的桌面电脑来启动GPU版本。 |
| [microsoft/graphrag](https://github.com/microsoft/graphrag) | 这段文本是关于GraphRAG项目的一个介绍，主要讲述了该项目的贡献指南、AI透明度FAQ以及对微软商标和品牌指导原则的遵守声明。同时提到了隐私政策链接，用户可以查看微软的隐私声明。 |
| [disposable-email-domains/disposable-email-domains](https://github.com/disposable-email-domains/disposable-email-domains) | 这段代码是一个用于检查电子邮件地址是否为临时或 disposable 的Java程序。它首先加载一个配置文件（如"disposable_email_blocklist.conf"）中列出的可识别的 disposable 电子邮件域名。<br/><br/>然后，`isDisposable`方法接受一个电子邮件地址，如果该地址包含在配置文件中的任何 disposable 域名，就返回 `true`。否则返回 `false`。<br/><br/>这段代码可以用于过滤垃圾邮件或防止滥用临时邮箱的情况。 |
| [public-apis/public-apis](https://github.com/public-apis/public-apis) | 这段文字是关于一个包含多个天气API的表格。每个API都有自己的名称、用途（如提供天气预报）、是否需要API密钥（code）以及密钥是否可用的信息。<br/><br/>最后，还提到了一个名为"License"的部分，这是关于代码库的许可证信息，引用了MIT许可（c）2022 public-apis。 |
| [practical-tutorials/project-based-learning](https://github.com/practical-tutorials/project-based-learning) | 本文主要介绍了几个编程语言的学习资源，包括但不限于：<br/><br/>1. **Rust**:<br/>   - 学习 Rust的博客文章：`Create a simulation of evolution using neural network and genetic algorithm, and compile the application to WebAssembly`<br/>   <br/>2. **Scala**：<br/>   - 使用Hacking with Swift学习Scala的项目链接：`https://github.com/nicklockwood/RetroRampage` <br/>   <br/>3. **Swift**：<br/>   - 通过Udemy.com平台获取Swift语言的学习资源：`https://udemy.com/topic/swift-programming-language/` <br/><br/>4. **额外资源**：<br/>   - 提供了多个编程学习社区的链接，如CodeCrafters.io等。<br/><br/>这些资源可以帮助初学者快速入门并深入理解所选编程语言。 |
| [shadcn-ui/ui](https://github.com/shadcn-ui/ui) | 这是一个用于创建美观且可定制UI组件的库。它提供了易于复制和粘贴到应用中的组件，这些组件设计上注重无障碍性。<br/><br/>这个开源项目是免费的，并且开放源代码。使用者可以使用此库来构建自己的组件库，进行个性化开发。<br/><br/>总之，shadcn/ui是一个提供易用、可定制UI组件的开源项目，适用于自由开发者和团队构建自定义组件库。 |
| [ente-io/ente](https://github.com/ente-io/ente) | 这段内容是关于Ente项目的一个贡献指南，包括如何支持、寻求帮助的途径以及社区参与的方式。同时提到了安全问题，鼓励发现潜在漏洞的人通过私密方式报告，以确保项目的安全。 |
| [GaiaNet-AI/gaianet-node](https://github.com/GaiaNet-AI/gaianet-node) | 这段文本是关于使用Gaianet命令行工具管理本地节点的指南。它详细解释了如何启动、停止和更新节点配置，如聊天模型URL、上下文大小等。此外，还提到了一些选项，如系统提示、反向提示等，以及如何更新Qdrant的设置。 |
| [alex-shpak/hugo-book](https://github.com/alex-shpak/hugo-book) | 这段话是关于一个Hugo主题的版本控制、配置选项以及贡献者的指南。主要强调了主题遵循简单增量版本，鼓励用户根据需要定制配置，并欢迎开发者提出缺失功能或个性化需求的问题。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [8点1氪｜中国移动回应资费套餐“升级容易降级难”；汇福粮油回应“卸完煤油直接装食用油”；微软要求中国员工禁用安卓手机](https://www.36kr.com/p/2854272668387973) | 以下是关于“上海硫元”完成数千万元天使轮融资和“价格战轮番上演，企业如何破局增长?”话题的简要摘要：<br/><br/>1. **“上海硫元”融资事件**：<br/>   - 上海硫元科技公司成功完成数千万元人民币天使轮融资。<br/>   - 投资方包括中科创星领投、格致资本跟投。<br/><br/>2. **价格战对企业的影响及破局策略**：<br/>   - 话题聚焦于企业如何应对价格战的挑战，寻找增长新动力。<br/>   - 案例提及汉王友基CE0李远志等专业人士的观点，可能包括对价格战影响分析、以及企业如何利用市场变化进行战略调整的建议。<br/><br/>请注意，这些摘要信息基于提供的新闻报道和摘要内容，并未包含完整的对话或详细的专业见解。 |
| [你连吵架都不会，还混什么职场](https://www.36kr.com/p/2853163800202121) | 这段信息看起来像是某篇文章的摘录，内容涉及如何正确地进行职场上的争吵，即所谓的"正确吵架"。文章强调了在底线被触及时要有勇气表达观点，并且指出这种态度能带来更多的尊重。<br/><br/>如果需要更具体的摘要，可能需要提供完整的信息或者对原文进行深入理解后才能给出准确的摘要。 |
| [“我在小红书拆卡，一周涨粉14万”](https://www.36kr.com/p/2853221253712521) | 这段内容是关于直播+拆卡模式的商业分析。主要提到：<br/><br/>1. 商业视角下，这种模式精准捕捉需求，高毛利和高复购表明其盈利能力。<br/><br/>2. 拆卡赛道的优势包括市场规模持续增长、多元化的赛道选择等。<br/><br/>3. 提到了一些在小红书上拥有大量粉丝的拆卡博主，如@霸气甜妹爱拆卡 等，并指出今年新加入的选手。<br/><br/>4. 最后，这段内容是通过微信公众号“运营研究社”（ID：U_quan）编辑部发布的，注明了授权发布的信息。 |
| [36氪独家｜抖音有计划降低达人直播比重，并持续扩大货架电商](https://www.36kr.com/p/2846324410403462) | 1. 抖音正在降低达播流量分配比例，转而倾斜给短视频、品牌店播和商城。<br/><br/>2. 今年618期间，抖音超级头部主播带货表现不佳，显示出平台对达播依赖的减弱。<br/><br/>3. 抖音电商未来规划中，内容和直播将主要服务于种草和成交，而商城则作为复购场景存在。<br/><br/>4. 魏雯雯宣布的重点发力方向是商城和搜索，新场域占比目标在50%以上。 |
| [国产芯片大战更焦灼了丨焦点分析](https://www.36kr.com/p/2851850589702787) | 这段文字是关于推理芯片市场爆发的讨论。内容包括国产推理卡的快速发展，以及它们如何挑战英伟达等国际大厂的地位。<br/><br/>文中提到，目前国产推理芯片厂商正在积极研发万卡规模的智算集群解决方案，以满足万亿参数大模型的需求。同时，这些厂商也在关注硬件投入与计算效率的关系，以及如何保证大模型训练过程中的稳定性和长期性。<br/><br/>总的来说，这段文字反映了国产推理芯片市场在技术、商业等多个层面的快速发展和挑战。 |
| [手机智能体，干掉App？](https://www.36kr.com/p/2845900058413956) | 本文讨论了手机智能体如何通过用户行为数据调用服务生态的问题。文章引用了一些AI手机领域的专家观点，提出了可能存在的问题，如强大的头部效应可能导致部分应用边缘化。<br/><br/>此外，文中提到手机企业需要考虑如何形成新的生态秩序，以适应与开发者和应用之间的关系变化。这个过程可能比超级入口的建设更为缓慢。<br/><br/>总的来说，本文围绕手机智能体调用服务生态的问题展开讨论，并提出了未来可能面临的一些挑战。 |
| [价格「大跳水」，今年的榴莲怎么了？｜氪金·大消费](https://www.36kr.com/p/2852989248113544) | 中国市场上鲜榴莲进口量持续增长，主要来自泰国。尽管越南、马来西亚等东南亚国家也开始向中国出口榴莲，但短期内对国内市场影响有限。<br/><br/>预计未来3至5年，东南亚榴莲的产量可能会翻一番。如果进口量能按预期增长，零售价格有可能下降到20元以下水平，这将为消费者带来更实惠的选择。 |
| [上海或率先“油电平权”，但燃油车的命运已天注定](https://www.36kr.com/p/2850643435870599) | 这段内容是关于新能源汽车市场的发展分析和预测。主要提到以下几个要点：<br/><br/>1. 现阶段插混车销量高，成为消费者购车首选，且对燃油车构成一定冲击。<br/><br/>2. 随着高能量密度电池成本下降，长续航纯电动车价格有望下探，纯电动车市场将逐渐回归主导地位。<br/><br/>3. 未来新能源汽车市场将呈现三足鼎立的局面，包括燃油车、插混和纯电车等类型。<br/><br/>4. 文章最后提到技术变革可能带来全新的动力模式，暗示着新能源领域还有更多可能性等待发掘。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Codec-ASR: Training Performant Automatic Speech Recognition Systems with Discrete Speech Representations](https://arxiv.org/abs/2407.03495) | 1. 提供了对使用离散代码构建自动语音识别（ASR）系统的全面分析。<br/><br/>2. 研究了不同编码训练方法，包括量化策略和时域特征与频谱特征的编码方式。<br/><br/>3. 探索了针对提高ASR性能、训练效率以及抗噪声能力的训练技术。<br/><br/>4. 根据研究结果，提出了一种超越传统编码的ASR管道，即使在相似比特率下也表现出更好的性能。<br/><br/>5. 该管道的性能甚至超过了使用强大自我监督模型的最先进的结果，在143种语言的ML-SUPERB基准上取得了优异表现。 |
| [Learning Video Temporal Dynamics with Cross-Modal Attention for Robust Audio-Visual Speech Recognition](https://arxiv.org/abs/2407.03563) | 1. 该研究关注音频-视觉演讲识别（AVSR），目标是使用音频和视频两种模态来转录人类语音。<br/><br/>2. 在有噪音干扰的音频环境下，视频信息的重要性显著提升。然而，现有的工作主要集中在音频特征增强上，忽视了视频特征的作用。<br/><br/>3. 研究中，作者通过学习视频数据中的三种时间动态特性：上下文顺序、播放方向和视频帧速度，来强化视频特征。<br/><br/>4. 交叉模态注意力模块被引入，以丰富视频特征并结合音频信息，从而更好地处理演讲的变异性。<br/><br/>5. 在基于这些方法的基础上，研究者在LRS2和LRS3两个AVSR基准上实现了噪音主导环境下的最先进的性能。<br/><br/>6. 研究结果表明，特别是在嘈杂声和语音噪声环境下，该方法能够有效地区分视频模态中应被识别的语音信号，而不仅仅是唇动作。 |
| [High Fidelity Text-Guided Music Generation and Editing via Single-Stage Flow Matching](https://arxiv.org/abs/2407.03648) | 1. 提出了一种简单且高效的文本可控高保真音乐生成和编辑模型。<br/><br/>2. 该模型基于一种扩散Transformer架构，经过训练以匹配流的目标。<br/><br/>3. 模型能够生成和编辑多样化的高质量立体样本，包括不同长度的变量时长样本。<br/><br/>4. 通过简单的文本描述进行操作，提供了便捷的音乐编辑工具。<br/><br/>5. 还探讨了一种新的正则化潜入逆转换方法，用于零样本测试时的文本引导编辑。<br/><br/>6. 实验证明了这种方法在多种音乐编辑提示下优于传统的DDIM逆转换方法。 |
| [Mixstyle based Domain Generalization for Sound Event Detection with Heterogeneous Training Data](https://arxiv.org/abs/2407.03654) | 1. 提出针对声音事件检测（SED）的领域泛化（DG）方法，以增强模型在真实世界环境下的适应性。<br/><br/>2. 利用mean-teacher框架，并结合DG策略，整合来自不同域的异构训练数据，同时保持SED模型性能跨域一致。<br/><br/>3. 技术实现上，首先通过mixstyle对频率维度进行转换，适应不同域的mel-谱图。其次，采用自适应残差归一化（Adaptive Residual Normalization, ARN）方法，跨域泛化特征，通过实例归一化在频域应用。<br/><br/>4. 最后，对检测结果进行后处理，使用DESED数据集上的声事件边界框方法。<br/><br/>5. 通过DCASE 2024 Challenge Task 4数据集的实验评估，结果显示所提出的DG-基于的方法能够显著提高多声源SED得分（PSDS）以及MAESTRO数据集上的宏观平均pAUC。 |
| [WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection System](https://arxiv.org/abs/2407.03656) | 1. 提出新的大型语言模型（LLM）驱动数据集，名为"野生家庭环境声音事件检测（WildDESED）"。<br/><br/>2. 作为对原始DESED数据集的扩展，这个新数据集旨在反映家庭环境中多样化的声学变化和复杂的噪声。<br/><br/>3. 利用LLMs生成了八个不同的家庭场景，这些场景基于DESED数据集的目标声音类别。<br/><br/>4. 将这些场景与精心挑选的混合噪声相结合，这些噪声来自AudioSet，并确保没有与目标声音重叠。<br/><br/>5. 使用广泛流行的卷积神经递归网络（CNN-RNN）来研究WildDESED数据集，这表明其具有挑战性。<br/><br/>6. 应用 curriculum learning，通过逐渐增加噪声的复杂性，来增强模型在各种噪声水平下的泛化能力。<br/><br/>7. 通过这种方法的应用，结果显示出在嘈杂环境中的改进，验证了这种方法对WildDESED数据集的有效性，促进了噪音鲁棒的声音事件检测（SED）研究的进步。 |
| [UCIL: An Unsupervised Class Incremental Learning Approach for Sound Event Detection](https://arxiv.org/abs/2407.03657) | 1. 探索了声事件检测（SED）领域中的类增量学习（CIL），旨在提升模型在现实世界场景下的适应性。<br/><br/>2. 基于计算机视觉领域的成功经验，设计了一种针对SED任务的定制方法，以解决音频环境多样性和复杂性的独特挑战。<br/><br/>3. 提出了一种独立的无监督学习框架，结合蒸馏损失函数来整合新声类信息，同时保持SED模型在增量任务中的一致性。<br/><br/>4. 进一步优化了这个框架，通过样本选择策略处理未标注数据，并引入平衡的示例更新机制，确保声音表示多样化且具有代表性。 |
| [Configurable DOA Estimation using Incremental Learning](https://arxiv.org/abs/2407.03661) | 1. 介绍了一种名为DOA-PNN的渐进神经网络模型，用于方向到达（DOA）估计。<br/><br/>2. 研究针对动态声学环境中的挑战，即由于 catastrophic forgetting导致的适应性问题。<br/><br/>3. 比较了传统方法如GCC、MUSIC、SRP-PHAT在静态环境下的有效性，但它们在嘈杂、反射性强的环境中表现不佳。<br/><br/>4. 提出DOA-PNN模型克服这些限制，通过任务增量学习和持续学习，允许在不同声学场景中进行适应，并减少先前知识的遗忘。<br/><br/>5. 研究了DOA-PPN在模拟数据下的性能，展示了其在微距麦克风设置变化时保持性能的能力，提出了一个有效解决DOA估计问题的方案。 |
| [Optimizing a-DCF for Spoofing-Robust Speaker Verification](https://arxiv.org/abs/2407.04034) | 1. 提出了一种新型的防冒充ASV后端分类器，优化目标直接针对最近引入的、架构无关的检测成本函数(a-DCF)。<br/><br/>2. 结合了a-DCF和二元交叉熵(BCE)损失来优化网络权重，通过一种新的直观的检测阈值优化技术实现这一结合。<br/><br/>3. 在ASVspoof2019数据库上进行实验，结果显示该模型在与仅使用BCE优化的基线相比时，性能有了显著提升，实现了13%的相对改进。<br/><br/>这些初步的积极结果表明，通过调整ASV系统，可以找到用户便利性和防冒充安全之间适当的平衡。 |
| [DASS: Distilled Audio State Space Models Are Stronger and More Duration-Scalable Learners](https://arxiv.org/abs/2407.04082) | 1) 提出应用知识蒸馏训练音频空间模型的方法，生成名为"Knowledge Distilled Audio State-Space Models" (DASS)的模型。这是首次在AudioSet上超越Transformer的SSM，并实现了47.6的mAP。<br/><br/>2) 设计了一个新的测试集"Audio Needle In A Haystack" (Audio NIAH)，用于评估模型在长音频输入上的性能。实验结果显示，尽管DASS是在10-秒音频片段上训练的，但它能够处理长达2.5小时的音频记录，而AST模型在这种情况下失败了。这证明SSMs在时间尺度扩展性方面确实优于Transformer模型。 |
| [Semi-supervised Learning for Code-Switching ASR with Large Language Model Filter](https://arxiv.org/abs/2407.04219) | 1. 提出利用未标注的单语言母语语音数据增强跨语言自动语音识别（CS-ASR）系统的观点。<br/><br/>2. 在半监督学习框架下，特别强调了当获取CS数据有限时，这种方法的有效性。<br/><br/>3. 创立了一种通用方法，将噪声学生训练（NST）应用于CS-ASR任务中。具体引入了LLM-Filter，它利用精心设计的提示模板来激活大型语言模型（LLMs）的纠正能力，用于单语言数据选择和伪标签优化。<br/><br/>4. 实验结果表明，这种方法不仅在CS任务上显著超越了监督学习和半监督学习的基线，而且在性能上也超过了全监督下Oracle的上限。<br/><br/>5. 进一步研究AESRC数据集中的口音影响，并证明当单语言数据包含相关语言特征时，这种方法能带来额外的好处。 |
| [Who Finds This Voice Attractive? A Large-Scale Experiment Using In-the-Wild Data](https://arxiv.org/abs/2407.04270) | 1. 介绍CocoNut-Humoresque，一个开源的大型语音可听性语料库。<br/><br/>2. 语料库包括演讲片段和每个听众对其可听性的评分。<br/><br/>3. 讨论了评估声音可听性的重要性，这对于设计对话或公告系统等语音系统的偏好声音至关重要。<br/><br/>4. 描述了构建语料库的过程，包括让885名听众对1800个不同说话人的演讲片段进行评分，并收集多说话人属性（如性别、年龄和最喜欢的YouTube视频）。<br/><br/>5. 提出初步数据分析以揭示声音可听性中可能存在的性别和年龄偏见。同时研究了语料库中的可听性分数与给定话语的两个声学特征（基频频率和x-vectors）之间的关系。 |
| [We Need Variations in Speech Synthesis: Sub-center Modelling for Speaker Embeddings](https://arxiv.org/abs/2407.04291) | 1. 提出了一种新的说话人嵌入网络，该网络在说话人分类训练中使用多个类中心，而不是传统的单个类中心。<br/><br/>2. 通过引入说话人嵌入中的变化，同时保持说话人识别性能，因为模型不需要将所有说话者讲话的样本都映射到同一个类中心。<br/><br/>3. 应用这种新的嵌入方法在语音转换任务中，并展示了这种方法能提供更自然、更丰富的语调合成语音。 |
| [Sound Field Estimation Using Deep Kernel Learning Regularized by the Wave Equation](https://arxiv.org/abs/2407.04417) | 1. 提出一种新的时空域核函数，用于高斯过程（GP）回归为基础的声场估计。<br/><br/>2. GP具有特性：声场是测量值线性函数，允许从分布式麦克风测量中高效地估计声场。<br/><br/>3. 为了确保分析的可处理性，大多数现有的声场估计核函数都是在频域中形式化的，对每个频率独立形成。<br/><br/>4. 提出解决时空域核函数分析不可行问题的方法：通过深度学习内核学习（Deep Kernel Learning,DKL）直接从数据中学习这些核函数。<br/><br/>5. 为了提高深度学习内核的泛化能力，提出使用波动方程进行正则化的方法。这展示了深度学习内核和波动方程正则化相结合的优势。 |
| [XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models](https://arxiv.org/abs/2407.04439) | 1. 提出XLSR-Transducer模型，将XLSR-53模型作为编码器用于转录器设置。<br/><br/>2. 在AMI数据集上进行实验，结果显示XLSR-Transducer相比 Whisper large- v2 模型在绝对WER方面提高了4%，而与自训练的Zipformer转录器相比，其性能提升了8%。<br/><br/>3. 探究不同注意力掩码模式对XLSR-53模型中Transformer层计算中的自我注意力的影响。验证了XLSR-Transducer在多种语言和低资源场景下的有效性。<br/><br/>4. 通过引入注意力沉淀物，将左上下文减少一半，但相对WER提高了12%。这表明模型在保持一定程度的性能的同时，能够适应更小的输入上下文。 |
| [From Audio Encoders to Piano Judges: Benchmarking Performance Understanding for Solo Piano](https://arxiv.org/abs/2407.04518) | 1. 本研究探讨了一种通过音频编码模型理解音乐表演的方法，特别关注于西方古典钢琴独奏音乐领域。<br/><br/>2. 研究者发现，在理解和解析音乐表现的难度上，与基于作曲层面属性的理解（如调性或类型）相比，存在一个知识空白。<br/><br/>3. 他们提出了三个关键任务：专家排名、难度估计和钢琴技巧检测，并创建了一个名为Pianism-Labeling Dataset (PLD) 的综合数据集来支持这些工作。<br/><br/>4. 研究者利用预训练的音频编码器，如Jukebox、Audio-MAE、MERT和DAC，展示了它们在解决下游任务上的多样性能力，以此探索特定领域内精细化微调是否能增强捕捉表演细节的能力。<br/><br/>5. 最终，他们使用训练好的模型对肖邦钢琴比赛数据进行了专家排名案例研究，这突显了准确评估顶级表现的挑战。 |
| [FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder](https://arxiv.org/abs/2407.04575) | 1. 采用新型的GAN为基础的 vocoder，名为FA-GAN，旨在减少明显的频谱artifact并提高音质。<br/><br/>2. 提出抗混叠双去卷积模块，用于抑制高频率组件中非理想上采样层引起的混叠 artifact。<br/><br/>3. 推出精细层次多分辨率实部和虚部损失，以帮助模型更好地捕捉相位信息，从而减轻模糊现象并丰富频谱细节的重建。<br/><br/>4. 实验结果表明，FA-GAN在音频质量提升、减少频谱artifact以及对未见过的说话者场景的适应性上优于比较方法。 |
| [Written Term Detection Improves Spoken Term Detection](https://arxiv.org/abs/2407.04601) | 1. 提出了一种多任务训练目标，该目标允许未配对的文本融入到端到端（E2E）关键词搜索系统中，而无需增加索引和搜索的复杂性。<br/><br/>2. 除了训练E2E KWS模型从口语文档中检索文本查询外，还联合训练它从被遮盖的书面文档中检索文本查询。<br/><br/>3. 实验结果表明，这种方法能够有效地利用未配对的文本进行关键词搜索，且在多种语言上都能显著提高搜索性能。分析进一步揭示了这些改进是因为所提出的策略提高了文档中与未配对文本相关词汇的表示质量。最后，展示了该方法可用于领域适应，在缺乏或不存在内域配对数据的情况下也能发挥作用。 |
| [Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models](https://arxiv.org/abs/2407.04641) | 1. 探索了推测性语音识别（SSR），这是一种赋予常规自动语音识别（ASR）推测能力的方法。<br/><br/>2. 提出了一种衡量SSR性能的指标，为评估SSR系统的有效性提供了标准。<br/><br/>3. 建议了一个模型，该模型通过结合基于RNN-Transducer的ASR系统和音频前缀语言模型（LM）来实现SSR。ASR系统负责实时转录音频，而LM则根据音频依赖性推测可能的完成句子。<br/><br/>4. 实验了多种ASR数据集，展示了他们上应用该方法的有效性和SSR作为一种减少ASR延迟的方法的可行性。 |
| [Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units](https://arxiv.org/abs/2407.04652) | 1. 提出一种使用无转录数据预训练端到端（E2E）关键词搜索（KWS）系统的方法。<br/><br/>2. 利用声学单元发现（AUD）技术，从无转录数据中获取离散的声学单位。<br/><br/>3. 训练模型学会定位这些声学单位序列在语音信号中。<br/><br/>4. 实验覆盖多种语言和AUD系统，结果显示预训练模型通过微调显著优于从零开始训练的模型。<br/><br/>5. 结果表明性能提升与AUD系统的质量相关。 |
| [Multitaper mel-spectrograms for keyword spotting](https://arxiv.org/abs/2407.04662) | 1. 该论文探讨了多带技术在关键词识别（KWS）任务中创造改进特征的方法。<br/><br/>2. 实验研究针对不同测试场景、窗口和参数、数据集以及常用于嵌入式KWS应用的神经网络进行了实施。<br/><br/>3. 结果证明了使用提议的改进特征的优势，这为KWS领域提供了新的特征优化思路。 |
| [Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition](https://arxiv.org/abs/2407.04675) | 1. 提出Seed-ASR，一个基于大型语言模型的语音识别模型。<br/>2. Seed-ASR是基于音频条件下的大型语言模型框架开发的，利用了大型语言模型的能力。<br/>3. 通过分阶段的大规模训练和在大型语言模型中激发语境意识能力的方式，使Seed-ASR在全面评估集上（包括多个领域、口音/方言和语言）上表现出显著优于端到端模型的进步。<br/>4. Seed-ASR还能够进一步部署以支持各种场景下的特定需求，无需额外的语言模型。与最近发布的大型语音识别模型相比，Seed-ASR在中文和英文公共测试集上的词错误率（或字符错误率）减少了10%-40%，进一步证明了其强大的性能。 |
| [PianoBART: Symbolic Piano Music Generation and Understanding with Large-Scale Pre-Training](https://arxiv.org/abs/2407.03361) | 1. 提出钢琴BART（PianoBART），一个预训练模型，使用BART进行象征性钢琴音乐生成和理解。<br/><br/>2. 设计了一种多级对象选择策略，用于不同钢琴BART的预训练任务中，以防止信息泄露或损失，并增强学习能力。<br/><br/>3. 在预训练阶段捕获的音乐语义，在音乐生成和理解任务中进行了微调。<br/><br/>4. 实验结果证明了PianoBART能够有效地学习音乐模式，并在生成高质量连贯片段和理解音乐方面表现出色。代码和补充材料可访问链接。 |
| [Advanced Framework for Animal Sound Classification With Features Optimization](https://arxiv.org/abs/2407.03440) | 1. 提出了一种适用于一般动物声音分类的自动化分类框架。<br/>2. 利用Mel频率 cepstral coefficients(MFCC)提取音频特征，并通过优化特征排列和减少特征来提高特征质量。<br/>3. 使用注意力-基于双向长短期记忆(Bi-LSTM))模型，利用优化后的特征进行深度语义特征提取，用于声音分类。<br/>4. 提供了一个包含海洋动物和鸟类的动物声音基准数据集。<br/>5. 通过在真实世界数据集上的大量实验，证明了该方法在精度、召回率和准确性方面明显优于基线方法，为动物声音分类技术的进步做出了贡献。 |
| [Prosody-Driven Privacy-Preserving Dementia Detection](https://arxiv.org/abs/2407.03470) | 1. 提出匿名化 speaker embeddings的研究，以解决隐私问题。<br/>2. 研究目标是保留痴呆症诊断的有用性，同时匿名化特征。<br/>3. 利用领域知识来分离与痴呆相关的声学特征，而无需依赖痴呆分类器。<br/>4. 实验结果表明，采用该方法可以显著提高在ADReSS数据集上保护说话者隐私的能力（F1-score下降到0.01%）。<br/>5. 与基于更受限的分类器系统的比较显示，这种方法在ADReSSo上的表现相当（F1-score变化不大，分别为0.01%和0.66%），并且不影响合成语音的自然性。 |
| [Towards Attention-based Contrastive Learning for Audio Spoof Detection](https://arxiv.org/abs/2407.03514) | 1. 提出使用Vision Transformer（ViT）进行音频Spoof检测任务的创新方法。<br/><br/>2. 设计并实施了一种基于注意力的对比学习框架（SSAST-CL），该框架利用交叉注意力辅助特征学习。<br/><br/>3. 实验结果表明，提出的SSAST-CL框架能够成功地分离真实和伪造类别，并有助于学习更好的分类器。<br/><br/>4. 在适当的数据增强策略下，基于SSAST-CL框架训练的模型在ASVSpoof 2021挑战中达到了竞争性能。 |
| [Continual Learning Optimizations for Auto-regressive Decoder of Multilingual ASR systems](https://arxiv.org/abs/2407.03645) | 1. 提出MASR（多语言自动语音识别）领域中针对连续学习（CL）优化的需要。<br/>2. 假设现有的CL方法在直接应用于MASR时效果不佳，这归因于MASR模型中自回归解码器的CL难度大。<br/>3. 针对这一问题，提出四个针对解码器的优化策略：解码层梯度手术、冻结未用词嵌入、抑制新添加词汇输出以及学习率重缩。<br/>4. 通过在Whisper（一种多语言语音识别工具）上进行10种未见过的语言适应实验，验证这些优化能够显著降低预训练语言的平均词错误率（AWER），从14.2%降至12.4%，而对新语言的AWER没有负面影响。 |
| [Multi-Convformer: Extending Conformer with Multiple Convolution Kernels](https://arxiv.org/abs/2407.03718) | 1. 提出Multi-Convformer模型，该模型在Conformer的卷积模块中使用多个不同尺寸的卷积核，并结合门控机制。<br/><br/>2. 这种设计有助于更精细地建模局部依赖关系，适应不同粒度的语境。<br/><br/>3. 通过实验对比，发现Multi-Convformer在性能上接近或超越现有的CgMLP和E-Branchformer等Conformer变体，同时具有更高的参数效率。 |
| [Improving Self-supervised Pre-training using Accent-Specific Codebooks](https://arxiv.org/abs/2407.03734) | 1. 提出一种针对口音自适应的自我监督学习技术。<br/>2. 创造性地引入一组可训练的口音特定代码本集到自我监督架构中。<br/>3. 这些可学习的代码本使得模型在预训练阶段能够捕获口音特有的信息，而在ASR微调过程中进一步优化。<br/>4. 在Mozilla Common Voice数据集上，该方法显著优于其他口音适应方法，无论是在已见过的还是未见过的英语口音中，其词错误率（WER）可降低高达9%。 |
| [Finetuning End-to-End Models for Estonian Conversational Spoken Language Translation](https://arxiv.org/abs/2407.03809) | 1. 该研究探讨了端到端模型在双向爱沙尼亚-英语和爱沙尼亚-俄语会话语音转文本翻译任务中的微调。<br/><br/>2. 爱沙尼亚的语音翻译数据有限，因此作者创建了额外的训练数据。这通过网络爬虫抓取和使用机器翻译合成来自语音识别数据集的数据来实现。<br/><br/>3. 他们评估了三个公开可用的端到端模型：Whisper、OWSM 3.1 和 SeamlessM4T。<br/><br/>4. 结果表明，使用合成数据进行微调可以显著提高翻译准确性，其中SeamlessM4T的表现与或超越了使用最新语音识别和机器翻译技术的串行语音翻译系统。 |
| [Unsupervised speech enhancement with spectral kurtosis and double deep priors](https://arxiv.org/abs/2407.03887) | 1. 提出了一种基于深度先验的无监督DNN语音增强方法。<br/>2. 利用两个DNN，一个生成清洁语音信号，另一个生成噪声，它们的组合输出接近嘈杂语音信号。<br/>3. 通过损失项基于谱峭度来分离语音信号，实现对噪声和清晰语音的分离。<br/>4. 该方法的关键优势在于它能够避免传统方法中可能存在的权衡问题和早期停止问题。<br/>5. 通过实验验证，提出的无监督DNN语音增强方法在白噪声和环境噪声条件下优于常规方法，并有效地缓解了早期停止问题。 |
| [On the Effectiveness of Acoustic BPE in Decoder-Only TTS](https://arxiv.org/abs/2407.03892) | 1. 该研究对使用自监督语义表示生成的语音令牌的解码型TTS模型进行了全面探讨。<br/><br/>2. 研究中，作者通过实验在LibriTTS数据集上验证了声学BPE能够均匀提高合成语音的可理解性和多样性。<br/><br/>3. 作者发现声学BPE在不同设置下表现出不同的特征，这表明它是一个灵活且有用的工具。<br/><br/>综上所述，这项研究为使用声学字节对编码的解码型TTS模型提供了深入的理解和有益的建议。 |
| [Serialized Output Training by Learned Dominance](https://arxiv.org/abs/2407.03966) | 1. 提出一种基于模型的序列化策略，通过在注意力编码器-解码器架构中加入一个辅助模块来实现。<br/><br/>2. 该辅助模块能够自主地识别决定输出序列顺序的关键因素，包括多说话者中的主导语音成分，如音量和性别等。<br/><br/>3. 实验在LibriSpeech和LibriMix数据库上进行，结果显示，这种方法显著优于基于PIT（Permutation Invariant Training）和FIFO（First-In-First-Out）规则的基线。<br/><br/>4. 进一步分析表明，序列化模块能够根据主导性分数对混合语音中的各个成分进行排序。 |
| [Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis](https://arxiv.org/abs/2407.04047) | 1. 探究使用无监督文本到语音合成（TTS）作为数据增强方法，以改善带有口音的语音识别。<br/><br/>2. 训练TTS系统时，采用少量带口音的训练数据和它们的伪标签，而非人工转录，因此是无监督的。<br/><br/>3. 这种方法使得在不依赖人工转录的情况下，可以使用带口音的语音数据进行数据增强。<br/><br/>4. 通过合成带有口音的语音数据，这些数据由无监督的TTS系统生成，并与Librispeech库中的非口音语音数据结合，用于训练ASR模型。<br/><br/>5. 实验结果表明，经过对下游ASR任务进行微调的Wav2vec2.0模型，使用由无监督TTS合成的带口音语音数据作为增强数据，比仅使用Librispeech库中非口音数据的模型，在相对词错误率方面能减少6.1%。 |
| [FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs](https://arxiv.org/abs/2407.04051) | 1. FunAudioLLM模型家族的引入，旨在提升人与大型语言模型之间的自然语音交互。<br/><br/>2. 深度研发了两个创新模型：SenseVoice，用于多语种的语音识别、情感识别和音频事件检测；CosyVoice，专注于自然语音生成，支持多种语言、音色、风格等控制。<br/><br/>3. 提供了低延迟ASR服务（如 SenseVoice-Small针对5种语言），以及高精度ASR服务（如 SenseVoice-Large适用于超过50种语言）。<br/><br/>4. CosyVoice在多语种语音生成方面表现出色，支持零样本跨语言学习，以及跨语言语音克隆等能力。<br/><br/>5. FunAudioLLM模型家族的源代码已开放在Modelscope和Huggingface上，并提供了相应的训练、推理和微调代码，便于开发者进行二次开发和应用。 |
| [BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks](https://arxiv.org/abs/2407.04279) | 1. 提出新的框架 BiosERC，专门研究对话中说话者的个性特征。<br/><br/>2. 利用大型语言模型（LLMs）来提取对话中说话者“生物信息”，作为额外的知识注入到模型中。<br/><br/>3. 通过这种方法，将个人特质融入情感识别任务，以提高对每个发言的情感标签分类的准确性。<br/><br/>4. 实验结果在三个著名基准数据集上达到最先进的水平（SOTA），证明了模型的有效性和泛化能力。<br/><br/>5. 提供源代码链接，表明研究团队愿意分享他们的工作成果。 |
| [LearnerVoice: A Dataset of Non-Native English Learners' Spontaneous Speech](https://arxiv.org/abs/2407.04280) | 1. 提供了L2学习者口语的专门数据集，名为LearnerVoice，包含50.04小时的音频和转录。<br/><br/>2. 数据分析显示，LearnerVoice中的转录包含了大量L2S特征，包括不规范表达和流畅性问题（如填充词、重复词等）。<br/><br/>3. 通过在whisper-small.en模型上对LearnerVoice进行微调，实现了错误率降低44.2%的显著效果，达到10.26%的WER。<br/><br/>4. 实质性分析表明，54.2%的原模型错误与L2S特征相关，而经过微调后的模型则减少了这些错误。 |
| [Systematic Evaluation of Online Speaker Diarization Systems Regarding their Latency](https://arxiv.org/abs/2407.04293) | 1. 该研究对多个在线说话者分段系统进行了评估，这些系统在相同的硬件环境下、使用相同测试数据，并考虑了它们的延迟。<br/><br/>2. 在评估过程中，比较了DIART框架内不同模型组合，UIS-RNN-SML基于在线聚类算法的DIAR系统，以及FS-EEND这种端到端的在线分段系统。<br/><br/>3. 结果表明，DIART-pipeline通过使用pyannote/embedding和pyannote/segmentation这两个模型，实现了最低延迟。FS- EEND系统的延迟表现也相当好。<br/><br/>4. 该研究填补了目前公开文献中关于多个在线分段系统延迟比较的空白，因此具有较高的相关性和实用性。 |
| [MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss](https://arxiv.org/abs/2407.04331) | 1. 提出自动生成适应特定需求的符号音乐（music scores）的研究，这在音乐和爱好者领域具有潜在价值。<br/><br/>2. 研究表明，使用大规模数据集和先进的Transformer架构已经取得了一些积极成果。<br/><br/>3. 但是，这些最先进的模型通常只提供基本的控制，例如对整体节奏和风格的管理，而缺乏精细控制能力，如针对单个音符或酒吧级别的控制。<br/><br/>4. 通过预训练任务设计，提出了一种方法来直接链接控制信号与相应的音乐标记，这有助于在后续微调时实现更有效的初始化。<br/><br/>5. 实施了新颖的反事实损失函数，旨在促进生成音乐与控制提示之间的更好对齐。<br/><br/>6. 这些技术显著提高了在酒吧级别控制音乐生成的能力，相比于传统方法，性能提升了13.06%。<br/><br/>7. 通过主观评估，确认这种增强的控制并未牺牲原始预训练生成模型的音乐质量。 |
| [PAGURI: a user experience study of creative interaction with text-to-music models](https://arxiv.org/abs/2407.04333) | 1. 通过研究Prompt Audio Generation User Research Investigation（PAGURI），提出一种用户体验方法，探讨音乐从业者和实践者如何与文本到音乐模型系统互动。<br/><br/>2. 开发了在线工具，允许用户生成音乐样本，并应用最近提出的个性化技术，如基于微调的个人化，使文本到音乐模型更接近他们的需求和偏好。<br/><br/>3. 通过问卷调查分析参与者如何使用这个工具，以评估文本到音乐模型在增强创造力方面的有效性。结果表明即使音频样本的质量可能不总是满足用户期望，大多数参与者仍愿意将该工具融入其创作过程中。<br/><br/>4. 参与者还提供了关于系统改进和其音乐实践整合的见解。这进一步证明了文本到音乐模型在音乐创作中的潜力和接受度。 |
| [Romanization Encoding For Multilingual ASR](https://arxiv.org/abs/2407.04368) | 1. 提出罗马化编码作为处理重文本语言的优化方案，以适应多语种和代码切换的ASR系统。<br/><br/>2. 在FastConformer-RNNT框架内，结合平衡的并行分词器和Roman2Char模块，实现了词汇量显著减少和输出维度降低。<br/><br/>3. 通过这种方法，可以实现更大的训练批次和更低的内存消耗，增强了系统的灵活性和适应性。<br/><br/>4. 实验结果表明，将此方法应用于普通话-英语的ASR系统，取得了63.51%的词汇量减少和性能提升的显著效果。 |
| [A Mapping Strategy for Interacting with Latent Audio Synthesis Using Artistic Materials](https://arxiv.org/abs/2407.04379) | 1. 提出了一种与生成人工智能模型的潜在空间交互的映射策略。<br/><br/>2. 通过无监督特征学习来编码人类控制空间，并将其映射到音频合成模型的潜在空间中。<br/><br/>3. 提供了一个证明概念系统，该系统使用视觉草图来控制音频合成模型，展示了这种映射策略的实际应用。<br/><br/>4. 讨论了这项工作如何与XAI（可解释的人工智能）在艺术和创意领域相结合，并提出了当前的局限性以及未来研究的方向。 |
| [Improving Audio Generation with Visual Enhanced Caption](https://arxiv.org/abs/2407.04416) | 1. 创建大规模音频数据集：作者提出的目标是创建一个包含丰富描述的大型音频数据集，以改善音频生成模型的能力。<br/><br/>2. 自动化管道生成详细描述：开发了一个自动化流程，通过将视觉预测、音频标题、标签等转化为全面描述，为音频-视觉数据集生成了详细的描述。<br/><br/>3. 提供Sound-VECaps数据集：作者介绍的Sound-VECaps是一个包含1.66M高质量音频-标题对以及丰富细节的数据集。<br/><br/>4. 模型性能提升：通过使用Sound-VECaps训练模型，作者展示了这些模型在理解和生成复杂输入提示下的音频的能力显著增强，从而改善整体系统性能。 |
| [TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR](https://arxiv.org/abs/2407.04444) | 1. 提出TokenVerse，一个单一的基于转录器的模型，设计用于处理多种任务。<br/><br/>2. 通过在ASR模型训练过程中整合任务特定的令牌到参考文本中，实现了多任务的简化处理和无缝推理。<br/><br/>3. 实验覆盖了语音识别（ASR）、说话人变化检测、端点定位和命名实体识别等三个不同任务。<br/><br/>4. 在公开和私有数据集上的实验结果显示，提出的多任务处理方法显著提高了ASR的相对WER，最高可达7.7%。同时，在单个任务性能上超越了传统的分阶段pipeline方法。 |
| [Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models](https://arxiv.org/abs/2407.04482) | 1. 介绍新型的语音模型，如OpenAI Whisper，能够同时进行语音转录和翻译。<br/><br/>2. 提出音频提示下的大型语言模型（LLMs）具有更大的灵活性，可能面临模型控制对抗性攻击的风险。<br/><br/>3. 实验展示了在没有访问模型提示的情况下，通过改变音频输入，可以修改系统行为，从而实现对ASR基础模型的模型控制攻击。<br/><br/>4. 举例说明了如何使用一个通用的对抗性声学段来覆盖Whisper的设置，使其始终执行翻译任务，而不是转录任务。<br/><br/>贡献点总结：该论文主要贡献在于揭示了音频提示下的多任务语音模型可能面临的模型控制对抗性攻击，并通过实验展示了这种攻击的实际操作方法。 |
| [Performance Analysis of Speech Encoders for Low-Resource SLU and ASR in Tunisian Dialect](https://arxiv.org/abs/2407.04533) | 1. 对SSL（自我监督学习）在低资源 spoken Tunisian Arabic方言和结合低资源SLU和ASR场景的对比研究进行了贡献。<br/><br/>2. 实验使用了许多SSL语音编码器在TARIC-SLU数据集上进行操作，这为研究提供了实际的数据支持。<br/><br/>3. 一些实验使用的模型在预训练阶段就考虑了单语或多语数据，或者通过多模态监督学习框架进行了再训练，这些方法的贡献在于提高了模型的有效性。 |
| [Real-time Timbre Remapping with Differentiable DSP](https://arxiv.org/abs/2407.04547) | 1. 提出基于timbre analogies的音频合成方法，研究如何将输入信号的音色表达映射到合成器的控制参数上。<br/><br/>2. 利用可微分数字信号处理技术，使得直接优化合成器参数成为可能，通过引入新的特征差异损失函数。<br/><br/>3. 该损失函数设计用于学习音乐事件之间相对音色变化，特别关注语句中音调平滑度的变化，从而实现有意义的音色空间翻译。<br/><br/>4. 以鼓表演为例进行实证研究，强调音色表达在案例中的重要性，通过实时音色映射展示了从真实鼓声到合成器模拟音色的有效转换。 |
| [Resource-Efficient Speech Quality Prediction through Quantization Aware Training and Binary Activation Maps](https://arxiv.org/abs/2407.04578) | 1. 研究了二进制激活图（BAMs）在基于DNSMOS的卷积架构上的语音质量预测。<br/>2. 发现了带有量化感知训练的二进制模型，其性能与基线模型相当。<br/>3. 该模型还允许使用其他压缩技术，为资源有限的设备提供了灵活性。<br/>4. 结合8位权重量化，他们的方法在推理时实现了25倍的记忆减小，同时几乎全部点积替换为求和操作，体现了显著的资源节省潜力。 |
| [Joint Multi-scale Cross-lingual Speaking Style Transfer with Bidirectional Attention Mechanism for Automatic Dubbing](https://arxiv.org/abs/2305.05203) | 1. 提出了一种联合多尺度跨语言说话风格转移框架，用于同时在全局（如句子级别）和局部（如单词级别）层次上建模两种语言之间的双向说话风格转移。<br/><br/>2. 该框架使用了编码-解码架构，每个方向都有自己的模型，并且通过共享的双向注意力机制进行交互。<br/><br/>3. 进一步，提出了基于多尺度说话风格增强的FastSpeech 2模型，用于将预测的全局和局部说话风格转换为语音。<br/><br/>4. 实验结果证明了该框架的有效性，它在客观和主观评估中都超越了只考虑持续性的基准。 |
| [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](https://arxiv.org/abs/2404.09956) | 1. 提出研究假设：关注音频生成中概念或事件的时空顺序对音频质量的影响，尤其是在数据有限的情况下。<br/><br/>2. 创造偏好学习数据集：使用现有模型Tango，通过合成方式为每个文本提示创建赢家和输家音频输出，供模型学习。<br/><br/>3. 实施优化训练：采用扩散-直接偏好优化（diffusion-DPO）损失在偏好数据集上对Tango模型进行微调。<br/><br/>4. 比较实验结果：通过自动评估和手动评估指标对比，展示优化后的音频输出质量相对于基础模型Tango和AudioLDM2有所提升。 |
| [Towards Audio Codec-based Speech Separation](https://arxiv.org/abs/2406.12434) | 1. 提出Audio Codec-基于的Speech Separation（SS）新任务，即在神经音频编码器（NAC）的嵌入空间中执行SS。<br/><br/>2. 针对这个新任务，提出Codecformer模型，用于音频编码器背景下的SS。<br/><br/>3. 在推理阶段，Codecformer实现了MAC操作量的52倍减少，同时保持与云部署Sepformer相当的分离性能。<br/><br/>4. 该方法为在实际场景中实现高效SS开辟了新的路径。 |
| [SAVE: Segment Audio-Visual Easy way using Segment Anything Model](https://arxiv.org/abs/2407.02004) | 1. 提出一种名为SAVE的轻量级方法，该方法能够有效地将预训练的段任何模型（SAM）适应到音频-视觉分割（AVS）任务中。<br/><br/>2. 通过在Transformer块中融入图像编码器适配器，来更好地捕获独特数据集信息，这表明对数据特征的理解是关键。<br/><br/>3. 提出残差音频编码器适配器，用于将音频特征编码为稀疏提示，这一创新有助于音频和视觉信息的有效融合。<br/><br/>4. 通过实验验证了这种方法的有效性，结果显示其模型在AVSBench数据上的性能显著优于其他SOTA方法。<br/><br/>5. 最后，利用预训练模型在合成数据上进行增强，能够进一步提升在真实AVSBench数据上的表现。 |
