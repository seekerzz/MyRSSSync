# 五里墩茶社
---
| Title | Date | Summary |
| --- | --- | --- |
# 小工蚁创始人
---
| Title | Date | Summary |
| --- | --- | --- |
# AIGCLINK
---
| Title | Date | Summary |
| --- | --- | --- |
# 技术爬爬虾
---
| Title | Date | Summary |
| --- | --- | --- |
# 秋芝2046
---
| Title | Date | Summary |
| --- | --- | --- |
# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [grab/cursor-talk-to-figma-mcp](https://github.com/grab/cursor-talk-to-figma-mcp) | 这份文档是关于Figma设计工具中MCP（Model Construction Kit）插件的详细指南。以下是主要要点和功能概述：<br/><br/>1. **环境设置与构建**：<br/>   - 说明如何在本地开发环境中导航到特定目录，进行代码编辑和修改。<br/><br/>2. **最佳实践**：<br/>   - 强调了操作前与Figma建立连接的重要性。<br/>   - 建议先获取文档信息（使用`get_document_info`），了解设计的基本结构。<br/>   - 在执行任何改动之前检查当前的选择状态（通过`get_selection`）。<br/>   - 根据需求选择合适的创建工具：如用于容器的`create_frame`、基本形状的`create_rectangle`和文本元素的`create_text`。<br/>   - 确保在修改后验证结果，使用`get_node_info`获取节点信息检查是否符合预期。<br/>   - 强调使用组件实例（当可能时）以保持设计一致性。<br/><br/>3. **错误处理**：<br/>   - 提醒所有命令操作可能会抛出异常，并鼓励在实现中加入适当的错误处理逻辑。<br/><br/>4. **大设计的优化策略**：<br/>   - 使用`chunking`参数来处理大量文本节点，分批处理减少内存负担。<br/>   - 监控WebSocket更新以跟踪进度。<br/>   - 实现了针对大型项目的优化和错误处理策略。<br/><br/>5. **复杂设计操作**：<br/>   - 对于文本操作，推荐使用批量操作，并考虑元素之间的结构关系和依赖性。<br/>   - 通过验证输出（如导出部分设计）来确保操作正确实施。<br/><br/>6. **从遗留注释到Figma原生注释的转换**：<br/>   - 描述了识别并匹配文本标记与目标元素的过程，包括利用路径、名称或邻近度进行关联。<br/>   - 建议使用`scan_nodes_by_types`等方法定位相关UI元素以准确分配注释。<br/><br/>7. **原型线到FigJam连接器的转换**：<br/>   - 通过提取原型流动（使用`get_reactions`），设置默认连接器（`set_default_connector`）并生成连结线（`create_connections`）来实现这一目标。<br/>   <br/>8. **许可**：文档指出了使用了MIT许可证，表明开源和免费使用的权利。<br/><br/>这份指南不仅提供了MCP插件的使用说明，还提供了一系列最佳实践、优化策略和注意事项，帮助开发者更高效、更准确地操作Figma设计工具。 |
| [zoicware/RemoveWindowsAI](https://github.com/zoicware/RemoveWindowsAI) | 这篇文档主要介绍了一个名为`RemoveWindowsAi.ps1`的PowerShell脚本，该脚本用于移除或禁用Windows中的人工智能（AI）特性和功能。以下是主要内容：<br/><br/>- **使用说明**：<br/>  - 非交互模式执行脚本：`& [scriptblock]::Create((irm "https://raw.githubusercontent.com/zoicware/RemoveWindowsAI/main/RemoveWindowsAi.ps1")) -nonInteractive`<br/>  - 使用特定选项：`-Options DisableRegKeys,RemoveAppxPackages,DisableCopilotPolicies`<br/>  - 安装经典应用：例如`photoviewer,mspaint,snippingtool,notepad`<br/>  - 启用备份模式以允许回滚操作：`-backupMode`<br/>  - 激活还原模式，用于回滚更改：`-revertMode`<br/>  <br/>- **脚本功能**：<br/>  - 禁用注册表键<br/>  - 阻止AI包重新安装（PreventAIPackageReinstall）<br/>  - 禁用Copilot策略（DisableCopilotPolicies）<br/>  - 移除或禁用AppX包（RemoveAppxPackages）<br/>  - 移除召回功能或特征（RemoveRecallFeature）<br/>  <br/>- **持续更新**：<br/>  - 脚本会随最新的稳定Windows版本更新，以适应新增的AI特性。<br/>  - 提交新发现的AI特性可以帮助扩展脚本的功能。<br/><br/>- **文档中提及的链接**：<br/>  - 最新的脚本更改历史：[GitHub仓库](https://github.com/zoicware/RemoveWindowsAI/commits/main/)<br/>  <br/>- **贡献方式**：<br/>  - 用户可以报告未在脚本中处理的新AI特性或注册表键，以获得进一步的支持。<br/><br/>- **支持与交流**：<br/>  - 可以通过购买作者的咖啡等方式进行捐赠。<br/>  - 加入Discord社区，了解更多信息和支持。<br/>  - 观看YouTube指南视频：[如何移除所有Windows AI功能](https://youtu.be/j5_eEBWGHFw)。<br/><br/>总的来说，该脚本提供了清理和自定义Windows系统以减少或消除AI元素的方法。用户可以根据自己的需求选择性地应用脚本中的功能，并通过社区贡献帮助其持续更新。 |
| [obra/superpowers](https://github.com/obra/superpowers) | Superpowers插件为开发者提供了一套自动化流程和工具集，用于提高开发效率、确保代码质量并简化协作过程。以下是其核心功能的中文概述：<br/><br/>1. **测试驱动开发**（Test-Driven Development）：提倡编写测试用例在前，以确保代码质量，并通过持续集成来验证新功能。<br/><br/>2. **系统化流程**（Systematic over ad-hoc）：优先采用有条理的过程和方法论而非凭直觉和试错法进行工作。<br/><br/>3. **简化复杂性**（Complexity reduction）：追求简洁，减少不必要的复杂性和冗余。<br/><br/>4. **基于证据的决策**（Evidence over claims）：在决定是否完成某个功能时，需要充分的验证和证据支持。<br/><br/>主要包含以下组件：<br/><br/>- **技能库**：包括测试、调试、协作与过程管理等技能。<br/>- **自动化工作流程**：如“测试驱动开发”、“系统化调试”、“并行代理执行”等，以提升效率和质量。<br/>- **更新机制**：通过自动更新插件来获取最新版本的技能和工具。<br/><br/>Superpowers旨在帮助开发者构建更可靠、高效且易于维护的软件产品。通过遵循其哲学和实践指导原则，可以显著提高开发团队的工作流程效率，并确保代码质量和可维护性。 |
| [twitter/the-algorithm](https://github.com/twitter/the-algorithm) | 文档是关于Twitter推荐系统内部实现细节的公开分享。主要包含了以下内容：<br/><br/>1. **推荐系统的组成部分**：<br/>   - **Home Timeline**: 包括轻量级排名（Light Ranker）、重置排名（Heavy Ranker）和内容过滤等组件，用于构建及提供个人主页时间线。<br/>   - **Recommended Notifications**: 使用轻量级和重置排名模型，向用户推送个性化通知。<br/><br/>2. **Bazel构建与测试**：<br/>   文档提及使用Bazel作为构建工具，但没有提供顶层的BUILD或WORKSPACE文件。计划在未来加入更完整的构建和测试系统。<br/><br/>3. **贡献方式**：<br/>   - 社区可以通过GitHub提交问题或拉取请求来提出建议或改进推荐算法。<br/>   - 安全相关问题应通过官方HackerOne漏洞赏金项目报告。<br/>   - 鼓励社区参与，利用集体智慧帮助发现和改进系统中的问题。<br/><br/>4. **透明度与公开**：<br/>   Twitter正在采取更开放的策略，在一个博客文章中宣布了这一新的透明时代，并表明愿意从全球社区获得反馈和建议来提升X（Twitter）平台的功能。<br/><br/>文档强调了通过公开源代码、建立交流渠道以及引入更多社区参与，旨在改进推荐算法及整体用户体验。通过这种合作方式，Twitter期望能在保证服务质量的同时，增强平台的创新性和响应速度。 |
| [rancher/rancher](https://github.com/rancher/rancher) | Rancher是一款开源容器管理平台，专为生产环境中部署容器的组织设计。它简化了Kubernetes的运行、满足IT需求并赋能DevOps团队。提供稳定版本更新通知和快速启动指南，并详细介绍安装要求及文档资源。源代码和项目信息可在其仓库中获取，支持通过多种方式定制构建和打包Rancher。社区可通过论坛或Slack参与讨论与获取帮助，安全问题应私信邮件联系并遵循安全政策。Rancher由SUSE公司版权持有，并遵循Apache License 2.0开源许可协议。 |
| [mudler/LocalAI](https://github.com/mudler/LocalAI) | LocalAI是一个开源项目，由Ettore Di Giacinto创建。它提供了一个免费的替代方案，以替代OpenAI的一些功能，并且在GitHub上托管。<br/><br/>项目的主要目标是为用户提供类似OpenAI的功能和模型，同时保持开放性、免费以及社区驱动。LocalAI支持多种与AI相关的任务如对话生成、文本编辑等。它基于一些现有的开源库进行开发，比如llama.cpp，whisper.cpp等。<br/><br/>项目已经收到了包括Spectrocloud和Premai在内的赞助商的支持，并且欢迎更多的贡献者通过GitHub或Buymeacoffee成为赞助者。Star历史显示了项目的受欢迎程度随时间的波动情况。<br/><br/>License方面，LocalAI采用MIT License，鼓励社区成员贡献代码、想法以及测试反馈。<br/><br/>感谢项目中所有参与的个体贡献者和团队，他们在技术、建议和资源上提供了支持。通过这种方式，LocalAI不仅是一个技术工具，也是一个团结社区的平台。<br/><br/>总之，LocalAI是一个集成了多种开源软件功能的项目，旨在提供一个免费且社区驱动的人工智能框架，为用户提供从对话生成到文本理解等领域的服务。 |
| [dev-sec/ansible-collection-hardening](https://github.com/dev-sec/ansible-collection-hardening) | 这是一个用于Ansible的软件包集合，提供了一套自动化操作系统设置和配置的工具。这个集合作为一个开源项目在GitHub上托管，并且遵循Apache 2.0许可条款。<br/><br/>以下是关键点：<br/><br/>1. **功能**：<br/>   - 包括四个主要的角色：`os_hardening`（用于操作系统加固），`mysql_hardening`（MySQL加固），`nginx_hardening`（Nginx加固）和`ssh_hardening`（SSH加固）。还有正在开发中的Apache和Windows角色。<br/>   <br/>2. **安装**：<br/>   使用`ansible-galaxy collection install devsec.hardening`命令安装这个集合。<br/><br/>3. **使用指南**：<br/>   每个角色都有自己的README文件，提供了详细的示例和用法说明。建议查看Ansible的用户指南来了解更多关于如何在项目中使用这些集合的信息。<br/><br/>4. **贡献**：<br/>   有一个明确的贡献者指导方针（CONTRIBUTING.md），用于指导代码提交和其他形式的参与。<br/>   <br/>5. **版本记录**：<br/>   可以通过访问CHANGELOG文件获取最新的更改和更新历史。<br/><br/>6. **路线图**：<br/>   表示正在进行的工作包括Apache和Windows加固角色的开发，以及对更多操作系统的支持。<br/><br/>7. **其他信息**：<br/>   提供了各种链接用于了解Ansible本身、如何贡献代码以及社区的相关指南和资源。<br/>   <br/>8. **许可条款**：<br/>   使用Apache 2.0许可证进行分发。这意味着软件可以在符合该协议的条件下自由使用、修改并分发。<br/><br/>总的来说，这是一个旨在自动化服务器配置和操作系统加固的高级集合工具，非常适合DevOps实践和安全性增强。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Semantic visually-guided acoustic highlighting with large vision-language models](https://arxiv.org/abs/2601.08871) | ### 贡献点：<br/><br/>1. **提出问题**：论文指出当前音频混合工作流程主要依赖于手动操作和劳动密集型过程，特别是在平衡对话、音乐与音效和伴视频之间的关系时存在挑战。同时，虽然近期的研究已经引入了基于视觉指导的声学高亮任务，该任务通过多模态引导隐式地调整音频源，但对于哪些视觉方面最有效作为条件信号仍不清楚。<br/><br/>2. **系统性研究**：为填补这一空白，论文进行了一个系统性的研究，以评估深度视频理解对音频混合的影响。通过使用文本描述作为视觉分析的代理，作者提示大型视语模型提取六种类型的不同视觉-语义方面，包括对象和角色外观、情感、镜头焦点、语气、场景背景以及推断出的声音相关线索。<br/><br/>3. **实验结果**：研究结果显示，在感知混音质量上，相比最先进的基准方法，镜头焦点、语气和场景背景这三种视觉-语义线索的提取持续显示出最大的改善。这一发现不仅识别了哪些视觉-语义提示最能支持一致且与视觉对齐的声音混合，而且也揭示了一条通过从大型视语模型中提取轻量级指导来自动化电影级别的声音设计的实际路径。<br/><br/>4. **贡献总结**：论文的主要贡献在于其系统研究方法和实际的发现，为如何利用深度视频理解和大模型的视觉-语义信息自动改进音频混音提供了理论依据和技术路线。通过这一过程，不仅明确了哪些特定的视觉元素对提高听觉体验至关重要，而且还为行业实践提供了一种可能的、更为自动化的声音设计方法。 |
| [Echoes of Ideology: Toward an Audio Analysis Pipeline to Unveil Character Traits in Historical Nazi Propaganda Films](https://arxiv.org/abs/2601.08879) | 贡献点:<br/><br/>1. **研究领域创新** - 该论文将计算机音频分析技术应用于探究纳粹宣传电影中的意识形态叙事，开辟了在音频领域内研究历史与意识形态的新视角。<br/><br/>2. **多步骤数据分析** - 引入了一个三阶段流程框架（包括演讲者分段、音频转录和心理语言学分析），以系统地评估和识别影片中角色的意识形态模式，展示了技术分析的全面性和严谨性。<br/><br/>3. **揭示深层次意识形态** - 通过计算机处理方法发现了电影角色中的潜在意识形态线索与故事线，为理解历史宣传手段提供了新的数据驱动视角。<br/><br/>4. **面对挑战的适应性** - 论文讨论了当前演讲者分段技术的局限性，并指出这并不妨碍整体研究的有效性和价值。这表明了研究在面临技术障碍时的创新和适应能力。<br/><br/>5. **潜在的可扩展应用** - 研究成果不仅限于历史分析，还暗示着在社会科学研究、媒体内容评估以及教育领域中的广泛应用潜力，强调了计算音频分析的通用适用性。<br/><br/>6. **跨学科合作与方法融合** - 通过结合语音识别、文本转录和心理语言学等不同领域的技术，体现了跨学科研究的价值，并提供了整合多种数据源来深入理解复杂意识形态的方法。 |
| [Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception](https://arxiv.org/abs/2601.09413) | 以下是该论文的主要贡献点：<br/><br/>1. **提出语音自主框架**：引入了一个用于学习关键的全理解技能（即知道何时相信自己、何时寻求外部音频感知）的声音自主性架构。这个框架旨在解决在同时进行语音识别和外部声音理解任务时，简单地对通用模型进行微调可能导致性能下降的问题。<br/><br/>2. **问题转化为明确的自我反思决策**：通过将上述问题重新定义为一个明确的自我反思决策过程（即“Speech-Hands”框架），研究人员证明了学习可实现的反射原语能够有效防止模型被有缺陷的外部候选方案误导。这种方法不仅适用于语音识别，而且还能自然地扩展到复杂的、多选音频推理任务。<br/><br/>3. **性能显著提升**：通过使用“Speech-Hands”，模型在七个基准测试中的词错误率（WER）比强大的基线提高了12.1%。这显示了该模型在跨多种ASR开放数据集上的稳健泛化能力和可靠性，在音频问题回答决策上，准确性达到77.37%，F1得分高。<br/><br/>4. **统一感知和决策**：该工作提供了一条实践途径，即通过将感知与决策合并来实现更可靠和坚韧的音频智能。这表明了在理解和处理多样的音频问答数据集时具备强大的泛化能力和稳定性。<br/><br/>综上所述，这项研究的主要贡献是提出并验证了一个用于提高语音识别系统自我反思能力、防止模型被外部误导源误导的有效框架，并通过实验验证了该框架在多个任务上的有效性和可靠性。 |
| [Integrated Minimum Mean Squared Error Algorithms for Combined Acoustic Echo Cancellation and Noise Reduction](https://arxiv.org/abs/2412.04267) | ### 贡献点:<br/><br/>1. **提出综合方法** - 该论文提出了一个集成方法来同时处理噪声抑制（NR）和声学回声消除（AEC），在多麦克风和多扬声器的通用设置中考虑了这些过程之间的相互作用。这与传统的分离设计方法不同，后者分别独立地为AEC和NR选择不同的信号模型、成本函数和解法策略。<br/><br/>2. **单一信号模型** - 该论文采用了单一的信号模型，可以是麦克风信号矢量或者是通过将麦克风和扬声器信号堆叠而得到的扩展信号矢量。这一方法简化了处理过程，并通过使用单个均方误差（MSE）成本函数和通用解决方案策略来优化NR和AEC效果。<br/><br/>3. **多通道维纳滤波器** - 该论文基于麦克风信号模型，开发了一个多通道维纳滤波器（MWF）。同时，利用扩展的信号模型证明了可以推导出一个扩展的MWF（MWFext），并找到了几个等价表达式。这些等价表达式虽然在形式上有所不同，但都可解释为AEC和NR顺序的不同排列策略。<br/><br/>4. **非唯一性和等效性** - 在秩不足的情况下，扩展的MWFext可能不是唯一的解。论文讨论了在这种情况下不同的等价表达式的性质，以及它们与最小范数解决方案的关系。虽然这些表达式在理论上是等价的，但在实际应用中因非平稳性和不完美的协方差矩阵估计导致性能差异。<br/><br/>5. **实践性能比较** - 最后，通过实验评估，论文发现了在不同场景下AEC-NR和NRext-AEC-PF算法具有最佳综合表现。这些结果强调了在噪声抑制与回声消除过程中的顺序排列对实际性能的影响。 |
| [MORE: Multi-Objective Adversarial Attacks on Speech Recognition](https://arxiv.org/abs/2601.01852) | 以下是该论文的贡献点：<br/><br/>1. **ASR模型在多种实际应用中的广泛应用**：通过引入大规模自动语音识别（ASR）模型，如Whisper，显著扩展了这些模型的应用范围至多样的现实世界场景。<br/><br/>2. **对ASR模型鲁棒性的重视**：强调了确保ASR模型在实时环境中能够抵抗微小输入扰动的鲁棒性对于维护可靠性能的重要性。<br/><br/>3. **对ASR鲁棒性与效率之间关系的研究**：研究了之前工作主要关注的准确性降解问题，但忽略了与效率相关的鲁棒性。通过这窄化的视角，论文认识到仅专注于其中一方面并未充分理解ASR模型的脆弱性。<br/><br/>4. **全面评估ASR在不同攻击场景下的鲁棒性**：提出了对ASR模型在多种攻击情况（如对抗攻击）下进行鲁棒性的综合研究。<br/><br/>5. **多目标重复双倍鼓励攻击（MORE）的提出**：提出了一种名为MORE（Multi-Objective REpetitive Doubling Encouragement Attack）的策略，通过层次化分阶段排斥-锚定机制同时降低识别准确率和推理效率。该方法将多目标对抗优化问题重新构造成一个层级框架，并通过逐次实现双重目标。<br/><br/>6. **新颖的重复鼓励双倍目标（REDO）**：提出了一种名为REDO（Repetitive Encouragement Doubling Objective）的新颖策略，用于在保持准确度降解的同时维持预测序列长度的周期性加倍，从而增强对ASR模型的多目标攻击有效性。<br/><br/>7. **实验结果与分析**：论文通过实验展示了MORE方法的一致效果，在对抗输入下能够显著增加转录输出的时间长度，同时保持较高的词错误率。这证明了MORE在多目标对抗攻击中的有效性，并强调了其对于ASR模型鲁棒性和效率改进的贡献。 |
| [MATS: An Audio Language Model under Text-only Supervision](https://arxiv.org/abs/2502.13433) | 贡献点如下：<br/><br/>1. **MATS模型开发**：提出了一种名为MATS（多模态音频语言LMM）的文本驱动的多模态大型语言模型，它专注于使用仅基于文本监督的策略处理多种音频任务。<br/><br/>2. **音频-语言对齐模型的利用**：通过利用预训练的音频-语言对齐模型如CLAP，开发了一种纯文本训练策略，将共享的音频-语言潜在空间映射到LLM潜在空间中。这使得在训练过程中无需依赖音频数据即可赋予LLM音频理解能力。<br/><br/>3. **多模态桥接机制**：为了进一步缩小音频和语言嵌入之间的模态差距，并利用CLAP中的音频信息，提出了一个名为Santa（强相关噪声文本与音频）的机制。该机制将音频嵌入映射到CLAP语言嵌入空间中，同时保留了音频输入的关键信息。<br/><br/>4. **纯文本训练**：MATL模型仅在大量文本数据上进行了训练，并且仍然能够实现与大型音频-语言对训练的数据集相比具有竞争力的性能表现。<br/><br/>5. **代码开源**：提供了一个公开可用的代码库（链接为<https://github.com/wangwen-banban/MATS>），使得其他研究者和开发者可以访问、学习并进一步探索MATS模型的应用。 |
| [Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio](https://arxiv.org/abs/2505.10975) | 贡献点：<br/><br/>1. **系统分类与概述**：论文提供了一套对端到端（E2E）神经网络方法进行多说话人自动语音识别的全面分类，强调了近期的发展，并进行了对比分析。<br/><br/>2. **架构范式区分**：分析并比较了预分割音频中的SIMO（单输出-多个输入）和SISO（单一输出-单一输入）架构的不同特性及其权衡。<br/><br/>3. **改进与算法**：基于上述两种架构，概述并讨论了近期的架构和技术改进。<br/><br/>4. **扩展至长时间语音**：探讨了对长时语音的适应性，包括分段策略和确保说话者一致性假设缝合的方法。<br/><br/>5. **方法评估与比较**：通过标准基准对不同方法进行了评价，并进行了全面对比分析。<br/><br/>6. **挑战与未来方向**：总结了多说话人自动语音识别领域面临的关键挑战及未来研究的方向。 |
| [A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering](https://arxiv.org/abs/2507.07046) | ###贡献点:<br/><br/>1. **创新模型开发**: 提出了一种结合深度卷积循环网络(DCRF)和双向长短期记忆(BiLSTM)的模型，用于语音情绪识别(SER)，能够识别包括中性、快乐、悲伤、愤怒、恐惧、厌恶以及惊讶在内的七种基本情绪。<br/><br/>2. **多数据集训练与优化**: 该模型在五组不同的人声情绪数据库上进行训练和评估，分别是RAVDESS (R)、TESS (T)、SAVEE (S)、EmoDB (E)和Crema-D (C)，实现了高精度的识别结果。<br/><br/>3. **单一模型综合评价**: 第一次在五组基准数据集(RAVDESS+TESS+SAVEE+CERMA-D+Eemo-DB)上对单一SER模型进行系统性的评估，展示了其在不同数据集上的应用能力和稳定性。<br/><br/>4. **高总体准确率**: 实现了93.76%的总体准确率，显著超过了之前的研究结果，在五组综合数据集中达到了98.82%的准确率。<br/><br/>5. **全面性和通用性验证**: 通过这一系列实验和比较分析，证明了所提出的DCRF-BiLSTM框架在多种类型的人声数据库上的强大鲁棒性和泛化能力。 |
| [Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets](https://arxiv.org/abs/2511.13529) | ### 贡献点:<br/><br/>1. **提出新数据集**:<br/>   - 引入了两个新的音频数据集，即BEA-Large和BEA-Dialogue。这两个数据集来自于未处理的匈牙利语音语料库（BEA）部分。<br/>   <br/>2. **增强数据多样性**:<br/>   - BEA-Large通过增加来自433名说话者的255小时自发性言语片段，扩展了原有的基础数据集，丰富了详细的分段元数据。<br/>   - BEA-Dialogue包含85小时的自发对话内容，这些对话被划分为基于说话者独立的子集，并支持在会话自动语音识别（ASR）和说话者聚类分析领域的研究。<br/><br/>3. **建立可复现基准**:<br/>   - 使用公开可用的ASR模型，为这两个数据集建立了可重复性基线。通过微调Fast Conformer模型，实现了自发语段14.18%和重复语句4.8%的词错误率。<br/>   <br/>4. **提供对话ASR参考点**:<br/>   - 进行了语音分割实验，提供了12.46%-17.40%的语音分割误差率，为未来的研究改进提供了参考。<br/><br/>5. **强调挑战与需求**:<br/>   - 强调了会话ASR面临的主要挑战，包括流利性、重叠和非正式语言模式。<br/>   <br/>6. **推动匈牙利语音技术发展**:<br/>   - 通过释放这两个数据集和基线结果，旨在促进匈牙利语音技术的进步，并为其他语言的自发性和对话基准开发提供方法学框架。 |
| [MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization](https://arxiv.org/abs/2601.01554) | ### 贡献点:<br/><br/>1. **提出SATS目标**: 介绍了Speaker-Attributed Time-Stamped Transcription（SATS）的目标，旨在同时识别所讲的内容并精确确定每个发言者的时机。这一特性特别适用于会议转录场景。<br/><br/>2. **现有系统的局限性**: 指出了当前的SATS系统在端到端建模、有限上下文窗口、长距离发言人记忆弱以及无法输出时间戳等方面存在限制。<br/><br/>3. **MOSS Transcribe Diarize模型介绍**: 提出了一种名为MOSS Transcribe Diarize的统一多模式大型语言模型，能够以端到端的方式联合执行Speaker-Attributed Time-Stamped Transcription任务。该模型通过在大量实际野外数据上进行训练，并配备有高达90分钟输入的128k上下文窗口来解决上述问题。<br/><br/>4. **性能提升**: 该模型在多种公共和内部基准测试中均超越了最先进的商业系统，在全面评估中显示出了良好的扩展性和鲁棒性。 |
