# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [nvm-sh/nvm](https://github.com/nvm-sh/nvm) | 这段内容是关于NVM（Node Version Manager）项目和其维护者ljharb的。NVM是一个用于管理Node.js版本的工具，它允许用户轻松地切换不同版本的Node.js。<br/><br/>内容提要包括以下几点：<br/><br/>1. **唯一维护者**：目前NVM的主要维护者是ljharb。<br/><br/>2. **项目发展**：随着项目的推进，项目的管理和贡献者可能会增加。<br/><br/>3. **版权和政策声明**：NVM遵循一定的版权政策，并提供了详细的使用条款、隐私政策等信息。<br/><br/>总之，这段内容主要围绕NVM项目及其维护者的介绍，同时也强调了项目的一些管理规定以及用户访问时需要注意的政策声明。 |
| [swiftlang/swift](https://github.com/swiftlang/swift) | 这段文字是关于如何使用Swift的本地工具链来构建和安装到Xcode中的工具链。它还提到了在遇到构建问题时可以尝试的解决步骤，以及更新Xcode版本后如何重新配置构建以避免错误。最后，这段话还建议学习者先查看文档索引，以便对可用文档有一个全面的认识，特别是对于初学者提交PR前需要理解的内容。 |
| [freeCodeCamp/freeCodeCamp](https://github.com/freeCodeCamp/freeCodeCamp) | 这段代码是运行在<https://www.freecodecamp.ORG/>这个网站上的。它是一个社区平台，提供学习编程、数据可视化和后端开发等技能的资源。<br/><br/>代码还包含一个关于如何报告bug的指南，以及如何安全地报告可能影响平台完整性的漏洞的信息。<br/><br/>此外，这段代码还显示了平台的总体状态，包括所有应用的通用平台状态，以及用于代码构建和部署的具体DevOps状态。 |
| [Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) | 本文是关于AutoGPT这个项目的介绍。AutoGPT是一个基于通用语言模型（LLM）的AI应用，它提供了一个框架，可以用来创建和管理自己的AI代理。<br/><br/>项目的核心是使用了agent protocol标准，这确保了与其他AI系统兼容，并且通信路径清晰明了。<br/><br/>此外，本文还提到了如何获取帮助、如何报告问题或请求新功能的方法，以及AutoGPT与相关姐妹项目的联系。<br/><br/>总的来说，AutoGPT是一个集成了通用语言模型和agent protocol的AI应用开发平台，它为开发者提供了创建和管理自己AI代理的强大工具。 |
| [yuliskov/SmartTube](https://github.com/yuliskov/SmartTube) | Q: Does it skip video segments?<br/>A: No, SmartTube does not skip video segments. However, if your device's hardware does not support high frame rates (HDR), you might experience some skipped frames or buffering issues.<br/><br/>Q: How to start the next video automatically / stop after every video?<br/>A: To start the next video automatically, use the loop button 🔁. If you prefer to stop playing after every video, this behavior is typically default and does not require any specific settings.<br/><br/>Q: Can I remove recommended videos that are unrelated to me?<br/>A: Unfortunately, SmartTube does not currently provide a feature to remove recommended videos based on personal preferences. These recommendations are determined by YouTube's algorithms, which take into account various factors like watch history, search queries, and user interactions with the platform.<br/><br/>Q: Why do some updates say "don't update if satisfied with the current version"?<br/>A: This message typically appears in software update notifications when an update is available but not mandatory. The recommendation is to refrain from updating if you are content with the current version.<br/><br/>This advice can be beneficial for users who have recently installed a new version and want to avoid any potential issues that might arise from updating immediately. However, it's important to note that this message does not guarantee that there won't be any updates or improvements in the future. |
| [grpc/grpc-go](https://github.com/grpc/grpc-go) | 这段文字是关于如何解决在使用gRPC-Go时遇到的错误和问题。具体包括如何更新版本以解决日志级别设置的问题，以及如何通过查看客户端和服务器的日志来定位和调试运输错误等。 |
| [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) | 这个代码库是由多个贡献者共同创建的，最初由Daniel Stefanovic发起，现在由CodeCrafters, Inc.维护。根据法律许可，CodeCrafters, Inc.已经放弃了所有版权和相关或邻接的权利。 |
| [flutter/flutter](https://github.com/flutter/flutter) | Flutter是一个用于创建美观、快速应用的开源开发平台。它具有以下特点：<br/><br/>1. **美观用户体验**：Flutter通过其分层架构，允许设计师在不受限于底层框架的情况下创作完整的视觉效果。<br/><br/>2. **快速结果**：Flutter使用硬件加速的2D图形库（如Skia和Impeller），确保应用程序运行流畅且无卡顿。<br/><br/>3. **生产力工具**：Flutter支持状态热重载（hot reload），使开发者能够实时看到代码更改后的应用效果，无需重新启动或丢失状态。<br/><br/>4. **开放和可扩展**：Flutter是一个开源项目，欢迎所有贡献者参与。它提供了丰富的第三方包，方便开发者根据目标平台进行快速开发。 |
| [ueberdosis/tiptap](https://github.com/ueberdosis/tiptap) | 这段文字是关于Tiptap Editor Core的贡献指南和贡献者的列表。它提到了如何进行贡献，包括查看详细的CONTRIBUTING文件，以及列出的一系列贡献者名单，其中包括Sam Willis、Brian Hung等知名开发者。最后还提到了MIT许可作为项目的基础许可证，并链接到LICENSE.md文件以获取更多信息。 |
| [jwasham/coding-interview-university](https://github.com/jwasham/coding-interview-university) | 这篇文章主要介绍了计算机领域中一些重要的研究和论文，包括Google的分布式存储系统Bigtable、高可用性数据基础设施建设案例等。同时提到了这些论文的版权信息，声明为CC- BY- SA-4.0许可。总的来说，这篇文章旨在提供一个计算机科学领域的知识库。 |
| [donnemartin/system-design-primer](https://github.com/donnemartin/system-design-primer) | 这个仓库包含了多个系统设计相关的博客文章和资源。作者Donne Martin提供了代码和资料，许可为Creative Commons Attribution 4.0 International License（CC BY 4.0）。<br/><br/>如果你对系统设计或者相关技术有兴趣，可以通过阅读这些博客来学习。同时，也可以通过GitHub页面上的联系方式与作者交流。 |
| [RocketChat/Rocket.Chat](https://github.com/RocketChat/Rocket.Chat) | 本文主要介绍了Rocket.Chat这款开源的聊天应用。它提供了一个基于Web的界面，用户可以通过这个界面与其他使用Rocket.Chat的人进行交流。<br/><br/>安装 Rocket.Chat可以通过Gitpod提供的链接，这是一个方便的在线开发环境。安装完成后，你可以通过yarn或npm命令来运行和管理你的Rocket.Chat实例。<br/><br/>此外，本文还提到了如何成为Rocketeer（火箭人），即如何加入到Rocket.Chat的开发团队中。如果你对这款应用感兴趣或者想要贡献自己的力量，可以参考文中提供的链接和信息进行进一步了解。 |
| [Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt) | LitGPT是一个基于Lightning Fabric的模型，它扩展了Lit-LLaMA和nanoGPT。这个项目是开源的，遵循Apache 2.0许可证。<br/><br/>如果你在研究中使用了LitGPT，请参考以下引用：<br/><br/>```bibtex<br/>@misc{litgpt-2023, <br/>    author        = {Lightning AI}, <br/>    title         = {LitGPT}, <br/>    howpublished  = {\url{https://github. com/Lightning-AI/litgpt}}, <br/>    year          = {2023}, <br/>}<br/>```<br/><br/>这将帮助你在学术界正确引用这个模型。 |
| [ethereum-optimism/optimism](https://github.com/ethereum-optimism/optimism) | 这段代码是用于创建一个名为"op-ufm"的组件，该组件可能是一个监控用户反馈指标的工具。"op-ufm"可能是Optimism项目的一部分，该项目致力于改进以太坊网络。<br/><br/>代码中提到了几个关键概念：<br/><br/>1. `<%= %>`：这是模板引擎中的占位符，用于输出变量的值。<br/><br/>2. `chain-mon`：这可能是一个监控链上活动的服务或组件。<br/><br/>3. `op-ufm`：这是创建的组件名称，它代表用户反馈管理工具。<br/><br/>4. `develop`：这是主要开发分支，用于维护最新且兼容的软件版本。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [一年暴增4200家，攻占商场的“穷鬼食堂”，让海底捞都眼红](https://www.36kr.com/p/2858941376498304) | 这篇文章讨论了小火锅作为一种餐饮业态的发展前景。文章提到了海底捞等大企业通过推出露营火锅等创新产品来开拓市场，而许多小火锅品牌则显得较为弱势，试水的业务可能最终消失或转变。<br/><br/>总的来说，小火锅是否能长久发展，以及它们在竞争中的地位，都取决于它们能否找到差异化策略，以及自身对市场的适应能力。 |
| [美图CEO吴欣鸿：两年做了13款AI应用，我们都踩了哪些坑？· 36氪专访](https://www.36kr.com/p/2858145012763528) | 这段文字是吴欣鸿，美图的CEO，在一次访谈或公开演讲中分享的内容。内容主要围绕技术发展、军备竞赛的战略定位以及如何将自身能力与AGI（人工智能助手）调用的能力相结合。<br/><br/>如果需要更具体的咨询摘要，可能需要对这段话进行提炼和总结，例如可以关注以下几个点：<br/><br/>1. 美图的技术战略：如何看待在视频生成领域与其他大模型的竞争？<br/><br/>2. 技术与业务结合：如何将技术能力转化为实际的商业价值？<br/><br/>3. AGI调用能力：美图如何利用AGI的能力来提升其服务或产品的灵活性？<br/><br/>以上信息可以根据需要进行摘要。 |
| [2024年“暴利”赛道：直播拆卡](https://www.36kr.com/p/2858756693150601) | 本文主要探讨了直播拆卡这一现象，分析了它作为新型社交货币的特性，以及它在年轻人情绪消费中的地位。<br/><br/>文章指出，卡牌市场存在未成年人沉迷、涉及赌博争议等问题，需要正确的引导和管理。同时，卡牌作为一种情感寄托和收藏爱好，对于满足一部分人的精神需求具有积极作用。<br/><br/>总的来说，直播拆卡这一现象反映了年轻人的情感消费趋势，同时也提出了对相关市场的规范和完善问题。 |
| [苹果“返校优惠”吸引力不再，只因电商平台价格战凶猛？](https://www.36kr.com/p/2858760133679494) | Apple 不断在中国市场释放善意，如频繁举办促销活动和参与电商节日等，其最终目的是刺激在华销量。然而，随着汇率变化等因素影响，官方定价体系面临挑战，导致新品价格破发现象增多。<br/><br/>尽管如此，iPhone 在各大电商平台的表现依然强劲，特别是在双十一这样的购物狂欢节中，Apple 成为了最大的赢家之一。<br/><br/>综上所述，Apple 依赖中国市场并积极促销以维持销售，但官方定价体系的调整对其销量策略产生了影响。 |
| [任天堂的背刺，造就了它最强大的对手](https://www.36kr.com/p/2858760310950787) | 本文讲述了任天堂与索尼之间的一次合作破裂事件，即所谓的「一刀背刺」。这次事件不仅改变了游戏主机市场的格局，还对后来的游戏技术和市场发展产生了深远影响。<br/><br/>总结来说，这段历史片段展示了商业合作中的策略变化和由此产生的行业动态，对于理解现代电子游戏产业的发展脉络具有重要参考价值。 |
| [天猫推出199元的电视盒子，只因“苍蝇腿也是肉”？](https://www.36kr.com/p/2858705862416768) | 这篇文章主要讨论了购买电视盒子的需求以及其存在的市场空间。作者提到，部分电视品牌在追求利润时忽视了用户体验，这使得电视盒子作为对抗劣质体验的工具存在需求。<br/><br/>文章还提到了天猫魔盒8 Air Pro这款产品，它以相对合理的定价和硬件配置吸引用户。此外，文中还建议，如果用户的电视配置老旧，可以考虑购买电视盒子来提升使用体验。<br/><br/>总的来说，这篇文章通过分析市场现状和消费者需求，阐述了电视盒子作为一种改善用户体验的工具存在的必要性和价值。 |
| [36氪独家 · TikTok在海外开启本地生活业务](https://www.36kr.com/p/2857541368662660) | TikTok正在海外试水本地生活业务，首站选择东南亚地区。目前业务已在印尼和泰国开启，主要集中在餐饮商家。为了抓住新商机，服务商已经开始拓展本地生活服务。<br/><br/>然而，本地生活业务的开展面临供应链难题、连锁化率相对较低以及监管风险等问题。TikTok在推进这一业务时需要平衡这些挑战。 |
| [独家｜其实，DST买的是小红书的老股](https://www.36kr.com/p/2857918060710537) | 小红书最近完成了新一轮融资，估值达到170亿美元。这是DST Global与红杉中国共同参与的一轮资本运作，其他投资者包括高瓴、博裕和中信资本等。<br/><br/>小红书此前并不持有其股份，而红杉中国在此之前并未投资小红书。这次融资使得小红书在资本市场中地位提升，同时也反映了其正向盈利能力和市场吸引力。<br/><br/>此外，DST作为全球知名的PE基金，在中国的投资动作并不多见，这次对小红书的投资进一步凸显了DST在全球互联网领域的影响力和战略眼光。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Source Tracing of Audio Deepfake Systems](https://arxiv.org/abs/2407.08016) | 1. 提出了一种系统，用于分类各种语音 Spoofing 的属性，这针对音频深度伪造生成过程中各模块的特征进行了捕捉。<br/><br/>2. 系统设计的目标是覆盖整个生成管道，即从输入处理到波形生成的全过程。<br/><br/>3. 评估了该系统在两个数据集上：ASVspoof 2019 Logical Access 和 MLAAUD 上的表现。实验结果证明了系统的鲁棒性，能够准确识别深度伪造生成系统中的各种Spoofing属性。 |
| [Phonetic Richness for Improved Automatic Speaker Verification](https://arxiv.org/abs/2407.08017) | 1. 提出对测试语音质量的估计，以考虑不同声学条件。<br/><br/>2. 发现除了语句持续时间（net-speech duration）外，音素丰富度也是判断语音质量的关键指标。<br/><br/>3. 利用自动说话识别系统获得的转录文本，探索了几种基于音素频率分布的音素丰富度测量方法。<br/><br/>4. 提出的音素丰富度衡量被发现与语音身份验证分数有正相关性，这有助于提高声纹识别系统的准确性。<br/><br/>5. 通过将提出的音素丰富度测量与净语句时长结合起来，研究了这对调整说话者验证分数的影响，结果显示相对eer提高了5.8%。 |
| [Spiking Tucker Fusion Transformer for Audio-Visual Zero-Shot Learning](https://arxiv.org/abs/2407.08130) | 1. 提出Spiking Tucker Fusion Transformer（STFT）模型，用于音频-视觉零样本学习（ZSL）。<br/><br/>2. STFT利用不同时间步的时空信息生成鲁棒特征表示。<br/><br/>3. 引入时间步因素（TSF），动态合成后续推理信息。<br/><br/>4. 提出全局-局部池化（GLP）策略，结合最大和平均池化操作，减少神经元噪声。<br/><br/>5. 通过动态调整神经元阈值，根据语义和时间线索进行调整。<br/><br/>6. 针对直接线性模型难以整合时空和语义信息的问题，提出多尺度时空-语义融合模块，实现SNN和Transformer输出的多层融合，并保持第二阶交互完整。 |
| [An Unsupervised Domain Adaptation Method for Locating Manipulated Region in partially fake Audio](https://arxiv.org/abs/2407.08239) | 1. 提出针对部分虚假音频检测的跨领域问题，关注数据域间的性能下降。<br/><br/>2. 灵感来源于混合专家模型，提出一个名为"Samples mining with Diversity and Entropy (SDE)"的无监督方法。<br/><br/>3. 该方法首先通过学习多样专家，这些专家在源域的不同角度上表现出优异性能，但在目标样本上存在模糊性。<br/><br/>4. 利用这些专家进行信息样例选择，通过计算它们的熵来确定其重要性。<br/><br/>5. 进一步提出针对这些精选样例的标签生成方法，该方法专为这些融入训练过程中的源域和目标域信息样本设计。 <br/><br/>6. 在ADD2023Track2这样一个跨领域音频检测数据集上应用了SDE方法，通过引入10%的目标域未知样本，实现了43.84%的F1分数，相对提升77.2%。 |
| [Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning](https://arxiv.org/abs/2407.08306) | 1. 提出基于BERT的符号音乐理解模型（Adversarial-MidiBERT）。<br/><br/>2. 引入一种无偏预训练方法，基于对抗学习来最小化导致偏见的令牌参与。<br/><br/>3. 提出一个掩码微调方法，以缩小预训练和微调之间的数据差距，有助于模型更快收敛并表现更好。<br/><br/>4. 在四个音乐理解任务上对方法进行了评估，并展示了在所有任务中都表现出色的结果。 |
| [Autoregressive Speech Synthesis without Vector Quantization](https://arxiv.org/abs/2407.08551) | 1. 提出MELLE，一种基于连续值令牌的新型语言建模方法，用于文本到语音合成（TTS）。<br/><br/>2. MELLE避免了向量量化等音频压缩技术，直接从文本条件自回归生成连续梅尔谱帧，减少了对矢量编码的依赖。<br/><br/>3. 在模型训练上，MELLE应用了回归损失，并引入了针对梅尔谱流的新损失函数，以更好地模拟连续值令牌的概率分布。<br/><br/>4. MELLE还采用了变分推理技术，增强了模型的采样机制，从而提高了输出多样性并增强了模型的鲁棒性。<br/><br/>5. 实验结果表明，与VALL-E和其变体等双阶段编码语言模型相比，MELLE在性能上更优，且避免了样本离散码问题导致的稳定性问题。 |
| [From Real to Cloned Singer Identification](https://arxiv.org/abs/2407.08647) | 1. 研究了如何使用歌手识别方法来检测合成声音中的原始歌手。<br/><br/>2. 提供了三个嵌入模型，这些模型是通过一种歌手级别的对比学习训练的，其中正对是来自同一歌手的音段。<br/><br/>3. 这些模型可以处理不同的输入类型，如混合声音、单声道歌声或双声道都包含。<br/><br/>4. 实验证明，所有模型在识别真实歌手时表现出色。但在评估集中分类歌手克隆版本时，它们的表现下降，特别是对于使用混合声音作为输入的模型。<br/><br/>这些发现强调了理解歌手识别系统中存在的偏见的重要性，以及这些偏见如何影响对音乐中深度伪造声音的识别。 |
| [Speech dereverberation constrained on room impulse response characteristics](https://arxiv.org/abs/2407.08657) | 1. 提出问题：针对单通道语音去回声（speech dereverberation）领域，现有的深度学习方法在理解房间声学特性方面不透明，被视为黑箱系统。<br/><br/>2. 解决方案：提出一种新的物理一致性损失（Physical Coherence Loss, PCL）来解决这个问题。PCL鼓励模型生成的去回声结果所对应的房间响应（Room Impulse Response, RIR），使其与原始录音所在的房间声学特性相匹配。<br/><br/>3. 实验验证：通过实验，展示了使用PCL进行训练后，模型在保持原始去回声信号的同时，能够提供更物理上一致的RIR。 |
| [ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions](https://arxiv.org/abs/2407.08691) | 1. 介绍了一种方法，使得Transformer模型如Audio Spectrogram Transformers（AST）能够处理变长音频输入，在训练和推理阶段都适用。<br/><br/>2. 提出的解决方案是通过序列打包技术（Sequence Packing），创建了一个名为ElasticAST的模型。<br/><br/>3. 在训练阶段，ElasticAST能够适应任何长度的音频数据，提供灵活的训练环境。<br/><br/>4. 在推理阶段，ElasticAST保持了与标准AST在特定长度或分辨率下训练时相当的性能。<br/><br/>5. 通过实验验证，ElasticAST在使用原生长度音频数据集进行训练和评估时，表现优于标准AST。 |
| [Acoustic Disturbance Sensing Level Detection for ASD Diagnosis and Intelligibility Enhancement](https://arxiv.org/abs/2401.11832) | 1. 对自闭症（ASD）个体在嘈杂城市环境中的声学敏感性进行了研究。<br/>2. 使用感知听觉测试来展示高内部噪声（HIN）特征对他们理解能力的影响。<br/>3. 提出这种感知水平作为诊断ASD的额外辅助手段。<br/>4. 介绍了一种针对ASD特定情况的新颖理解增强方案。<br/>5. 在实验中，该方案通过估计语音帧中的谐波特征，并用它们作为滤波器银行中心频率，显著提高了ASD和正常人的声学理解能力。 |
| [Are Paralinguistic Representations all that is needed for Speech Emotion Recognition?](https://arxiv.org/abs/2402.01579) | 1. 对英语以外的多种语言环境下，使用预训练模型（PTMs）进行语音情感识别（SER）的研究进行了全面比较。<br/><br/>2. 作者对比了五种最先进的PTM代表，包括TRILLsson等。<br/><br/>3. 研究结果显示，TRILLsson的PTM表示在SER性能上表现最佳，这归因于它更有效地捕捉音高、语气和其他语音特征的能力。<br/><br/>4. 这项研究填补了使用paralinguistic PTM在多种语言环境下评估SER效能的空白。 |
| [AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning](https://arxiv.org/abs/2407.07801) | 1. 提出AVCap，一个音频-视觉Captioning框架，作为简单但强大的音频-视觉captioning基础方法。<br/><br/>2. AVCap利用音频-视觉特征作为文本令牌，这带来了性能、可扩展性和模型规模等多个方面的优势。<br/><br/>3. 设计围绕三个关键维度：探索最优的音频-视觉编码架构，根据生成文本特性调整预训练模型，以及研究模态融合在captioning中的有效性。 |
| [SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding](https://arxiv.org/abs/2307.07421) | 1. 提出一种新的线性时间替代自注意力的方法，名为"SummaryMixing"。<br/><br/>2. "SummaryMixing"通过汇总所有时间步的向量平均值来总结一个语音片段，这使得模型对整个序列进行快速概括。<br/><br/>3. 在最先进的ASR模型中引入"SummaryMixing"，使得训练和推理速度提高至28%，同时内存使用减少一半。<br/><br/>4. 该论文提出了一种有效且节省资源的替代自注意力的方法，对于提高ASR系统的性能和效率具有贡献价值。 |
| [Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach](https://arxiv.org/abs/2401.10747) | 1. 提出一种新型的知识转移网络，用于在不同模态之间进行翻译，以重构缺失的音频模态。<br/><br/>2. 开发了一种跨模态注意力机制，旨在保留重建和观察模态中最大信息量，以支持情感预测。<br/><br/>3. 在三个公开可用的数据集上进行了大规模实验，结果显示该方法显著优于基线，并且在多模态完整监督条件下达到了相当的性能。 |
| [MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation](https://arxiv.org/abs/2407.03188) | 1. 提出Colloquial Description-到-Song Generation的新任务，关注生成内容与人类日常表达的语义对齐。<br/><br/>2. 目标是弥合AI模型中语言理解（colloquial language understanding）和声音表达（auditory expression）之间的差距，最终创造出满足人类听觉期望的歌曲。<br/><br/>3. 介绍Caichong Music Dataset (CaiMD)，这是针对当前数据集存在的局限性而设计的。CaiMD由专业音乐人和业余爱好者共同手工标注，提供了多样化的视角和对描述语义全面的理解。<br/><br/>4. 提出MuDiT/MuSiT框架，这是一个创新的单阶段模型，旨在实现人类与机器在歌曲创作中的有效对齐。<br/><br/>5. 该框架不仅实现了语言（colloquial language）和音乐感知（auditory music perception）之间的跨模理解，还确保生成的歌曲能够满足用户期望的结果。 |
| [FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs](https://arxiv.org/abs/2407.04051) | 1. FunAudioLLM模型家族的引入，旨在提升人与大型语言模型之间的自然语音交互。<br/><br/>2. 深度研发了两个创新模型：SenseVoice，用于多语种的语音识别、情感识别和音频事件检测；CosyVoice，专注于自然语音生成，支持多种语言、音色、风格和身份控制。<br/><br/>3. 提供了低延迟ASR服务（如SenseVoice-Small针对5种语言），以及高精度ASR服务（如SenseVoice-Large适用于超过50种语言）。<br/><br/>4. FunAudioLLM模型家族的源代码已开源，包括ModelScope和HuggingFace平台上的模型，以及训练、推理和微调的代码。<br/><br/>通过这些贡献点，FunAudioLLM模型家族为语音交互技术提供了新的工具和能力。 |
| [Improving Speech Enhancement by Integrating Inter-Channel and Band Features with Dual-branch Conformer](https://arxiv.org/abs/2407.06524) | 1. 提出了一种名为channel-aware dual-branch conformer(CADB-Conformer))的新型双分支架构，用于探索不同通道之间的长范围时间频率相关性。<br/><br/>2. CADB-Conformer有效地提取了具有通道关系意识的时间频率信息，这在语音增强中非常重要。<br/><br/>3. 通过在DNS-Challenge 2020数据集上进行的ablation studies，证明了利用通道特征的重要性，并展示了通道关系意识的时间频率信息对于语音增强的有效性。<br/><br/>4. 实验结果还显示，提出的模型在性能上超越了近期的一些方法，并且具有吸引人的计算成本。 |
| [SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis](https://arxiv.org/abs/2407.07728) | 1. 提出了一种端到端的特征解耦模型，名为SaMoye，用于实现零样本多对多歌唱声音转换。<br/><br/>2. SaMoye通过分别分离歌唱声音的特征为内容特征、音色特征和音高特征。 <br/><br/>3. 为了增强内容特征，使用基于GPT的模型进行跨预测，与歌词中的音素相关联。<br/><br/>4. SaMoye能够生成带有转换声音的音乐，只需将目标歌手的音色特征替换回去即可。<br/><br/>5. 为保证零样本性能，建立了前所未有的大规模数据集。这个数据集包含1500万纯歌唱声片段，涵盖了至少10万个不同歌手。 |
