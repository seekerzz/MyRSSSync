# 五里墩茶社
---
| Title | Date | Summary |
| --- | --- | --- |
# 小工蚁创始人
---
| Title | Date | Summary |
| --- | --- | --- |
# AIGCLINK
---
| Title | Date | Summary |
| --- | --- | --- |
# 技术爬爬虾
---
| Title | Date | Summary |
| --- | --- | --- |
# 秋芝2046
---
| Title | Date | Summary |
| --- | --- | --- |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Towards Attribution of Generators and Emotional Manipulation in Cross-Lingual Synthetic Speech using Geometric Learning](https://arxiv.org/abs/2511.10790) | 该论文的贡献点如下：<br/><br/>1. **问题提出**：论文关注于从合成操纵语音中精确追踪情感和操纵特征的问题，这是一个音频领域中的挑战性课题。<br/><br/>2. **假设验证**：提出了一个假设，即通过结合由Speech Foundation Models (SFMs)捕捉的语义-声调线索以及来自听觉表示的精细频率动态，可以实现对情感和操纵来源更精准的跟踪。<br/><br/>3. **方法创新**：介绍了MiCuNet这一新颖的多任务框架，用于在合成生成语音中进行精细的情感和操纵属性追踪。该方法结合了SFM嵌入与基于频谱图的听觉特征，并通过混合曲率投影机制来整合这些信息，该机制由可学习的时间门控机制指导，跨越超椭圆、欧几里得和球形空间。<br/><br/>4. **实验设计**：采用了一种多任务学习配置，在EmoFake数据集（EFD）的英汉子集中同时预测原始情感、操纵后的情感以及操纵来源。这种方法能够对原声情绪、操控性情绪和操控源进行预测。<br/><br/>5. **结果验证**：MiCuNet在实验中展现出稳定的优势，持续超越传统的融合策略。这是首次探索特别针对合成语音中的多任务追踪的曲率自适应框架的研究报告。 |
| [Curved Worlds, Clear Boundaries: Generalizing Speech Deepfake Detection using Hyperbolic and Spherical Geometry Spaces](https://arxiv.org/abs/2511.10793) | 贡献点:<br/>1. **跨生成器类型的一致性检测框架**：论文提出了一种名为RHYME的统一音频深度伪造检测框架，旨在解决在不同语音合成范式（包括传统文本到语音(TTS)系统和现代扩散或流匹配(FM)基于的生成器）之间的通用化问题。该框架通过几何意识建模来识别，尽管不同生成方式可能产生特定的生成艺术特征，但合成语音在其嵌入空间中仍留下的共享结构扭曲可以被对齐。<br/><br/>2. **非欧几里得投影融合**：RHYME通过使用非欧几里德投影将来自多种预训练语音编码器的单个级嵌入融合。这种方法使得能够用在不同的几何空间（如超球面和双曲空间）中表示信息，并利用这些空间的独特特性进行检测。<br/><br/>3. **几何优化映射**：该论文使用了特殊的几何空间，包括双曲空间和球形投影，来表示合成语音的特征。其中，双曲几何擅长于捕捉生成器家族之间的层次关系，而球面投影则能够捕获诸如周期性波形编码器产生的角度和能量不变的线索。<br/><br/>4. **里emannian巴氏平均融合**：RHYME通过RIEMANNIAN巴氏平均化方法来获得融合表示。这种技术允许在合成语音中保持不变的对齐，即使生成方式不同也能实现一致性的检测。<br/><br/>5. **性能提升与新前沿**：实验结果显示，RHYME不仅优于个体预训练模型（PTMs）和同质融合基线，在跨范式音频深度伪造检测任务上实现了最佳性能，并且还开创了新的状态最前沿。 |
| [Synthetic Voices, Real Threats: Evaluating Large Text-to-Speech Models in Generating Harmful Audio](https://arxiv.org/abs/2511.10913) | ### 贡献点:<br/><br/>1. **研究焦点转变** - 论文将现代文本到语音(TTS)系统的安全性关注从模仿特定说话者身份转向内容安全,探索使用TTS生成含有有害信息的威胁。<br/><br/>2. **两大挑战概述** - 提出并讨论了利用大型音频语言模型(LALMs)构建的TTS系统面临的两个主要挑战: <br/>   a) 安全对齐问题，即LALM在处理有害提示时经常被拒绝。<br/>   b) 实际部署管道中常使用的输入/输出过滤器可以阻拦有害文本和音频。<br/><br/>3. **HARMGEN攻击套件** - 提出了一套由五种攻击组成的HARMGEN套件,分为两个家族来解决上述挑战:<br/>   a) 采用语义混淆技术(Concat、Shuffle),将有害内容巧妙地隐藏在文本中。<br/>   b) 利用音频模态的漏洞(Read、Spell、Phoneme),通过辅助音频通道注入有害信息同时保持文本提示的无害性。<br/><br/>4. **跨商业TTS系统评估** - 在五个基于LALM的商业级TTS系统以及三种覆盖两种语言的数据集上进行了全面评估,证明了HARMGEN攻击显著降低了拒绝率并增加了生成语音的毒性。<br/><br/>5. **反制措施分析** - 对音频流媒体平台使用的反应性对策和TTS提供商实施的预防性防御进行了评估。发现深层伪造检测在高保真度音频中表现不佳、反应式管理可被对抗扰动规避,而主动管理能够识别57%-93%的攻击。<br/><br/>6. **内容为中心的滥用向量** - 强调了对TTS系统内容安全性的未充分探索，并强调在整个训练和部署过程中需要建立强大的跨模态防护措施。 |
| [Proactive Hearing Assistants that Isolate Egocentric Conversations](https://arxiv.org/abs/2511.11473) | 贡献点如下：<br/><br/>1. **主动听觉助手的引入**：论文提出了一种自动识别和分离佩戴者对话伙伴的听觉辅助系统，无需明确提示。这一创新旨在为用户提供更加自然、直观的互动体验。<br/><br/>2. **基于自发言话的系统**：该系统利用佩戴者的自我发言作为锚点进行工作，通过分析谈话中的轮流行为和对话动态来推断对话伙伴并抑制其他声音。<br/><br/>3. **实时、离线操作的双模型架构**：为了实现低延迟的实时操作，论文提出了一种双模型结构。一个轻量级流式模型每12.5毫秒运行一次，用于快速提取对话伙伴；另一个较慢的模型则周期性地运行以捕捉更广泛的对话动态。<br/><br/>4. **实际场景下的测试和验证**：通过在真实的二至三发言者对话场景中收集的数据集（由11名参与者总共6.8小时的binaural egocentric硬件数据）进行实证研究，论文验证了系统的泛化能力，在多通话环境中的识别与隔离对话伙伴的能力。<br/><br/>5. **主动适应性听觉助手**：这项工作为听觉辅助系统向着能够主动适应并响应对话动态和参与度的方向迈出了一步。这标志着在自适应性和个性化交互方面的一次重要进展，为进一步提升用户体验提供了可能的解决方案。 |
| [CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition](https://arxiv.org/abs/2506.06071) | 贡献点:<br/><br/>1. **提出CO-VADA方法**: CO-VADA是一种基于信心的语音增强去偏方法，旨在通过识别和转换训练数据中的代表性样本来减轻演讲者特征与情绪标签之间的不相关关联导致的情感识别系统中的偏见。<br/><br/>2. **无需模型特定改变或依赖人口统计信息**：与其他许多去偏方法不同，CO-VADA不需要对模型架构进行修改或依赖于特定的人口统计数据标注，这使得该方法在实践中更为灵活和实用。<br/><br/>3. **利用语音转换技术**：通过应用语音转换来调整无关属性并生成样本，以此来改变训练数据中主导模式的演讲者特征。这种方法引入了与现有数据中的主导模式不同的讲者变异性，引导模型更多关注于情感相关的特性。<br/><br/>4. **广泛的兼容性与可扩展性**：CO-VADA框架可以与多种情感识别（SER）模型和语音转换工具相集成，使其成为改善情感识别系统公平性的规模化且实用的解决方案。<br/><br/>5. **改进情感识别系统的公平性**：总体而言，该方法旨在通过减轻由训练数据中存在的偏见引起的不公平预测，提高情感识别系统的整体公平性。 |
| [SPUR: A Plug-and-Play Framework for Integrating Spatial Audio Understanding and Reasoning into Large Audio-Language Models](https://arxiv.org/abs/2511.06606) | 贡献点:<br/>1. **提出SPUR（Spatial Perceiving Unified Retrofitting）**: 一种轻量级、模块化的方法，旨在通过最小的架构调整为大型音频语言模型(LALMs)提供空间感知能力。<br/>2. **First-Order Ambisonics (FOA) 编码器**: SPUR引入了用于映射(W, X, Y, Z)通道到旋转意识和以听众为中心的空间特征的第一阶Ambisonics编码器，这将这些功能整合到目标LALMs中通过一个多模态适配器。<br/>3. **SPUR-Set空间问答数据集**：该数据集结合了开放源代码FOA录音与受控模拟，着重于相对方向、高度、距离和重叠等元素，以用于监督的空间推理。<br/>4. **在SPUR-Set上的微调改进**: 在此数据集上对模型进行微调能够一致地提高空间问答(Q&A)能力和多说话者归属（speaker attribution），同时保持一般音频理解能力的完整性。<br/>5. **SPUR方法的有效性验证**：通过广泛的消融实验，证明了该方法的有效性和效率。 |
| [MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification](https://arxiv.org/abs/2506.11331) | ### 贡献点:<br/><br/>1. **MUDAS框架的引入**: 为了解决现有领域适应算法在多标签任务和资源受限的物联网设备上的局限性，本文提出了Mote-scale Unsupervised Domain Adaptation for Sounds (MUDAS)，这是一种专用于资源受限的IoT环境中的多标签声音分类的无监督域适应框架。<br/><br/>2. **低功耗本地化模型更新**: MUDAS通过在就地选择性重新训练分类器并使用高置信度的数据，有效减少计算和内存需求，使其更适合于设备上的部署。这种策略帮助降低了对计算资源的需求，并确保了模型能够在有限的硬件条件下运行。<br/><br/>3. **类特定自适应阈值的引入**: 为了生成可靠伪标签，MUDAS采用了类特定的自适应阈值方法。这种方法能够提高模型对新环境数据分布变化的鲁棒性，并在多标签分类任务中提供更准确的结果。<br/><br/>4. **多样性正则化用于改善多标签准确性**: MUDAS通过应用多样性的正则化来提升多标签分类性能，这有助于在保持模型泛化能力的同时，优化针对不同类别的预测准确性。<br/><br/>5. **实际场景验证与比较**: 通过在纽约市多个地点记录的SONYC Urban Sound Tagging (SONYC-UST)数据集上进行评估，MUDAS展示了相较于现有无监督域适应算法在分类准确度上的显著提升，并证明了其在资源受限的IoT设置下的有效性和性能。 |
| [Enhancing the NAO: Extending Capabilities of Legacy Robots for Long-Term Research](https://arxiv.org/abs/2509.17760) | ### 贡献点:<br/><br/>1. **新型NAO机器人的开发**: 提出了一个升级版的NAO机器人，即"Enhanced NAO"，旨在通过集成增强的定向麦克风、RGB-D摄像头和热像仪等现代传感器技术，以及额外的计算资源来提升其研究用途。<br/><br/>2. **整合云基与本地模型**: 该系统结合了基于云端和本地的感知及对话模型，同时保持了NAO机器人的表达性身体和行为特征，实现功能增强而不影响原有的互动体验。<br/><br/>3. **用户对话性能验证**: 在一项试点用户研究中验证了Enhanced NAO在对话性能方面的表现，结果显示其在对话质量上显著高于NAO AI Edition，并且没有增加响应延迟。这证明了升级版本的卓越性和优势。<br/><br/>4. **建立感知驱动交互的基础**: 通过新增视觉和热像仪模态，为未来基于感知的机器人交互奠定了基础，增强了机器人的环境适应能力和用户交互体验。<br/><br/>5. **延长老化机器人研究寿命的框架**: 提供了一个平台中立的方法来扩展老旧机器人（Legacy robots）的研究适用性和生命周期，确保它们继续作为有价值的人机互动工具存在。这一方法可以广泛应用于其他老化的机器人平台，促进其持续在科学研究和应用领域发挥作用。 |
| [Golden Tonnetz](https://arxiv.org/abs/2509.21428) | ### 贡献点:<br/><br/>1. **音乐与几何学的结合** - 论文探索了音乐中七个音符在金三角形上的排列方式, 这种排列能够代表特定的大调或小调以及它们的主要和弦、主导和次级和弦。这展示了音乐理论与几何形状之间的联系。<br/><br/>2. **金色托内兹图的提出** - 根据上述发现，论文提出了“金色托内兹图”，这是一种使用金三角形或圭表来表示所有大调和小调以及三和弦的方法。这种方法提供了对旋律、平行和邻音交换等新里曼理论转换的一种视觉化理解。<br/><br/>3. **音乐转换的几何表示** - “金色托内兹图”不仅表示了音乐中的静态结构（如调性和三和弦），还通过金三角形和圭表之间的变换来描绘了音乐理论中的一些动态变化，包括相对、平行及邻音交换等。<br/><br/>4. **数理美学与音乐学的融合** - 论文揭示了数学中的菲波那切序列、黄金分割比等概念在音乐结构分析中的应用，表明了数理美学对理解音乐理论的独特贡献。<br/><br/>5. **跨学科研究的新视角** - 最后，这项工作提供了一个将音乐理论和几何学结合的新视角。通过引入“金色托内兹图”，它拓宽了音乐与数学、尤其是几何之间的联系领域，并可能激发未来在跨学科研究中的更多创新探索。 |
| [Melodia: Training-Free Music Editing Guided by Attention Probing in Diffusion Models](https://arxiv.org/abs/2511.08252) | 贡献点如下：<br/><br/>1. **深入分析音乐编辑中的注意力映射**：对音频LDM（AudioLDM）2中基于扩散的模型进行深入探究，揭示了交叉注意力映射和自我注意力映射在音乐特性和时间结构保留方面的不同作用。<br/><br/>2. **提出Melodia技术**：设计出一个无需训练的技术（Melodia），它在去除噪声的过程中选择性地操作特定层中的自我注意力映射，并利用注意力存储库来存储源音乐信息，以实现对音乐特性的精确修改同时保持原始结构的完整性，且不需要文本描述源音乐。<br/><br/>3. **引入新的评估方法**：提出两种新型的度量标准（指标），用于更全面地评估音乐编辑方法，不仅考虑到客观数据，还考虑了主观感受和整体结构的一致性。<br/><br/>4. **实验验证**：通过多项客观和主观实验表明，Melodia技术在不同数据集上都能提供更好的文本一致性、结构完整性表现，并与现有音乐生成模型的内部机制的理解相辅相成，提供了改进的音乐创作控制。 |
