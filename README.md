# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [nlohmann/json](https://github.com/nlohmann/json) | 这段文字是关于如何执行JSON单元测试的说明。首先，需要在构建目录下执行`mkdir build`和`cd build`命令。<br/><br/>然后，使用CMake配置器来编译代码，并通过 `-DJSON_BuildTests=On`选项来包含测试。如果需要下载测试数据集，可以添加 `-DJSON_TestDataDirectory=path`到CMake命令中。<br/><br/>在运行测试时，可能会遇到一些失败的测试，如“test case: check test suite is downloaded”失败。这可能是因为某些库或文件被修改导致的不一致。解决这类问题的方法是执行特定的清理步骤，或者跳过这些失败的测试。<br/><br/>最后，如果使用的是Intel的C++编译器，并且默认开启了不安全的浮点优化，可能会导致单元测试失败。这时需要通过`/fp:precise`选项来关闭这种优化。<br/><br/>总结起来，这段文字提供了关于如何配置和运行JSON单元测试的详细步骤和注意事项。 |
| [siyuan-note/siyuan](https://github.com/siyuan-note/siyuan) | SiYuan笔记是一个开源项目，用户可以创建、编辑和存储笔记。以下是关于如何升级数据repo key丢失时的处理步骤以及是否需要付费的信息概要：<br/><br/>1. **找回丢失的key**：<br/>   - 如果之前正确配置了多个设备并确保钥匙一致，可以在  <kbd>Settings</kbd>  ->  <kbd>About</kbd>  ->  <kbd>Data repo key</kbd>  ->  <kbd>Copy key string</kbd> 处复制并粘贴钥匙字符串。<br/><br/>   - 如果所有设备都无法访问或无法获取钥匙，可能需要手动备份数据。可以使用  <kbd>Export Data</kbd> 或直接复制  <code>workspace/data/</code> 文件夹到文件系统中。<br/><br/>2. **初始化新的数据repo**：<br/>   - 在一个设备上初始化新的数据repo key。初始化后，其他设备会导入这个新钥匙。<br/><br/>3. **删除旧的云同步目录和备份**：<br/>   - 旧的云同步目录不再可用并应删除。这可能包括在云存储服务中查找并删除相关文件夹。<br/><br/>4. **清理旧的云备份**：<br/>   - 如果之前有使用云备份功能，确保已清除所有旧备份。这通常可以在云存储服务的管理界面中完成。<br/><br/>关于付费问题，大部分SiYuan的功能是免费提供的，即使用于商业用途也是如此。但某些高级或定制化的服务可能需要付费才能使用。具体价格信息可以参考SiYuan官方网站的定价页面。 |
| [KenneyNL/Adobe-Alternatives](https://github.com/KenneyNL/Adobe-Alternatives) | 这段内容是关于几种视频和图形处理工具的介绍。以下是主要内容摘要：<br/><br/>1. **特效工具**：<br/>   - **Natron**：一款开源的合成软件，适用于Windows, Mac, Linux系统。<br/>   <br/>2. **运动图形工具**：<br/>   - **Blender**：一款多用途的3D创作软件，支持Windows, Mac, Linux系统。<br/>   <br/>3. **专业视频编辑工具**：<br/>   - **Final Cut Pro (Motion)****:** 作为Mac和iOS平台的专业视频剪辑工具，Final Cut Pro专用于运动图形设计。<br/><br/>4. **其他安全锁定的工具**：<br/>   - **Cavalry**：一个可能针对Windows和Mac操作系统的视频处理软件。<br/>   - **Rive**：一款在浏览器中运行的视频交互工具，适用于Windows, Mac系统。<br/>   - **Jitter**：同样是一款在浏览器中使用的视频编辑工具，但未明确提及支持哪些操作系统。<br/><br/>总之，这段内容介绍了几种用于视频和图形处理的专业工具，包括它们的功能、适用平台以及一些特定软件的名字。 |
| [fingerprintjs/fingerprintjs](https://github.com/fingerprintjs/fingerprintjs) | FingerprintsJS的版本政策、浏览器支持以及获取技术支持的方式进行了详细的说明。对于想要贡献代码或者使用库的开发者，还提供了具体的贡献指南。 |
| [VikParuchuri/surya](https://github.com/VikParuchuri/surya) | 这段文字是关于使用Python进行图像处理和布局分析的详细指南。它还提到了训练过程，包括使用的模型和训练时间。最后，它表达了对开源AI工作贡献者的感谢。 |
| [argmaxinc/WhisperKit](https://github.com/argmaxinc/WhisperKit) | 本文主要介绍了WhisperKit，一个用于构建和训练语音模型的工具包。它支持模型搜索、创建模型、部署到HuggingFace等操作。<br/><br/>文章还提到了Swift CLI，一个用于在本地环境中快速测试和调试WhisperKit功能的工具。此外，文中还提供了贡献指南和许可证信息，以帮助开发者了解如何参与项目并使用代码。 |
| [onevcat/Kingfisher](https://github.com/onevcat/Kingfisher) | 这段文字是关于Kingfisher项目的一段介绍。Kingfisher是一个轻量级的开源框架，专注于提供简单易用的图片下载和缓存功能。开发者鼓励用户支持这个项目，可以通过GitHub Sponsors进行赞助。<br/><br/>此外，这段文字还提到了一些特别感谢的对象，以及Kingfisher的许可证信息——MIT许可，详细内容在LICENSE文件中。 |
| [iree-org/iree](https://github.com/iree-org/iree) | IREE（IREE Runtime Environment）是一个开源项目，其主要目标是提供一个运行在多种硬件平台上的通用计算框架。这个架构基于Apache 2.0 License和LLVM Exceptions许可，并且提供了详细的许可证信息。<br/><br/>简而言之，IREE是一个跨硬件平台的通用计算框架，它遵循特定的开源许可协议。 |
| [cocos/cocos-engine](https://github.com/cocos/cocos-engine) | 这段文字是关于Cocos Creator引擎的，它是一个开源的3D游戏开发平台。引擎提供了丰富的功能模块，如动画系统、物理系统、粒子系统等，开发者可以通过这些模块快速构建游戏场景。<br/><br/>此外，这段话还提到了一些项目示例和文档资源，开发者可以参考这些来学习如何使用Cocos Creator进行游戏开发。<br/><br/>总的来说，这段文字是为那些想要学习或已经在使用Cocos Creator引擎的开发者提供的一份详细介绍。 |
| [Mbed-TLS/mbedtls](https://github.com/Mbed-TLS/mbedtls) | 这篇文档是关于Mbed TLS（一个用于安全通信的库）的。它包含了如何报告安全漏洞、提交bug请求或寻求功能扩展的信息。<br/><br/>首先，对于报告安全漏洞，提供了邮件地址，并解释了详细流程。<br/><br/>其次，对于报告bug或需求，鼓励用户在GitHub上创建新问题来提交。<br/><br/>最后，文档还提到了支持渠道，除了上述方式外，还有其他讨论和获取帮助的途径。<br/><br/>总的来说，这篇文档是Mbed TLS项目管理、贡献指南以及寻求技术支持的重要参考。 |
| [alibaba/higress](https://github.com/alibaba/higress) | Higress是一个基于Envoy和Istio开源工作的微服务网关。它提供了丰富的可观测性，支持多种服务发现机制，包括K8s Service。<br/><br/>此外，Higress还具有强大的路由能力，可以根据定义的域名、匹配规则以及目标服务进行路径配置。<br/><br/>社区方面，Higress项目提供了感谢Envoy和Istio开源贡献的平台，并且有交流群供用户互动和技术分享。<br/><br/>总之，Higress是一个功能强大、易于扩展的微服务网关解决方案。 |
| [firecracker-microvm/firecracker](https://github.com/firecracker-microvm/firecracker) | 本文是关于Firecracker微VM项目的信息。主要讲述了Firecracker的性能、安全政策、常见问题联系方式以及在社区交流时应遵守的代码准则等内容。对于关注容器和函数工作负载在服务器端运行模型的人来说，这些信息是有价值的。 |
| [electron/electron](https://github.com/electron/electron) | 本文是关于Electron（原名ChromiumElectron）的详细信息，包括其用途、快速开始指南、资源学习路径以及社区支持等内容。对于开发者来说，它提供了如何在Node应用中使用Electron的方法和链接。同时，文章还提到了Electron的许可证——MIT，并提醒在使用Electron标识时应遵循的政策。 |
| [danielmiessler/SecLists](https://github.com/danielmiessler/SecLists) | SecLists 是一个安全测试者的伴侣项目，它收集多种类型的列表，用于在安全评估中使用。这些列表类型包括用户名、密码、URL、敏感数据模式、 fuzzing 负载、web shell等。<br/><br/>项目的目标是让安全测试者能够在一个新的测试盒上轻松获取所需的列表资源。<br/><br/>此外，SecLists 还提供了贡献指南和类似的项目列表，以帮助社区成员参与项目的维护和发展。 |
| [mandiant/capa](https://github.com/mandiant/capa) | 本文介绍了Mandiant的Capa工具，包括其功能、API使用、与IDA Pro的集成以及相关的博客文章。同时提到了Capa规则库和测试文件库，供用户参考和测试。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [瞬间引流11万+人，爆火的「听泉鉴宝」让小众商家蹭爽了](https://www.36kr.com/p/2997609325391745) | 这段内容是关于电商流量昂贵的现象分析，并提到了品牌为了GMV和利润而采取的互动策略。同时，文章还预测了电商操盘手可能需要学习与直播主播互动的新技巧。总结来说，主要内容围绕电商流量成本上升、品牌互动策略以及电商运营新趋势展开讨论。 |
| [中国没有一家正宗的肯德基？](https://www.36kr.com/p/2997521203768964) | 这篇文章讨论了中国快餐品牌如肯德基、麦当劳以及本土品牌在应对中国市场变化时的表现。文章指出，随着中国消费市场的增长和消费者需求的多样化，洋品牌的中国化策略显得尤为重要。同时，文章还提到了一些本土品牌在中国市场上的成功案例。 |
| [曝通信大厂中国裁员近2000人](https://www.36kr.com/p/2997473593433990) | 诺基亚在大中华区裁员近2000人，占该区域员工总数的约20%，并计划在欧洲再裁员350人。此举是为了降低成本，根据诺基亚的年报数据，该公司目前在全球范围内拥有一定数量的员工。此外，诺基亚还在积极开拓印度市场，与当地电信运营商进行合作洽谈。 |
| [「卷王」刘旸，放弃完美](https://www.36kr.com/p/2997568339242627) | 《喜人奇妙夜》中的刘旸，从一个不善于社交，生活安排上显得有些被动的人，逐渐变得积极主动，甚至在喜剧领域取得了成就。<br/><br/>他通过参加喜剧综艺节目，不仅被更多人看到，还获得了包括徐峥在内的导演的邀请，担任新电影编剧。这个过程中，他克服了紧张和不自信，学会了如何在压力下成长，并且他的喜剧事业也因此得到了提升。<br/><br/>总的来说，刘旸的故事展示了一个人如何通过努力和积极的态度，改变自己的生活轨迹，实现自我价值的过程。 |
| [双11瞄准“会花钱的年轻人”](https://www.36kr.com/p/2997444623888256) | 这篇文章的摘要如下：<br/><br/>今年双11，各大电商平台呈现出与以往不同的景象。商家和平台不再盲目追求低价内卷，而是开始尝试更健康、可持续的发展模式。<br/><br/>在供给端，平台通过降低商家门槛、升级工具和服务等方式，帮助商家提升运营效率和用户体验。京东推出官方智能客服机器人等服务，拼多多则推出百亿减免计划以支持商家发展。<br/><br/>从大环境看，中国零售总额增速正在缓慢复苏，双11预售开启后家电、美妆和服饰品类销售大涨。这表明消费者对高品质商品和服务的需求依然强劲。<br/><br/>总结来说，今年双11呈现出平台与商家之间更加平衡、可持续发展的趋势。这种变化预示着未来消费市场将更加注重品质与服务的提升。 |
| [我在广州做酒店代订，年入百万](https://www.36kr.com/p/2997424613715845) | 这段内容看起来像是某个人在微信公众号上的一篇关于酒店代订的聊天记录摘要。<br/><br/>首先，G总提到可以通过帮助升级会员等级来获得白金会员的机会，这表明他可能是在提供某种服务，如会员升级服务。<br/><br/>其次，G总提到了代订利润和管控难度的问题，这显示他在讨论如何有效管理代订业务以获取利润。<br/><br/>最后，G总试图通过提供白金会员的优惠来吸引潜在客户，这体现了他的商业策略。<br/><br/>总结来说，这段摘要涉及酒店代订的业务管理、会员升级服务以及营销策略等内容。 |
| [非法测绘，危害为啥这么大？](https://www.36kr.com/p/2997316071992965) | 这段文字是关于一个境外企业以汽车智能驾驶研究为掩护，进行非法测绘的事件。事件被央视新闻报道，并对国内智驾发展可能产生的影响进行了讨论。<br/><br/>如果需要更具体的咨询摘要，可以基于以下几点进行提炼：<br/><br/>1. 事件主体：境外企业及其从事的研究。<br/>2. 行为性质：非法测绘，以研究为掩护。<br/>3. 影响范围：国内智驾领域的发展可能受此影响。<br/>4. 央视新闻报道：作为权威媒体的报道，此事具有一定的社会关注度。<br/><br/>根据以上信息，您可以选择需要摘要的关键点进行提炼。 |
| [中东白领喝起库迪，中国咖啡品牌进击全世界](https://www.36kr.com/p/2997339623206787) | 这篇文章主要讲述了咖啡品牌库迪在中东地区出海的策略和市场表现。库迪通过提供符合当地口味的产品调整，试图抓住中东咖啡消费市场的特点。<br/><br/>文章提到，库迪的菜单并未针对中东进行大规模口味调整，仍然以国内流行的“奶咖”为主。这表明库迪在产品本地化方面还有待加强。<br/><br/>此外，文章还提到了库迪想要通过低价策略和中东市场下沉来获取竞争优势，但这一过程可能比想象中更艰难。<br/><br/>总结来说，这篇文章分析了库迪在中东咖啡市场的表现以及其出海策略的局限性。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Exploiting Longitudinal Speech Sessions via Voice Assistant Systems for Early Detection of Cognitive Decline](https://arxiv.org/abs/2410.12885) | 1. 提出一项长期研究，使用语音助手系统（VAS）远程收集七次会话的语音数据，每隔三个月在18个月内进行。<br/><br/>2. 提出两种方法来改进MCI（轻度认知障碍）检测和预测认知变化。第一种方法利用历史数据，第二种方法则预测在两个时间点的认知变化。<br/><br/>3. 结果表明，当使用历史数据时，MCI检测的平均F1分数有所提高：对于声学特征，从58.6%提升到71.2%(提升了12.6%)；对于语言特征，从62.1%提升到75.1%(提升了13.0%)。<br/><br/>4. 此外，预测认知变化的F1分数也有所提高：在声学特征下达到73.7%。这些结果证实了基于VAS的语音会话对于早期识别认知衰退的潜力。 |
| [AI-Enhanced Acoustic Analysis for Comprehensive Biodiversity Monitoring and Assessment](https://arxiv.org/abs/2410.12897) | 1. 提出开发全面实时的生物多样性监测系统，该系统通过网络连接的声学传感器收集声音数据。<br/><br/>2. 系统将分析来自不同生态系统的声音记录，以识别和分类不同的物种，从而提供关于生态系统健康和生物多样性模式的有价值信息。<br/><br/>3. 该系统旨在解决噪音污染和物种重叠等关键挑战，通过先进的过滤和分类技术确保监测结果的准确性和可靠性。<br/><br/>4. 最终目标是增强对生物多样性动态的理解，并为支持有效的保护策略和政策决策提供必需的信息，从而赋能各利益相关者以实际行动来保护和维护至关重要的生态系统。 |
| [Multi-View Multi-Task Modeling with Speech Foundation Models for Speech Forensic Tasks](https://arxiv.org/abs/2410.12947) | 1. 本研究提出了一种多任务学习策略，用于解决语音 forensic 任务（SFTs）中的独立模型构建问题。<br/><br/>2. 研究者探索了多种先进的语音基础模型（SFM），通过提取它们的表示进行学习，并针对每个任务具体分析其有效性。<br/><br/>3. 他们还分析了这些提取的表示在多任务学习框架下的性能。结果表明，当将不同的SFTs一起建模时，性能会下降，这与单独构建特定任务模型的情况相比更为明显。<br/><br/>4. 因此，研究者提出了一种名为MVL（Multi-View Learning）的方法来解决这个问题，通过整合不同SFMs的多维表示来捕捉跨任务的互补信息。<br/><br/>5. 他们还引入了一个新的框架TANGO（Task Alignment with iNter-View Gated Optimal transport）来实现这个方法。在TANGO中，他们实现了最佳性能，不仅超越了单个SFM的表示，而且也超越了基础融合技术。 |
| [Using RLHF to align speech enhancement approaches to mean-opinion quality scores](https://arxiv.org/abs/2410.13182) | 1. 提出问题：论文指出传统的客观语音质量衡量指标在作为学习目标时存在不足，它们与人类主观评价的不一致性可能导致明显的失真和 artifact。<br/><br/>2. 解决方案：为解决这些问题，作者提出一个基于人类反馈的强化学习（RLHF）框架，用于微调现有的语音增强方法，通过优化性能来利用基于平均意见得分（MOS）的奖励模型。<br/><br/>3. 实验结果：实验结果显示，经过RLHF微调的模型在Voicebank+DEMAND数据集上对客观和基于MOS的语音质量评估指标具有最佳性能。<br/><br/>4. 模型优化：论文通过ablation研究展示了政策梯度损失和监督mse损失对于平衡不同指标的优化都是重要的。 |
| [Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](https://arxiv.org/abs/2410.13198) | 1. 提出问题：论文指出GEC模型在训练时遇到的特定错误类型限制了它们在测试时纠正新、未见过错误的能力，特别是在OOD场景中。<br/><br/>2. 解决方案：为解决这个问题，作者提出了DARAG（Data- and Retrieval-Augmented Generative Error Correction）这一方法。DARAG通过增加GEC训练数据集，使用大型语言模型和文本转语音模型生成模拟新错误的数据，来增强模型的泛化能力。<br/><br/>3. 适用场景：DARAG不仅适用于ID场景，还能在OOD环境下发挥作用，因为它能够模拟来自不同领域的测试时错误。<br/><br/>4. 简单性、可扩展性和通用性：DARAG设计简单，易于实施，并且具有良好的可扩展性。此外，它不受特定领域或语言的限制，具有一定的通用性。 |
| [Investigating Effective Speaker Property Privacy Protection in Federated Learning for Speech Emotion Recognition](https://arxiv.org/abs/2410.13221) | 1. 研究领域：针对Federated Learning (FL)在Speech Emotion Recognition (SER)中的应用，探讨其在财产信息推理攻击下的安全性。<br/><br/>2. 方法创新：提出一种新颖的方法来保护语音数据中的财产信息。这种方法通过分解声音中的各种属性，并对这些属性添加扰动来实现。<br/><br/>3. 实验验证：通过实验验证了所提出的保护方法在隐私-效用权衡方面优于现有方法，能够更有效地防止攻击同时保持相似的FL性能水平。<br/><br/>4. 应用前景：该研究对于未来语音处理领域的隐私保护技术发展具有指导意义。 |
| [DurIAN-E 2: Duration Informed Attention Network with Adaptive Variational Autoencoder and Adversarial Learning for Expressive Text-to-Speech Synthesis](https://arxiv.org/abs/2410.13288) | 1. 提出DurIAN-E 2，这是一个改进的DurIAN-E模型，用于表达性和高保真度的文本到语音合成。<br/><br/>2. 模型利用多层基于SwishRNN的Transformer块作为语言编码器，同时引入Style-Adaptive Instance Normalization（SAIN）层进行帧级编码器，以增强表达性建模能力。<br/><br/>3. 研究受到其他TTS模型如VITS的影响，DurIAN-E 2利用了变分自编码器（VAEs）增强，并结合正常流和BigVGAN波形生成器，采用对抗训练策略，进一步提升合成语音的质量和表达力。<br/><br/>4. 结果证明，DurIAN-E 2在表达性TTS领域具有更好的性能表现，超越了包括DurIAN-E在内的多个最先进的方法。 |
| [DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech](https://arxiv.org/abs/2410.13342) | 1. 提出针对带有口音的文本到语音合成（TTS）的新方法。<br/>2. 利用多级变分自编码器（ML-VAE）和向量量化（VQ）来改进模型的灵活性和个性化能力。<br/>3. 解决了当前模型难以分离说话者特征和口音表示的问题，使得对合成语音的控制更加精细。<br/>4. 提供了公开可用的代码和示例音频，以支持研究和实际应用。 |
| [Enhancing Crowdsourced Audio for Text-to-Speech Models](https://arxiv.org/abs/2410.13357) | 1. 提出一种克服使用机会主义或众包数据时限制的方法。<br/>2. 实现了一个针对加泰罗尼亚语子集的Commonvoice众包数据的去噪管道。<br/>3. 管道包括音频增强阶段和选择性过滤策略。<br/>4. 开发了一种自动过滤机制，利用NISQA模型来识别并保留经过增强后的高质量样本。<br/>5. 通过训练最先进的基于扩散的文本到语音模型在处理过的数据集上，评估了这种方法的有效性。<br/>6. 结果表明，与未增强的基线数据集相比，这种方法显著提高了UTMOS分数，增加了0.4分。这为使用众包数据扩展文本到语音应用的潜力提供了证据，特别是对于资源有限的语言如加泰罗尼亚语。 |
| [On the Use of Audio to Improve Dialogue Policies](https://arxiv.org/abs/2410.13385) | 1. 提出新的对话系统架构，通过结合语音和文本嵌入使用Double Multi-Head Attention组件来增加音频信息。<br/><br/>2. 实验表明，基于音频嵌入的对话策略在性能上优于仅依赖文本的策略，特别是在噪音较大的转录场景中。<br/><br/>3. 研究指出，如何组合文本和音频嵌入对于提高性能至关重要。 |
| [STCON System for the CHiME-8 Challenge](https://arxiv.org/abs/2410.13411) | 1. 提供了STCON系统，针对CHiME-8挑战任务1（DASR）进行研究。<br/><br/>2. 系统的主要关注点在于精心训练和调校的说话人分割管道和说话人数计。<br/><br/>3. 这些措施显著降低了说话人分割错误率（DER），并获得了更可靠的段落用于语音分离和识别。<br/><br/>4. 为了改进源分离，设计了Guided Target Speaker Extraction (G-TSSE)模型，并与传统的Guided Source Separation (GSS)方法相结合使用。<br/><br/>5. 在训练系统各部分时，研究了几种数据增强和生成技术，这些技术有助于提高整体系统的质量。 |
| [GAN-Based Speech Enhancement for Low SNR Using Latent Feature Conditioning](https://arxiv.org/abs/2410.13599) | 1. 提出DisCoGAN，这是一种基于时间-频率-域的生成对抗网络（GAN），其条件由预训练在低SNR环境下语音增强的判别模型的潜在特征决定。<br/><br/>2. 该方法与现有的先进判别方法相比性能优越，并且超越了端到端（E2E）训练的GAN模型。<br/><br/>3. 研究还探讨了不同配置对使用判别模型条件生成GAN模型影响的评估，以理解它们在提升语音质量方面的具体作用。 |
| [Align-ULCNet: Towards Low-Complexity and Robust Acoustic Echo and Noise Reduction](https://arxiv.org/abs/2410.13620) | 1. 提出了一种混合方法，通过时间对齐和并行编码块整合到ULCNet模型中，以增强其性能。<br/><br/>2. 该混合方法能够实现更好的回声减少，并且在噪声减少方面与现有的最先进的方法相当。<br/><br/>3. 还提出了一个基于通道级采样-基于特征重新定向的通道分量处理方法。这种方法保证了在多种挑战性场景下都能保持稳健性能，同时保持较低的计算和内存需求。 |
| [Decoding Emotions: Unveiling Facial Expressions through Acoustic Sensing with Contrastive Attention](https://arxiv.org/abs/2410.12811) | 1. 提出FacER+，一个主动声学面部表情识别系统，它消除了对外部麦克风阵列的需求。<br/><br/>2. FacER+通过分析智能手机耳塞扬声器与三维面部轮廓之间发射的近超声波信号的回声来提取面部表情特征。<br/><br/>3. 该方法不仅减少了背景噪音，还能够从不同用户甚至戴口罩的志愿者中识别出多种表达，只需少量训练数据。<br/><br/>4. 开发了一种基于对比性外部注意力的模型，用于在不同用户间一致学习表达特征，减少分布差异。<br/><br/>5. 实验结果表明，FacER+在20名志愿者（包括戴口罩的）的大量测试中，能够准确识别六种常见面部表情，且在多种真实场景下达到超过90%的准确率，远超领先声学感应方法。 |
| [Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings](https://arxiv.org/abs/2410.12866) | 1. 该论文提出了一种新的框架H2DiLR，用于解决脑-计算机接口（BCIs）中数据异质性问题。<br/><br/>2. H2DiLR通过解耦和学习神经表示中的同质性和异质性，实现了对跨多个参与者阅读材料时的颅内电活动记录的统一处理。<br/><br/>3. 为了评估H2DiLR的有效性，研究者收集了大量包含407个音节的普通话材料的立体脑电图（sEEG）数据。<br/><br/>4. 实验结果表明，与传统的异质性解码方法相比，H2DiLR作为统一的解码框架，显著提高了神经表示学习的准确性。<br/><br/>5. 通过实证研究，进一步证实了H2DiLR能够有效地捕获和学习神经表示中的同质性和异质性。 |
| [What Do Speech Foundation Models Not Learn About Speech?](https://arxiv.org/abs/2410.12948) | 1. 该研究分析了多种主流的语音基础模型，如Whisper、Seamless、Wav2Vec、HuBERT和Qwen2-Audio，关注它们在动态-SUPERB基准下的非言语信号捕获能力。<br/><br/>2. 研究通过零样本设置评估这些模型的一般化能力，并随后对模型进行层级特征的微调，以深入理解其层间表示的特性。<br/><br/>3. 通过对层级特征的分析，研究揭示了不同模型在深度与学习表示分离度之间的关系上可能存在的模式差异。<br/><br/>4. 研究结果表明，尽管这些模型在零样本设置下表现良好，但它们并不专门针对这些任务进行训练。此外，模型的一般化能力与其层间表示的学习质量相关。<br/><br/>5. 通过分析，研究为如何优化语音基础模型的非言语信号捕获能力提供了指导，包括如何设计更有效的通用化策略以及如何利用层级特征来理解和改进模型的表示学习过程。 |
| [Towards Computational Analysis of Pansori Singing](https://arxiv.org/abs/2410.12956) | 1. 提出基于音频和对应转录的计算分析方法，对韩传统音乐中的Pansori进行深入研究。<br/><br/>2. 引入现代音乐信息检索任务到传统音乐分析中，这有助于更有效地理解和解析复杂的传统音乐形式。<br/><br/>3. 通过这种方法，揭示了Pansori音乐中不同的音频特征，为音乐学、计算机音乐和文化遗产保护等领域提供了有价值的研究成果。 |
| [MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization](https://arxiv.org/abs/2410.12957) | 1. 提出MuVi，一个用于音频-视觉内容增强的新型框架。<br/>2. MuVi通过专门设计的视觉适配器分析视频内容，提取与时间和情境相关的关键特征。<br/>3. 利用这些特征生成音乐，确保音乐不仅匹配视频的情绪和主题，还考虑其节奏和时间感。<br/>4. 介绍一种基于音乐语句周期性的对比性音乐-视觉预训练方法，以确保音乐和视频的同步。<br/>5. 实验结果表明MuVi在音频质量和时间同步方面表现出优越性能。生成的音乐视频样本可供访问。 |
| [AADNet: An End-to-End Deep Learning Model for Auditory Attention Decoding](https://arxiv.org/abs/2410.13059) | 1. 提出一种新的端到端神经网络架构，名为AADNet，用于解决AAD问题。<br/>2. 将AAD的两个阶段直接合并到一个方法中，简化了传统两步方法。<br/>3. 通过实验对比，证明了AADNet在个体特异性和独立分类模型上都表现出显著性能提升。<br/>4. 结果表明，使用不同分析窗口长度，AADNet在对未见过的个体数据进行分类时，其泛化能力得到了显著提高。<br/>5. 这些贡献点强调了深度学习模型在AAD领域的潜力，并为未来听力辅助设备、辅助技术以及临床评估提供了新的可能性。 |
| [Sound Check: Auditing Audio Datasets](https://arxiv.org/abs/2410.13114) | 1. 对于生成音频的模型，尽管其能力不断提升并被广泛应用，但关于生成音频数据集的相关伦理问题研究不足。<br/><br/>2. 作者进行了大量的文献回顾，筛选出七种最知名的音频数据集进行更深入的审计。<br/><br/>3. 发现这些数据集存在对女性偏见的问题，包含有害的少数群体刻板印象，以及大量侵犯版权的作品。<br/><br/>4. 为了帮助艺术家检查自己是否出现在流行的音频数据集中，作者开发了一个名为"audio datasets exploration tool"的在线工具，链接为https://audio-audit.vercel.app/。 |
| [EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning](https://arxiv.org/abs/2410.13179) | 1. 提出新的自我监督学习方法EH- MAM，用于语音表示学习。<br/><br/>2. 与先前使用随机掩码策略的MAM方法相比，引入了新颖的有选择性和适应性的掩码策略。<br/><br/>3. 在SSL训练过程中，逐步向模型引入更难重构的区域。<br/><br/>4. 利用MAM任务中单帧的重构损失来判断帧的难度，并据此进行掩码选择。<br/><br/>5. 通过教师模型先预测损失并决定哪些帧需要遮罩的方式，自动识别和处理更难的语音帧。<br/><br/>6. 实证表明EH- MAM在多种资源有限的语音识别任务以及SUPERB基准上优于多个最先进的基线，性能提升5%-10%。<br/><br/>7. 进行了深入分析以证明EH- MAM所掩码的区域有效地捕捉了跨帧的有用上下文。 |
| [CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models](https://arxiv.org/abs/2410.13267) | 1. 提出CLaMP 2，一个支持101种语言的系统，用于音乐信息检索。<br/><br/>2. 系统支持ABC notation和MIDI两种音乐格式。<br/><br/>3. CLaMP 2经过大规模预训练，使用1.5百万个ABC- MIDI-文本三元组进行训练。<br/><br/>4. 系统包含一个多语言文本编码器和一个多模态音乐编码器，它们通过对比学习进行对齐。<br/><br/>5. 利用大型语言模型，CLaMP 2能够生成精细、一致的多语言描述，显著降低了文本噪声并平衡了语言分布。<br/><br/>6. 实验结果表明，CLaMP 2在跨语种语义搜索和音乐分类等多个模态任务中达到了领先水平，从而为全球包容性的音乐信息检索设立了新的标准。 |
| [Roadmap towards Superhuman Speech Understanding using Large Language Models](https://arxiv.org/abs/2410.13268) | 1. 提出将语音和音频数据整合到大型语言模型中的目标，以创建能够处理文本和非文本输入的通用基础模型。<br/><br/>2. 强调了GPT-4o等先进模型的潜力，它们展示了端到端的语音语言模型的可能性，这种模型可以保留非语义信息和世界知识，有助于深度理解语音。<br/><br/>3. 提出了一条五级路线图，旨在指导语音大型语言模型的发展。这包括从基本自动语音识别（ASR）开始，逐步提升到能够整合非语义信息与抽象音频知识的高级超人类模型。<br/><br/>4. 设计了一个基准，名为SAGI Benchmark，用于标准化在这些五级任务中关键方面的评估标准，揭示了使用抽象音频知识时的挑战以及能力的完整性。 |
| [End-to-End Integration of Speech Emotion Recognition with Voice Activity Detection using Self-Supervised Learning Features](https://arxiv.org/abs/2410.13282) | 1. 提出了一种端到端（E2E）方法，该方法结合了语音活动检测（VAD）和情感识别（SER）任务，使用自监督学习（SSL）特征。<br/><br/>2. 设计了一个联合训练的框架，让VAD模块首先接收SSL特征作为输入，然后分割得到的SSL特征片段，这些片段再进入SER模块进行情感分析。<br/><br/>3. 实验结果在IEMOCAP数据集上验证了该方法的有效性，它能够提升SER性能。<br/><br/>4. 通过分析VAD输出和SSL编码器各层权重，进一步探讨了该方法对VAD和SSL模块的影响。 |
| [Enhancing 1-Second 3D SELD Performance with Filter Bank Analysis and SCConv Integration in CST-Former](https://arxiv.org/abs/2410.13328) | 1. 研究了在短时间片段场景下，带有距离估计的声学事件、位置和方向（3D SELD）系统的表现。<br/><br/>2. 特别关注了一个1秒的时间窗口，建立了实用3D SELD应用的新基准。<br/><br/>3. 进一步探讨了不同滤波银行的影响，包括Bark、Mel和Gammatone，用于音频特征提取。实验结果表明，Gammatone滤波器在该背景下实现了最高的总体准确率。<br/><br/>4. 最后，提出将CST-Former中基于卷积的模块替换为SCConv模块的建议。这种调整在短片段场景下带来了可测量的F分数增益，证明了SCConv改进空间和通道特征表示的能力。<br/><br/>5. 实验结果强调了这种方法作为实用3D SELD系统在低延迟约束下的部署道路上重要一步的重要性。 |
| [MeloTrans: A Text to Symbolic Music Generation Model Following Human Composition Habit](https://arxiv.org/abs/2410.13419) | 1. 提出问题：当前神经网络模型在音乐创作中缺乏人类的音乐性和多样性。<br/><br/>2. 研究目标：整合神经网络的学习能力与人类音乐知识，以提升音乐生成的质量。<br/><br/>3. 数据开发：开发POP909_M数据集，包含音乐动机及其变体的标签，为模仿人类创作习惯提供基础。<br/><br/>4. 模型设计：提出MeloTrans模型，该模型基于音乐动机发展规则，将文本转化为音乐。<br/><br/>5. 实验结果：通过实验对比，证明MeloTrans在音乐生成上超越了现有模型，并且甚至超过了LLMs。这强调了结合人类知识与神经网络能力的重要性。 |
| [Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR](https://arxiv.org/abs/2410.13445) | 1. 研究如何有效地结合多语言多模态模型，如SeamlessM4T，使用参数效率高的微调和文本适应方法。<br/><br/>2. 探讨了多模态模型能够利用未标注文本进行文本适应，并进一步通过参数效率的ASR微调来提升性能。<br/><br/>3. 实验展示了跨语言迁移的能力，从高资源语言中获取知识并应用到低资源语言上，实现了相对17% WER减少。<br/><br/>4. 这项研究在零样本设置下进行了，没有使用任何标注的语音数据。 |
| [Dynamic Range Compression and Its Effect on Music Genre Classification](https://arxiv.org/abs/2410.13581) | 1. 研究内容：探讨动态范围压缩（DRC）对音乐流派分类准确性的影响。<br/><br/>2. 实验方法：使用支持向量机（SVM）分类器，训练在原始、未压缩数据集上，然后将压缩设置应用于测试集以评估效果。<br/><br/>3. 结果分析：研究了阈值、比率、膝宽、攻击时间、释放时间、化妆增益等压缩参数对分类性能的影响，并计算出平均改善的分类准确率。<br/><br/>4. 意义与应用：发现DRC可以作为音乐流派分类预处理的有效手段，这有助于提升音乐推荐系统的准确性。 |
| [Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding](https://arxiv.org/abs/2410.13839) | 1. 提出一种增强的推理方法，允许在不牺牲太多语音质量的前提下加速Codec为基础的语音合成系统。<br/><br/>2. 通过预测每个AR模块步骤中的多个令牌，提出一个基于多预测头的策略，这导致线性减少的合成时间随着预测头数量的增加而增加。<br/><br/>3. 引入一种新颖的推测性解码技术，利用Viterbi算法选择在每个解码步骤中生成令牌的最佳序列。<br/><br/>4. 在实验中展示了与基线模型相比，预测每个令牌的时间减少了4到5倍，同时保持或改善语音理解能力。 |
| [Coding Speech through Vocal Tract Kinematics](https://arxiv.org/abs/2406.12998) | 1. 提出基于语音articulatory编码（SPARC）的新框架，用于神经编码-解码的语音处理。<br/><br/>2. SPARC包括两个模型：articulatory analysis model，用于从语音音频中推断 articulatory features；以及articulatory synthesis model，用于根据 articulatory features 合成语音音频。<br/><br/>3. 该研究强调了articulatory features（如唇形、舌位等）作为可直观理解和控制的物理接口的重要性。<br/><br/>4. 通过在大规模语音数据上进行训练，实现了完全理解且高质量的articulatory合成器，能够泛化到未见过的说话者。<br/><br/>5. 此框架还促进了零样本 accent-preserved voice conversion，表明其作为语音编码的强大系统。 |
| [Music to Dance as Language Translation using Sequence Models](https://arxiv.org/abs/2403.15569) | 1. 提出MDLT（Music to Dance Choreography Translation）方法，将舞蹈编排生成问题转化为翻译任务。<br/><br/>2. 利用现有的AIST++和PhantomDance数据集来学习音乐与舞蹈动作之间的转换。<br/><br/>3. 提供两种MDLT的变体：一种使用Transformer架构，另一种采用Mamba架构。<br/><br/>4. 通过评估指标如平均关节误差和Fr\'echet Inception Distance，证明MDLT在生成逼真高质量舞蹈编排方面具有优势。 |
| [Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis](https://arxiv.org/abs/2404.10299) | 1. 构建基于机器学习的睡眠评估模型，提供基于证据的评估，如因频繁移动导致的睡眠质量差。<br/><br/>2. 提取睡眠声音事件，使用VAE（变分自编码器）进行潜在表示的推导。<br/><br/>3. 利用GMM（高斯混合模型）进行聚类，以区分不同个体的睡眠状态。<br/><br/>4. 基于训练的LSTM（长短期记忆网络）进行主观睡眠评估，实现高准确度的睡眠满意度区分，如94.8%。<br/><br/>5. 使用TimeSHAP（时间解释性方法）揭示个体间影响睡眠的关键声音事件类型和时间差异。 |
| [uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation in Low-Data Regimes](https://arxiv.org/abs/2407.01257) | 1. 提出了一种无需任何标注数据的新型知识蒸馏框架。<br/>2. 实验表明，经过过滤的最好蒸馏模型在WER指标上超越教师模型5-7个百分点。<br/>3. 与相似的监督数据过滤设置相比，这些蒸馏模型性能相当或更好。<br/>4. 当扩大数据规模时，他们的模型显著优于所有零样本和监督模型。<br/>5. 证明了在不使用任何标注数据的情况下，将大型Whisper模型知识精炼到相对小型模型是可能的。 |
| [SaMoye: Zero-shot Singing Voice Conversion Model Based on Feature Disentanglement and Enhancement](https://arxiv.org/abs/2407.07728) | 1. 提出首个开源的高质量零样本声源转换模型SaMoye。<br/><br/>2. SaMoye能够实现人与非人类音色的转换，具有广泛的应用价值。<br/><br/>3. 该模型通过内容、音色和音高特征的分离来增强声源转换的准确性。<br/><br/>4. 提供了包括大量纯歌唱声音数据、6367个说话者在内的大规模零样本声源转换验证集。 |
| [DiffATR: Diffusion-based Generative Modeling for Audio-Text Retrieval](https://arxiv.org/abs/2409.10025) | 1. 从生成性视角出发，提出一种基于扩散的音频文本检索框架（DiffATR）。<br/><br/>2. DiffATR模型将音频文本检索看作是一个逐步生成联合分布的过程，从噪声开始逐步演化。<br/><br/>3. 在训练阶段，DiffATR既优化了生成器也提升了特征提取器。生成器通过生成损失进行优化，而特征提取器则受益于对比损失，从而实现了两者方法的优点结合。<br/><br/>4. 实验在AudioCaps和Clotho数据集上进行了验证，结果表明DiffATR的有效性。特别指出的是，无需任何改动，DiffATR在跨域检索场景中始终表现出强大的性能。 |
| [Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction](https://arxiv.org/abs/2410.11522) | 1. 提出利用大型语言模型(LLM)嵌入进行音乐情绪识别的新方法。<br/><br/>2. 利用LLM计算情感标签的嵌入，并通过非参数聚类对相似标签进行分组，跨多个包含不重叠标签的数据集。<br/><br/>3. 使用这些聚类中心将音乐特征（MERT）映射到LLM嵌入空间中。<br/><br/>4. 为了进一步增强模型，引入了对齐正则化，允许MERT嵌入与不同聚类分离，从而更好地适应未见过的dataset。<br/><br/>5. 实验展示了该方法的有效性，通过在新数据集上进行零样本推理，证明了其能够泛化到未知标签而无需额外训练的能力。 |
