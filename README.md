# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) | 这个仓库是一个名为LlamaFactory的项目，它提供了一种统一高效的多语言模型微调工具。这个工具集了多种先进的技术，如PEFT（普适性预训练）、TRL（任务相关学习）和QLoRA等。<br/><br/>如果你的工作涉及到语言模型的更新或优化，或者需要使用到这些先进工具，那么LlamaFactory仓库将是一个非常有价值的地方。 |
| [MervinPraison/PraisonAI](https://github.com/MervinPraison/PraisonAI) | 这段代码是一个使用Python的Praison AI库的基本示例。`basic()`函数通过`poetry install`命令来安装依赖，这通常包括文档、测试和开发相关的包。<br/><br/>如果需要创建一个新功能，例如添加一个新的文档部分，开发者会在他们自己的分支上进行这些修改，并提交一个拉取请求以供审查。<br/><br/>请注意，这段代码假设你已经在你的项目目录下。如果你还没有，你需要先通过`git clone`命令克隆项目到本地。 |
| [supabase/supabase](https://github.com/supabase/supabase) | 以下是Supabase i18n (国际化)目录的简要中文概述：<br/><br/>1. **总览**：<br/>   - "概述"：提供目录整体介绍<br/><br/>2. **语言列表**：<br/>   - "中文"：当前页面的语言版本<br/>   - "其他语言"：列出所有已翻译的Supabase语言版本<br/><br/>3. **详细内容**：<br/>   - "每种语言的详情页"：为每个已翻译的语言版本提供详细的文档和指南<br/><br/>请注意，这只是一个简要概述。实际目录可能会包含更多细节或特定语言的链接。 |
| [neondatabase/neon](https://github.com/neondatabase/neon) | Neon是一个与PostgreSQL紧密相关的数据库系统。它主要用于构建和管理服务器端的PostgreSQL数据库。<br/><br/>要加入Neon的开发，首先需要阅读并理解<CONTRIBUTING.md>文件，了解项目代码风格和实践。<br/><br/>熟悉源代码树结构可以参考<docs/sourcetree.md>文档。<br/><br/>如果想深入了解PostgreSQL内部工作原理，可以访问<http://www.interdb.jp/pg/index.html}>这个链接。<br/><br/>希望这些信息能帮助你加入Neon的开发团队。 |
| [PaddlePaddle/Paddle](https://github.com/PaddlePaddle/Paddle) | PaddlePaddle 是一个开源的深度学习框架，提供包括模型训练、推理服务等在内的完整解决方案。它遵循 Apache-2.0 协议进行开源，并且不断优化和更新以适应快速发展的AI领域。 |
| [SoftFever/OrcaSlicer](https://github.com/SoftFever/OrcaSlicer) | OrcaSlicer是一个开源的3D打印切片软件，最初是基于Bambu Studio的。它具有很多来自SuperSlicer和Marlin等项目的功能。<br/><br/>这个项目遵循GNU Affero General Public License, version 3，确保用户在任何方式使用（包括Web服务器后端）该软件时，必须以相同许可证发布他们的软件。<br/><br/>此外，Orca Slicer 还包含一个基于 Bambulab 免费库的网络插件，为 Bambulab 打印机用户提供扩展功能。 |
| [stanford-oval/storm](https://github.com/stanford-oval/storm) | 本文介绍了一种使用大型语言模型辅助用户从零开始编写类似维基百科的文章的方法。我们提供了ROUGE相似度指标、实体召回和标题实体召回等评估指标，以及使用Prometheus-13b-v1.0的评估方法。此外，我们还感谢了参与设计项目logo和UI开发的相关人员。如果你在工作中使用了我们的代码或部分功能，请记得引用我们的论文作为参考。 |
| [TabbyML/tabby](https://github.com/TabbyML/tabby) | 这段内容是关于TabbyML的Tabby项目在GitHub上的贡献历史和社区活动。具体包括项目的Twitter账号、LinkedIn页面，以及一个显示Star历史图表的链接，展示了项目在特定日期获得星标的情况。<br/><br/>如果需要更详细的解读或提取关键信息，可以进一步阅读或者向我提问。 |
| [practical-tutorials/project-based-learning](https://github.com/practical-tutorials/project-based-learning) | 本文主要介绍了几个编程语言的学习资源，包括但不限于：<br/><br/>1. **Rust**:<br/>   - 学习 Rust的博客文章：`Create a simulation of evolution using neural network and genetic algorithm, and compile the application to WebAssembly`<br/>   <br/>2. **Scala**：<br/>   - 使用Hacking with Swift学习Scala的项目：`Hacking with Swift 39 projects - Learn Swift by doing`<br/>   <br/>3. **Swift**：<br/>   - 学习Swift的第一人称射击游戏，完全从零开始：`Retro first-person shooter from scratch in Swift`<br/>   <br/>4. **额外资源**：<br/>   - 推荐网站如Udemy、Full Stack Python等提供编程课程。<br/>   - 例如ScotchIO的博客文章链接，以及提供练习和项目实战的平台如Exercism、Egghead.io等。<br/><br/>这些资源可以帮助初学者快速入门编程语言，并通过实践不断提升技能。 |
| [apify/crawlee-python](https://github.com/apify/crawlee-python) | Crawlee是一个用于Python的Web爬虫库。它提供了一种统一的接口，用于处理HTTP和头less浏览器的爬取任务。<br/><br/>Crawlee的特点包括：<br/>1. **一体化接口**：支持同时进行HTTP和头浏览器爬取。<br/>2. **简洁优雅界面**：设置爬虫代码少于10行。<br/>3. **全面类型提示覆盖**：有助于减少bug并提高代码可读性。<br/>4. **基于标准Asyncio**：基础架构易于理解和维护。<br/><br/>此外，Crawlee还支持在Apify平台上部署和运行。对于任何遇到的问题或建议，Crawlee提供了GitHub问题提交、Stack Overflow提问以及Discord服务器交流等多种途径的支持服务。 |
| [free-educa/books](https://github.com/free-educa/books) | 这个仓库是Dev-Books，一个致力于提供精选开发和编程书籍的资源库。它由名为"free-educa"的团队维护，并且所有的书籍都可以免费下载阅读。<br/><br/>此外，仓库还提供了如何使用这个资源库的方法，包括浏览话题、贡献书籍、下载阅读以及反馈建议等操作指南。<br/><br/>总的来说，这个Dev-Books仓库是一个为开发者提供高质量学习资料的平台。 |
| [ueberdosis/tiptap](https://github.com/ueberdosis/tiptap) | 这段文字是关于Tiptap Editor Core的贡献指南和贡献者的列表。它提到了如何进行贡献，包括查看详细的CONTRIBUTING文件，并指出了几个主要的贡献者名字。<br/><br/>如果需要更具体的帮助，比如了解某个具体贡献者的贡献内容或者如何参与贡献等，可以直接提问。 |
| [roboflow/supervision](https://github.com/roboflow/supervision) | 这段文字是关于一个包含多个社交媒体和知识资源链接的列表。每个链接代表一个平台，如LinkedIn（图标为一个连接的头像）和一个具体的知识或服务来源，如RoboFlow博客（图标为一个博客的图标）。<br/><br/>列表中的每个链接都可以点击以访问相应的平台或内容。这个列表可能是用于推广、链接社区成员或者提供关于RoboFlow更多信息的方式。 |
| [WordPress/gutenberg](https://github.com/WordPress/gutenberg) | 本文主要介绍了WordPress的Gutenberg项目，包括如何下载和使用Gutenberg插件，以及如何开发和贡献代码。同时提到了参与社区的方式，如Slack频道，并强调了WordPress的开源许可证——GNU General Public License version 2。总的来说，本文为WordPress的Gutenberg项目提供了全面的指导和支持。 |
| [krahets/hello-algo](https://github.com/krahets/hello-algo) | 本书致力于打造一本面向初学者的开源数据结构与算法教程。全书采用动画图解的方式，旨在让学习过程更加清晰易懂，降低入门门槛。<br/><br/>源代码部分支持一键运行，帮助读者在实践中提升编程技能，并理解算法的工作原理和数据结构底层实现。<br/><br/>鼓励读者参与内容修正、代码翻译等贡献活动，共同推动书籍质量的提升。<br/><br/>本书还特别感谢每一位撰稿人的无私奉献，他们的辛勤工作让这本书更加完善。 |
| [paul-gauthier/aider](https://github.com/paul-gauthier/aider) | 这段文本是关于Aider这个AI编程助手的评价和使用体验分享。用户们普遍认为Aider在实际开发工作中表现优秀，能够帮助开发者在现有代码基础上进行高效工作。其中一些评价特别强调了Aider带来的便利性和改变生活的能力。 |
| [LizardByte/Sunshine](https://github.com/LizardByte/Sunshine) | 本文是一篇关于开源项目"Sunshine"的介绍性文章。项目由"LizardByte"维护，主要关注于提供一个本地化的流媒体服务。<br/><br/>文章首先展示了项目的GitHub stars数量，这表明该项目在GitHub上的受欢迎程度。<br/><br/>接下来详细介绍了项目的特性、功能以及如何通过Winget进行分发。同时提到了项目在GitHub上的链接，方便读者进一步了解和贡献。<br/><br/>总的来说，本文为"Sunshine"开源项目提供了一个全面的介绍，旨在吸引更多的开发者关注并参与到这个有意义的项目中来。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [8点1氪｜李佳琦方回应直播间卖假和田玉传闻；特朗普遭刺杀后支持率未显著领先；多家大模型测不出9.11和9.9哪个大](https://www.36kr.com/p/2867003680985219) | 以下是关于最近一些科技、投融资和奥运新闻的简要概述：<br/><br/>1. **科技公司动态**：<br/>   - **天府逍遥科技完成融资**：这家公司完成了数亿元人民币的新一轮融资，投资方包括沃衍资本和纽尔利资本等。<br/>   - **嘉轩智能完成新一轮融资**：永磁驱动装备创新企业嘉轩智能也宣布完成亿元级天使+轮融资。<br/><br/>2. **奥运新闻**：<br/>   - **巴黎市长为奥运会下河游泳**：巴黎市长在为奥运会做准备时，表示愿意亲自体验一下游泳这项运动。<br/>   - **塞纳河游泳安全质疑**：这一行为引发了关于河流清洁度和游泳安全性的讨论。<br/><br/>3. **投融资简述**：<br/>   - **耀速科技Xellar Biosystems融资情况**：公司完成了亿元级人民币的天使+轮融资，投资方包括鼎泰集团等。<br/>   - **嘉轩智能融资规模**：嘉轩智能的融资规模达到了数亿元人民币级别。<br/><br/>以上信息是基于公开报道和资料整理而成，具体细节可能会有所出入。 |
| [阿里通义千问技术骨干周畅将离职创业 · 36氪独家](https://www.36kr.com/p/2866187641195136) | 阿里云通义千问技术负责人周畅离职，将创业于AI应用领域。周畅在阿里巴巴任职期间，参与了多模态预训练模型M6的设计与实现。他的离职标志着阿里大模型团队的一个重要人物的流动。 |
| [华为车BU半年收入近百亿元，超过去两年总和 · 36氪独家](https://www.36kr.com/p/2864614229428870) | 以下是关于华为车BU独立进程、未来发展以及可能影响的摘要：<br/><br/>1. **独立准备**：华为车BU已进行多种准备工作，以保持团队的灵活性。<br/><br/>2. **项目储备**：华为计划在下半年发布与北汽、奇瑞合作的智选车型，为未来收入增长提供弹药。<br/><br/>3. **合作模式变化**：独立后，华为车BU可能弱化华为品牌的存在，以便于与其他主机厂合作时减少技术光环的影响。<br/><br/>4. **收入预期**：2025年将是华为车BU独立后的关键一年，其收入增长将取决于上述因素的综合效果。 |
| [美团外卖内测“省钱版”，“拼好饭”后再推低价产品｜36氪独家](https://www.36kr.com/p/2865998106971016) | 这段内容是关于美团外卖推出的新项目“省钱版”，以及其在商品模式上的尝试和消费者接受度的问题。该项目试图通过低价商品吸引流量，帮助中小商家获取用户，并优化冷门商品的曝光。同时，消费者对于“吃”安全性的高要求也是商品模式需要考虑的一个因素。总的来说，这段内容讨论的是美团外卖在提升性价比策略上的新探索。 |
| [百度又该造车了](https://www.36kr.com/p/2865896834042755) | 百度在自动驾驶领域的积极布局和转型尝试，引发了广泛关注。以下是基于提供的信息，对百度自动驾驶战略的几个关键点的总结：<br/><br/>1. **从解决方案提供商到自动驾驶整车制造商**：百度试图通过造车来实现自动驾驶技术的商业化应用。<br/><br/>2. **萝卜快跑挑战武汉“全员鄂人””**：萝卜快跑作为百度在自动驾驶领域的快速落地项目，展示了其在特定场景下的应用能力。<br/><br/>3. **与特斯拉的竞争**：百度希望通过自主造车的方式，与特斯拉等国际巨头在robotaxi市场展开竞争。<br/><br/>总结来说，百度正在积极构建自动驾驶的商业生态，并通过自身造车来实现这一目标。然而，这个过程也伴随着挑战和不确定性，需要持续关注其进展。 |
| [第一批大厂“离职博主”，已经集体回去上班了](https://www.36kr.com/p/2865716325046658) | 本文是一篇关于离职博主现象的分析文章。作者通过观察和解读，揭示了这一职业赛道的本质——并非真正的职业道路，而是利用“离职”标签吸引流量的营销策略。<br/><br/>文章强调，尽管一些离职博主可能通过这种方式获得了暂时的关注和收益，但长期来看，这并不是可持续的职业选择。最终，大多数打工人都需要回归到自己的工作岗位上。<br/><br/>总结来说，本文对离职博主这一现象进行了深入剖析，提醒人们在追求流量的同时，也要看清职业道路的本质。 |
| [马斯克 4 年前的这个决定，让特斯拉犯下了最严重的错误](https://www.36kr.com/p/2865714248076160) | 这篇文章讨论了特斯拉电池研发中的4680电池。电池工艺的难题导致生产方法需要验证和改进。文章还提到了投资者对此问题的质疑以及电动汽车市场竞争情况。<br/><br/>总结来说，这篇文章关注的是特斯拉在电池技术上的挑战、研发进度以及市场反应。 |
| [苹果iPhone 16抢先“体验”，多处设计大改，或6499元起售，心动了吗](https://www.36kr.com/p/2865683066980992) | iPhone 16系列全系有望配备8GB超大容量内存，并采用不锈钢电池外壳和触点连接的电池技术，电池一体性更强，续航有望成为iPhone史上最长。同时，新iPhone的充电速度有望达到40W，这是个惊人的数字。对于用户来说，是否选择入手iPhone 16系列，主要取决于个人对新设备性能提升、续航改善以及快速充电需求的重视程度。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [Team HYU ASML ROBOVOX SP Cup 2024 System Description](https://arxiv.org/abs/2407.11365) | 1. 提交了HYU ASML团队参加IEEE Signal Processing Cup 2024的报告。<br/><br/>2. 描述了挑战的主题，即"ROBOVOX：通过移动机器人进行远场扬声器识别"，并关注在嘈杂和反射条件下进行。<br/><br/>3. 提供了解决方案，结合深度残差神经网络（ResNet）的结果和基于时间-延迟神经网络（TDNN）的说话人嵌入模型。<br/><br/>4. 详细说明了这些模型如何训练，使用了一个多样化的数据集，包括法语语音。<br/><br/>5. 关注了在具有高噪声、反射、短讲话条件的评估环境中的应对策略，重点是数据增强和训练说话时长以适应嵌入模型。<br/><br/>6. 提供了提交作品的成绩，该团队在SP Cup 2024的公共排行榜上获得了第二名，检测成本函数为0.5245，等误率（Equal Error Rate）为6.46%。 |
| [VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark](https://arxiv.org/abs/2407.11510) | 1. 提供了大规模的音频-视觉演讲者识别数据集，VoxBlink2，包含约10M条带有视频的说话内容。<br/><br/>2. 数据集涵盖了110K+野生环境下的真实讲话者，通过优化的数据收集管道，扩大了多样性范围。<br/><br/>3. 研究探讨了训练策略、数据规模和模型复杂度对演讲者验证的影响。<br/><br/>4. 在VoxCeleb1-O测试集上建立了新的单模型最先进的EER（误识率）为0.170%和minDCF（最小成本分类）为0.006%。这些显著的结果激励了作者探索更具挑战性的演讲识别领域。 |
| [The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice Anonymisation](https://arxiv.org/abs/2407.11516) | 1. 系统概述和分析：对2022年VoicePrivacy Challenge的第二版进行了全面的系统概述，包括任务描述、使用的语音匿名化任务和数据集等。<br/><br/>2. 评估模型和指标：详细介绍了挑战中用于系统评价的不同攻击模型，以及与之相关的客观和主观评估指标。<br/><br/>3. 基线方法介绍：提出了三个匿名化基线，为后续系统的比较提供了参考。<br/><br/>4. 参与者系统描述：对挑战参与者开发的匿名化系统进行了简要概述。<br/><br/>5. 评估结果报告：详细报告了所有参与者的系统在客观和主观指标下的评估结果。<br/><br/>6. 后续分析和相关工作综述：介绍了针对评估结果进行的后续分析，以及公开文献中与VoicePrivacy Challenge相关的研究工作。 |
| [MUSA: Multi-lingual Speaker Anonymization via Serial Disentanglement](https://arxiv.org/abs/2407.11629) | 1. 提出MUSA，一个多语言的Speaker Anonymization方法。<br/>2. 采用串行解耦策略，通过逐步从全局不变的时间-invariant表示解耦到时间变化的表示。<br/>3. 利用语义蒸馏和自我监督说话者蒸馏来增强串行解耦策略，避免强先验假设并展现出在不同语言上的优秀泛化性能。<br/>4. 提出简单直接的匿名化策略，通过使用零值的空向量模拟说话者身份的隐藏过程，省去了伪-说话者身份转换步骤，降低了Speaker Anonymization的复杂性。 |
| [Universal Sound Separation with Self-Supervised Audio Masked Autoencoder](https://arxiv.org/abs/2407.11745) | 1. 提出将自监督预训练模型(A-MAE)整合到通用声分离系统中的方法，以提升其分离性能。<br/><br/>2. 利用两种策略利用SSL嵌入：在微调过程中冻结或更新A-MAE的参数。<br/><br/>3. 将SSL嵌入与短时傅里叶变换(STFT)相结合，作为分离模型的输入特征。<br/><br/>4. 在AudioSet数据集上评估了这些方法，实验结果表明所提出的增强分离性能的方法有效。 |
| [Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors](https://arxiv.org/abs/2407.11828) | 1. 创立了名为Vibravox的音频数据集，该数据集遵循GDPR规定，包含使用五种不同身体传导音频传感器录制的音频样本。<br/><br/>2. 数据集不仅包括来自空中麦克风的参考音频数据，还包含了参与者在不同声学条件下录制的各种生理声音和言语样本。<br/><br/>3. 通过实验系列，研究者在诸如语音识别、语音增强和说话人验证等与语音相关的任务上进行了应用。<br/><br/>4. 这些实验使用了最先进的模型来评估和比较它们在由Vibravox数据集提供的不同音频传感器捕捉的信号上的性能。 |
| [Navigating the Minefield of MT Beam Search in Cascaded Streaming Speech Translation](https://arxiv.org/abs/2407.11010) | 1. 适应性研究：该论文提出将经典的beam-搜索算法应用于实时的多语种口译系统中。<br/><br/>2. 挑战与解决方案：针对实际应用中的四个关键挑战，如ASR产生的不完整单词、翻译的最小用户感知延迟、不同长度和状态的模型假设以及句子边界处理等，论文提供了相应的解决方案。<br/><br/>3. 评估改进效果：通过对比beam-搜索实现与贪婪解码（之前工作仅实施此方法）在BLEU分数、CPU时间、字符闪烁率等方面的差异，展示了算法的有效性改进。 |
| [Exploring Gender-Specific Speech Patterns in Automatic Suicide Risk Assessment](https://arxiv.org/abs/2407.11012) | 1. 提出了一种基于语音的自杀风险自动评估方法。<br/>2. 创立了一个包含20名患者阅读中性文本录音的新数据集。<br/>3. 提取了四种涵盖可解释和深度特征的语音表示。<br/>4. 研究了性别模型差异化对特征影响以及短语级正常化的效果。<br/>5. 结果表明，应用性别排除的模型，可以利用经过情绪精细调优的wav2vec2.0模型提取的特征，以81%的平衡准确率区分高和低自杀风险。<br/>6. 分析揭示了女性和男性在语音特征与自杀风险关系上的差异。 |
| [Knowledge boosting during low-latency inference](https://arxiv.org/abs/2407.11055) | 1. 提出知识增强（Knowledge Boosting）技术，用于解决大型模型与小型设备之间资源限制的问题。<br/><br/>2. 设计并评估使用时间延迟输入的流式神经网络，处理8毫秒的帧。<br/><br/>3. 在不同语音分离和增强任务中引入通信延迟，实验范围可达6个或48毫秒的延迟。<br/><br/>4. 结果表明，在模型性能差距较大的情况下，知识增强技术能带来更大的提升，为大型小型模型协作提供了一种有前景的方法。 |
| [Target conversation extraction: Source separation using turn-taking dynamics](https://arxiv.org/abs/2407.11277) | 1. 提出新任务：目标对话提取，即根据参与者之一的说话人嵌入，提取目标对话的音频。<br/><br/>2. 创新方法：利用人类对话中固有的时间模式，特别是轮换动态，这些特性独特地标识了参与对话的发言者，并与干扰发言者和噪音区分开来。<br/><br/>3. 实验验证：使用神经网络模型在英语和普通话对话数据集上进行实验，证明了这种方法的可行性。<br/><br/>4. 代码和数据集公开：提供一个GitHub链接，其中包含实现该方法的代码以及用于实验的数据集。 |
| [Disentangled Acoustic Fields For Multimodal Physical Scene Understanding](https://arxiv.org/abs/2407.11333) | 1. 该研究探讨了多模态物理场景理解的问题，其中需要一个有形代理找到落下的物体，通过推断对象属性、方向和声音源撞击声的传播距离来实现。<br/><br/>2. 前面的工作通常使用前馈神经网络直接从声音中回归变量，这导致了泛化能力差和领域适应问题。<br/><br/>3. 本论文提出学习一个声学形成过程的解离模型，称为解离的声场(Disentangled Acoustic Field, DAF)，以捕捉声音生成和传播的过程。通过这种方式，有形代理能够构建一个空间不确定性地图，显示物体可能落下的位置。<br/><br/>4. 研究表明，基于分析-合成框架的联合推断可以明确分解和因子化解离模型的潜在空间，从而更准确地推断声音属性。此外，空间不确定性地图能显著提高定位失败物体的成功率，通过在多个合理探索位置上提出假设来实现这一点。 |
| [Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models](https://arxiv.org/abs/2407.11345) | 1. 提出使用生成预训练的Transformer（GPT）模型来识别从文本转录来的多种类型的口述错误，即多类口误检测。<br/><br/>2. 展示两种端到端的方法，它们专注于同时建模自动语音识别（ASR）和口误分类作为多个序列与单一序列的区别。<br/><br/>3. 实证表明，单序列模型在多类口误检测任务中优于基于GPT的基线模型。 |
| [A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora](https://arxiv.org/abs/2407.11370) | 1. 提出使用Generative Spoken Language Model (GSLM)模拟人类外语口音化过程的方法。<br/><br/>2. 利用GSLM，仅依赖母语语音数据集，实现对目标语言A的口音化合成。<br/><br/>3. 描述了当一个人听外语并重复时，重复的口音往往带有说话者母语L1的特征。<br/><br/>4. 提出通过将语言A的语音输入到语言B的GSLM中，来为输入语音添加语言B的口音这一模拟过程。<br/><br/>5. 实验结果表明，生成的口音非常自然，与由母语是B的语言使用者生成的A语言样本相比有显著优势。同时，口音化的程度也可以通过调整模型参数进行控制。 |
| [MMSD-Net: Towards Multi-modal Stuttering Detection](https://arxiv.org/abs/2407.11492) | 1. 提出MMSD-Net，这是第一个多模态神经框架，专门用于 stuttering（口吃）检测。<br/><br/>2. 该研究填补了现有uni-modal方法在处理口吃时缺乏跨模态信息的空白。<br/><br/>3. 实验和结果表明，视觉信号的整合显著有助于口吃的检测。模型相对于现有state-of-the-art uni-modal方法，在F1分数上提高了2%-17%。 |
| [Investigating the Effect of Label Topology and Training Criterion on ASR Performance and Alignment Quality](https://arxiv.org/abs/2407.11641) | 1. 提供了一种针对自动语音识别(ASR)中两种主要方法——端到端和经典模块系统——的深入比较。<br/><br/>2. 研究焦点集中在标签拓扑结构和训练准则上，这有助于理解模型在这些方面的要求和优缺点。<br/><br/>3. 比较了两种基于判别性对齐的模型（与HMM和连接ist时间分类拓扑结构相结合），以及两种使用事实化HMM和严格单调递增RNN转录器的标签上下文ASR模型。<br/><br/>4. 通过不同的测量标准评估了这些模型的对齐质量，并比较了最佳系统的词错误率和实时因子。 |
| [Statistics-aware Audio-visual Deepfake Detector](https://arxiv.org/abs/2407.11650) | 1. 提出统计特征损失，增强模型的区分能力，而非单纯依赖特征距离。<br/><br/>2. 使用声波描述音频，替代基于频率的表示，有助于音频信息的更自然处理。<br/><br/>3. 推广后处理的伪造分数标准化，消除因原始数据差异导致的评分偏差。<br/><br/>4. 采用较浅的网络结构以降低计算复杂度，使得模型在保持检测性能的同时，更加高效。 |
| [Leveraging ASR Pretrained Conformers for Speaker Verification through Transfer Learning and Knowledge Distillation](https://arxiv.org/abs/2309.03019) | 1. 提出使用ASR预训练的Conformers进行说话人验证的方法，利用它们在处理语音信号方面的优势。<br/><br/>2. 推介了三种策略：<br/>   - (1) 转移学习初始化，通过提高泛化能力并减少过拟合来改善模型。<br/>   - (2) 知识蒸馏训练更灵活的模型，通过辅助任务（如帧级ASR损失）来整合ASR的能力。<br/>   - (3) 设计轻量级说话人适配器，用于高效地转换特征而不改变原始ASR Conformer，允许同时进行ASR和说话人验证。<br/><br/>实验在VoxCeleb数据集上进行了，结果表明这些方法显著提高了性能：<br/>- 转移学习带来0.48%的eer。<br/>- 知识蒸馏带来了0.43%的eer。<br/>- 适配器方法，仅增加了4.92M参数到一个130.94M参数模型，却实现了0.57%的eer。<br/><br/>总的来说，这些方法有效地将ASR的能力转移到说话人验证任务中。 |
| [Self-supervised Reflective Learning through Self-distillation and Online Clustering for Speaker Representation Learning](https://arxiv.org/abs/2401.01473) | 1. 提出自我监督的反思学习（SSRL）方法，这是一种新颖的学习范式。<br/><br/>2. SSRL整合了自监督知识蒸馏和在线聚类，以优化伪标签并训练模型，避免迭代瓶颈。<br/><br/>3. 通过教师模型持续更新伪标签，并提供动态监督信号给学生模型进行训练。<br/><br/>4. 学生模型在输入噪声和模型噪声的条件下进行训练，以提升其建模能力。<br/><br/>5. 教师模型通过学生模型的指数移动平均来更新，模拟了过去迭代的集合行为。<br/><br/>6. 通过伪标签队列保留历史标签以保持一致性，并引导学习朝着清洁样本方向发展。 |
| [Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data](https://arxiv.org/abs/2402.18932) | 1. 提出了一种框架，用于使用找到的数据无监督地扩展多语言文本到语音转换模型，覆盖100+种语言。<br/><br/>2. 该框架结合了预训练的语音-文本编码器和使用未转录语音和未说出文本数据源的无监督训练。<br/><br/>3. 利用大规模多语联合的语音和文本表示学习，从而在没有新语言的转录语音的情况下，生成超过30种未见过的语言的可理解语音。<br/><br/>4. 通过使用15分钟的已找到转录数据，可以将可理解性差异降低到与地面真实值相差1%或更少的程度，并在几种语言中达到与地面真实值匹配的自然度评分。 |
| [Dance Any Beat: Blending Beats with Visuals in Dance Video Generation](https://arxiv.org/abs/2405.09266) | 1. 任务创新：提出直接从个体图像生成舞蹈视频的新任务，这有助于克服现有方法的局限性。<br/><br/>2. 模型设计：介绍Dance Any Beat Diffusion模型（DabFusion），它利用参考图像和音乐来生成具有多样舞蹈类型和编排的视频。<br/><br/>3. 数据处理挑战：指出当前方法需要精确的关键点标注，这使得数据收集困难且限制了使用自定义视频数据集的能力。<br/><br/>4. 技术贡献：提出一种2D Motion-Music Alignment Score（2D-MM Align）来评估新任务中运动和音乐的对齐程度，这是对现有音乐同步度评价方法的改进。 |
| [SHMamba: Structured Hyperbolic State Space Model for Audio-Visual Question Answering](https://arxiv.org/abs/2406.09833) | 1. 提出SHMamba，一种结合了hyperbolic几何和状态空间模型的结构化模型。<br/><br/>2. SHMamba利用hyperbolic空间的内在特性来表示音频-视觉数据中的层次结构和复杂关系。<br/><br/>3. 通过状态空间模型捕捉序列随时间的动态变化。<br/><br/>4. 引入适应性曲率的hyperbolic对齐模块和交叉融合块，以增强对层次结构的理解以及跨模态信息的动态交换。<br/><br/>5. 实验结果表明SHMamba在参数量更少、计算成本更低的情况下超越了先前的方法，并且其性能平均提高了2.53\%。 |
| [Towards Effective and Efficient Non-autoregressive Decoding Using Block-based Attention Mask](https://arxiv.org/abs/2406.10034) | 1. 提出一种非自回归的(NAR)块级注意力掩码解码器(AMD)，用于平衡性能效率在变声器ASR系统中的权衡。<br/><br/>2. AMD通过并行在连续输出标签块中进行NAR推理，这些标签使用注意力掩码隐藏起来，同时进行左到右的自回归预测和相邻块之间的历史上下文融合。<br/><br/>3. 设计了一种基于动态融合的CTC、解码器AR概率和AMD概率的搜索算法，以利用这种多模态概率的协同效应。<br/><br/>4. 在LibriSpeech-100hr数据集上进行实验，结果显示采用AMD模块的三部分解码器相比基础的CTC+AR解码，能实现最大1.73倍的解码速度提升，同时在测试集上没有显著的词错误率(WER)增加。当以相同的解码实时因子运行时，相对于CTC+AR基线，可以获得高达0.7%和0.3%绝对(5.3%和6.1%相对)的WER减少。 |
