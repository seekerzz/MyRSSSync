# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [idootop/mi-gpt](https://github.com/idootop/mi-gpt) | 这个代码片段是关于一个名为 `MiGPT` 的项目，该项目可能是一个用于学习和研究的AI模型。代码中通过 `MiGPT.create` 创建了一个实例，并设置了相关参数如 `speaker.userId` 和 `password`。<br/><br/>如果用户想要本地开发或了解工作原理，可以查阅相关的文档链接，如 `development`、`how-it-works` 等。<br/><br/>此外，项目还包含了免责声明，提醒用户在使用本项目时需遵守法律法规并自行承担风险。 |
| [DaoCloud/public-image-mirror](https://github.com/DaoCloud/public-image-mirror) | 本文主要介绍了如何通过Docker加速镜像，包括配置文件的修改和添加到`/etc/docker/daemon.json`。同时，还提到了二进制文件加速、Helm图表加速等服务的加速方法。<br/><br/>此外，文中还特别提及了贡献者列表，展示了对该项目有贡献的开发者姓名。<br/><br/>总的来说，本文提供了一种通过Docker实现镜像加速的方法，并鼓励更多人参与到相关服务的优化中来。 |
| [alist-org/alist](https://github.com/alist-org/alist) | AList是一个开源的网络文件分享软件，它基于AGPL-3.0许可协议。这个程序设计用于在本地网络磁盘上共享文件，方便下载和学习Golang编程。<br/><br/>使用AList时，请遵守相关法律法规，并尊重他人权益，不要滥用服务。<br/><br/>此项目仅进行302重定向/流量转发操作，不拦截、存储或篡改任何用户数据。<br/><br/>在使用前，请理解并承担相应的风险，包括但不限于账号禁用、下载速度限制等，这些都不是这个程序的责任。如有侵权行为，请通过电子邮件联系我（邮箱地址），我会及时处理。 |
| [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 这段文字是关于一个名为nanoGPT的项目或模型的介绍。它提到了使用PyTorch 2.0进行编译，这可能意味着代码需要经过优化才能在该版本的PyTorch中运行。<br/><br/>此外，这段文字还包含了一些故障排除提示，比如如果遇到相关错误，可以尝试通过添加`--compile=False`标志来禁用编译以使代码运行。<br/><br/>最后，这段文字还提到了一个Discord社区频道#nanoGPT，作为讨论和寻求帮助的平台。<br/><br/>总结来说，这段文字是关于一个使用PyTorch 2.0进行优化的语言模型或项目nanoGPT的介绍，同时也包含了故障排除和社区支持的信息。 |
| [yt-dlp/yt-dlp](https://github.com/yt-dlp/yt-dlp) | 本文是关于YouTube下载插件（yt-dlp）的贡献指南。主要包括以下部分：<br/><br/>1. **CONTRIBUTING**：详细说明如何参与项目，包括如何提交问题和开发代码。<br/><br/>2. **WIKI**：链接到项目的wiki页面，那里通常会包含更详细的使用指南和技术文档。<br/><br/>3. **SUMMARY**：简要概括内容，方便读者快速了解关键信息。 |
| [microsoft/winget-pkgs](https://github.com/microsoft/winget-pkgs) | 这个Windows Package Manager社区仓库的README文件提供了关于如何贡献代码和管理的详细指导。它强调了需要签署Contributor License Agreement (CLA)来提交pull请求，并指出了如果违反第三方材料的权利，可能禁止链接到第三方材料的Submissions。 |
| [SoftFever/OrcaSlicer](https://github.com/SoftFever/OrcaSlicer) | OrcaSlicer是一个开源的3D打印软件，最初是基于Bambu Studio的基础上开发。它具有很多来自SuperSlicer和社区成员Justin Levine设计的功能。<br/><br/>Orca Slicer的许可证是GNU Affero General Public License, version 3，确保如果用户以任何方式使用该软件（甚至在Web服务器后），他们的软件必须以相同的方式发布。<br/><br/>此外，Orca Slicer中包含了一个基于Andrew Ellis生成器的压力前进校准测试图案，这本身是根据Sineos为Marlin开发的非免费库改编的。这个插件是可选的，并且为Bambulab打印机用户提供额外的功能。 |
| [LazyVim/LazyVim](https://github.com/LazyVim/LazyVim) | "LazyVim是一个强大的Neovim配置工具，它能够将你的配置文件自动化加载，并且支持半自动的配置更新。通过使用懒 Vim，你可以轻松地管理你的配置，避免手动复制粘贴导致的错误和不便。"<br/><br/>简而言之，这个工具简化了Neovim的配置过程，使得配置更加自动化、高效和易于管理。 |
| [google/mesop](https://github.com/google/mesop) | "Mesop是一个基于Python的UI框架，用于快速构建内部应用和演示。它易于理解，采用直观的Python代码和反应式UI设计。 Mesop还提供了丰富的组件库，以及在开发过程中支持热重载。适用于UI初学者和希望快速搭建应用的开发者。" |
| [cloudcommunity/Free-Certifications](https://github.com/cloudcommunity/Free-Certifications) | 这个表格列出了多个提供免费证书认证的资源。每个条目都包括了资源名称、简介（如一个英语能力测试或个人技能证书），链接到具体评估或注册页面，以及证书获取的限制条件（如是否无限次获取）。<br/><br/>例如，EF SET提供了两种类型的证书：一种是50分钟的全面测试以获得个性化英语证书；另一种是15分钟的快速检查英语水平的证书。这两种证书都可以无限次获取。 |
| [lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge) | Forge WebUI新增功能，包括DDPM、DPM++ 2M Turbo等新Samplers。同时，ControlNet和TiledVAE已整合，旧的控制net v2v和batch still在建设中，预计一周内完成。其他扩展如canvas-zoom、translations/localizations等应正常工作。对于Forge功能的贡献，可以提交与 Forge 功能相关的代码 PR 到指定的 dev分支。 |
| [roboflow/notebooks](https://github.com/roboflow/notebooks) | 这段文字是关于如何在Amazon SageMaker Studio Lab中运行Roboflow Notebooks的指导。首先，需要在本地克隆Notebooks仓库，并导航到根目录。然后，建议使用venv环境来安装和管理Python依赖。最后，提供了创建SageMaker Notebook并运行的步骤链接。<br/><br/>如果读者在运行过程中遇到问题，被鼓励创建一个bug报告，这样开发者可以及时了解并解决问题。对于想要贡献新教程的想法，也鼓励提出feature request，一起推动Roboflow Notebooks的发展。 |
| [k2-fsa/sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx) | 本文是一个关于Kaldi语音识别工具的指南。首先，提供了如何找到他们的官方文档和社交媒体群体链接的指导。<br/><br/>然后，特别提到了新一代Kaldi的微信交流群和QQ交流群，这对于想要加入这个社区进行交流的人来说是重要的信息。<br/><br/>总的来说，这篇文章为对Kaldi感兴趣的开发者、研究人员以及潜在用户提供了一个全面的入门指南。 |
| [huggingface/lerobot](https://github.com/huggingface/lerobot) | 本文介绍了LeRobot项目，这是一个使用PyTorch实现的机器学习框架，专门用于真实世界的机器人学。开发者提供了详细的代码和配置指南，方便其他人理解和使用。<br/><br/>此外，文章还提到了如何进行性能分析和调试，这对于优化代码并提高评估政策的效率至关重要。<br/><br/>最后，文中列出了引用此工作的参考信息，以便他人在需要时进行学术引用。 |
| [donnemartin/system-design-primer](https://github.com/donnemartin/system-design-primer) | 这个仓库包含了各种系统设计相关的资源和代码。它旨在帮助开发者学习和理解系统设计的过程和技巧。<br/><br/>仓库中的内容包括但不限于：系统设计的书籍推荐、面试题集、案例分析等。此外，还有一些关于分布式系统、数据库设计等方面的资源。<br/><br/>如果你对系统设计感兴趣，或者在工作中需要进行系统设计，这个仓库可能会对你有所帮助。 |
| [coollabsio/coolify](https://github.com/coollabsio/coolify) | 这段HTML代码是用于展示一个关于开源项目"Coolify"的页面。它包含了几个关键信息点：<br/><br/>1. **Hacker News Feature**：Coolify被推荐在Hacker News上，这是一个技术新闻和社区。<br/><br/>2. **Product Hunt Recognition**：Coolify还出现在Product Hunt的列表中，这表明该项目受到了一定的关注。<br/><br/>3. **Star History Chart**：这段代码显示了一个星历史图表，用于展示"Coolify"项目在过去某个日期的星标数量变化。<br/><br/>总的来说，这段代码是用来展示"Coolify"项目的知名度和关注度增长情况。 |
| [mahdibland/V2RayAggregator](https://github.com/mahdibland/V2RayAggregator) | 本文是一篇关于网络客户端软件的列表，主要介绍了适用于iOS/iPadOS和Android系统的Shadowrocket、Surge、Quantumult X、Potatso Lite以及CFA(Clash For Android)等网络客户端应用。每个条目都列出了其支持的协议类型，如SS（Shadowsocks）、Trojan、Vmess等，并提到了是否需要购买非本国App Store中的应用，以及这些应用的一些特性或功能。 |
| [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) | 这个代码库是由多个贡献者共同创建的，最初由Daniel Stefanovic发起。现在，它由CodeCrafters, Inc.维护。根据法律许可，CodeCrafters, Inc.已经放弃了所有版权和相关或邻接的权利。 |
| [xenova/transformers.js](https://github.com/xenova/transformers.js) | 这段信息是关于多个语言模型的介绍，包括它们的名字（如ViT、WavLM等）以及对应的来源。每个模型都与特定的语言处理任务相关，例如语音识别或跨语言理解。 |
# 36氪 - 24小时热榜
---
| Title | Summary |
| --- | --- |
| [苹果：你们这些 AI 公司，只配做备胎](https://www.36kr.com/p/2815361562905089) | 苹果在 WWDC 大会上展示了自家的 6 个操作系统后，重点介绍了名为 Apple Intelligence 的人工智能项目。Apple Intelligence 看似将AI技术应用于数据收集和处理上，并且强调了其在不联网的情况下也能进行复杂指令处理的能力。这对于苹果来说是一个重要的里程碑，可能会影响其未来的战略方向。<br/><br/>然而，Apple Intelligence 的具体表现、数据收集的深度以及实际智能水平等仍然是未知数，需要等到年底英文版本上线后才能得到更准确的信息。<br/><br/>总的来说，Apple Intelligence 显示了苹果在 AI 技术领域的创新和野心，值得期待。 |
| [为脱单，年轻人盯上恋综式旅行](https://www.36kr.com/p/2815153812752643) | 这段内容是关于一个名为Tia的人物跨界到旅游行业创办奇语旅行，并推出恋综式旅行、MBTI综艺式旅行等主题活动的介绍。Tia认为年轻人喜欢的热门旅行线路会融入产品设计中，这反映了当前旅行业发展趋势和年轻消费者的喜好。 |
| [2024最拥挤赛道：离职博主](https://www.36kr.com/p/2814882266139144) | 这段内容是关于一个离职博主的个人经历分享。博主@西南Irene通过自己的自媒体账号，分享了做博主的心路历程，包括初期的数据压力、坚持的动力以及对职业成长的独特感受。<br/><br/>此外，内容还提到了博主在起号初期面临的挑战，以及她如何通过爱好来保持动力和持续创新。<br/><br/>总的来说，这段摘要提供了一个离职博主个人经历的概览，强调了她在自媒体领域的学习和成长。 |
| [我们体验了iOS 18 最重磅的“史诗级更新”，发现了这些细节](https://www.36kr.com/p/2814863407892736) | 苹果在其最新版操作系统iOS 18中引入了一系列新功能和改进。尽管这些更新可能不如预期那样令人兴奋，但它们确实代表了苹果对用户体验的持续追求。<br/><br/>具体来说，iOS 18中的信息 App新增了定时发送消息的功能，并且文字还支持动画效果。地图 App则提供了离线使用地形图的功能，这对于需要在没有网络覆盖的地方导航的用户来说非常实用。<br/><br/>此外，发布会中提到的「Tap to Cash」碰一碰支付功能虽然并未直接出现在国行iOS 18中，但这也代表了苹果对于创新支付方式的探索。<br/><br/>总结来说，尽管iOS 18的一些更新可能不如预期那样令人兴奋，但它确实代表了苹果在用户体验和技术创新方面的持续努力。 |
| [字节“亲儿子”估值217亿，红杉、KKR入局](https://www.36kr.com/p/2814843163953669) | 这篇文章讨论的是字节跳动旗下的汽车业务平台懂车帝。文章分析了字节跳动为何会选择拆分懂车帝这一业务部门，并提到了火山引擎作为大模型服务商与懂车帝的合作。<br/><br/>此外，文章还引用了“投中网”作者张雪的观点，但并未提供详细内容。<br/><br/>如果你需要更具体的信息或者对这篇文章的某个观点有疑问，可以继续提问。 |
| [30万人疯抢1998元收藏版，黑神话的定价策略太对了](https://www.36kr.com/p/2814818386643202) | 《黑神话：悟空》作为中国第一款全民关注的3A游戏，其价格设定对整个国游市场有深远影响。游戏定价298元，相较于其他派对游戏，这个价格在普通玩家预期中算是较高。同时，国产游戏产量上升背景下，真正匹配3A制作规格的游戏稀缺性也凸显出来。<br/><br/>《黑神话：悟空》的成功在于它满足了海外玩家对于高品质游戏的期待，超越了同类型游戏。未来这款游戏的口碑和市场反应将备受关注。 |
| [一顿饭9块钱，盒马盯上“打工人快餐”](https://www.36kr.com/p/2814812771076360) | 这篇文章讨论了餐饮行业中的快餐赛道面临的挑战。传统夫妻店在产品研发、品控和价格等方面难以抗衡便利店等跨界业态的低价策略。<br/><br/>文章引用一位快餐老兵的观点，指出价格战不会停止，而是会升级到供应链和运营系统的竞争层面。同时提到了萨莉亚式的“极致性价比”战略，强调高品质、高性价比的品牌才能在竞争中脱颖而出。<br/><br/>总结来说，这篇文章分析了快餐行业面临的挑战，包括价格战的压力以及传统模式的局限性。提出了只有具备独特品质和性价比的品牌才能在这个快速变化的市场中立足并发展。 |
| [高位贷款的买房人，每天都在盼着存量房贷利率下降](https://www.36kr.com/p/2814750506273289) | 这段文字是关于房贷利率变化对购房者心理和经济影响的讨论。主要人物包括贷款买房的人（如慧慧、庾欣等）、银行（通过净息差指标反映）、以及经济学家张大伟。<br/><br/>讨论内容包括：<br/>1. 新旧房贷之间的利率落差，成为购房者的心理压力。<br/>2. 银行降息动力不足，可能影响到存量房贷的利率调整。<br/>3. 经济学家张大伟认为稳定楼市和救市政策是为了拉动消费，而降低房贷利率有助于消费者增加消费。<br/><br/>总结来说，这段文字讨论了房贷利率变化对购房者心理和经济的影响，以及政府通过稳定楼市来刺激消费的策略。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [XANE: eXplainable Acoustic Neural Embeddings](https://arxiv.org/abs/2406.05199) | 1. 提出了一种新的方法，用于从神经嵌入中提取模型，这些嵌入捕捉了语音信号的背景噪声特性。<br/><br/>2. 这些提取的嵌入被用来估计与信号背景声学属性相关的特定参数，这种方法是非侵入性的，允许嵌入以这些参数为解释。<br/><br/>3. 通过在未见过的测试数据上进行聚类实验来展示这些嵌入的价值。结果显示，提出的嵌入在三个不同任务上的平均F1分数达到了95.2%，显著优于基于WavLM的信号嵌入。<br/><br/>4. 此外，研究还展示了该方法能够以高准确度和较低实时性估计14个描述背景声学特性的参数，包括回声、噪声水平等。 |
| [A model of early word acquisition based on realistic-scale audiovisual naming events](https://arxiv.org/abs/2406.05259) | 1. 研究早期词汇学习是否可以通过统计学习，从音频视觉感官输入的规律中获取知识。<br/><br/>2. 模拟婴儿在12个月龄内的语言学习过程，在一个现实场景下进行，使用一个仅通过统计规律在未标注原始语音和像素级视觉输入中学习的模型。<br/><br/>3. 在设计事件命名的数量时，特别注意与同龄婴儿可接触到的事件数量相匹配。<br/><br/>4. 结果表明，该模型有效地学习了识别词汇并将其与相应的视觉对象关联起来的能力，其词汇增长速度与观察到的婴儿相似。<br/><br/>5. 研究结果支持早期词汇感知可以通过一般统计学习进行的观点，并展示了学习如何在不假设任何先前语言能力的情况下运作。 |
| [Signal processing algorithm effective for sound quality of hearing loss simulators](https://arxiv.org/abs/2406.05286) | 1. 该研究提出了使用听力损失模拟器（HL simulator）进行声音质量感知实验的设想。<br/><br/>2. 实验中对比了两种版本的HL simulator，即CamHLS和WHIS（带Wakayama算法）。<br/><br/>3. 特别指出的是，WHIS在DTVF算法下产生的声音失真比其他两种方法更少，即使在非线性过程工作时也是如此。<br/><br/>4. 这个优势主要归因于使用了DTVF算法，这表明这种算法可能适用于多种信号合成应用，特别是那些基于滤波分析的。 |
| [Spectral Codecs: Spectrogram-Based Audio Codecs for High Quality Speech Synthesis](https://arxiv.org/abs/2406.05298) | 1. 提出新的音频编码器：作者提出了一种名为"谱系编码器"（Spectral Codec）的新型音频编码器，它压缩并重构了梅尔频率谱图。<br/><br/>2. 对比分析：通过研究客观音频质量指标，作者发现他们的谱系编码器在感知质量上与同等音频编码器相当。<br/><br/>3. 模型应用：进一步，作者指出训练非自回归语音合成模型（如TTS）时，使用他们提出的谱系编码器生成的音频质量显著高于使用梅尔频率谱图或传统音频编码器训练的情况。 |
| [Relational Proxy Loss for Audio-Text based Keyword Spotting](https://arxiv.org/abs/2406.05314) | 1. 提出音频-文本基于关键词识别（KWS）任务，这是现有系统关注的用户便利性增强。<br/><br/>2. 描述了通常用于训练这种任务的深度学习方法，包括使用基于triplet和proxy的损失函数进行多模态特征编码。<br/><br/>3. 研究目标是改进现有的多模态KWS方法，通过利用音频嵌入和文本嵌入内部结构关系来优化模型性能。<br/><br/>4. 提出一种新的损失函数概念——Relational Proxy Loss（RPL）——用于在多模态空间中关注和利用这些内在结构关系。<br/><br/>5. 实验结果表明，通过引入RPL，系统在Wall Street Journal（WSJ）语料库上的表现有所提升。 |
| [LDM-SVC: Latent Diffusion Model Based Zero-Shot Any-to-Any Singing Voice Conversion with Singer Guidance](https://arxiv.org/abs/2406.05325) | 1. 提出了一种基于潜在扩散模型的歌唱声音转换（SVC）方法，即LDM-刘维。<br/><br/>2. 通过预训练一个变分自编码器结构，使用了公开的So-VITS-刘维SVC项目，该结构基于VITS框架。<br/><br/>3. 在LDM训练过程中应用了歌手指导训练方法，基于无分类指导（classifier-free guidance）来进一步抑制原始歌手的声音特征。<br/><br/>4. 实验结果证明了所提出的LDM-刘维方法在主观和客观评估中对声音相似度的优越性。 |
| [To what extent can ASV systems naturally defend against spoofing attacks?](https://arxiv.org/abs/2406.05339) | 1. 该研究探讨了自动演讲验证（ASV）系统是否能通过零样本能力轻松获得对伪造攻击的鲁棒性。<br/><br/>2. 研究者系统地探索了多种类型的ASV系统和伪造攻击，包括传统和前沿技术。<br/><br/>3. 通过在八个不同的ASV系统和二十九个伪造攻击系统上进行详尽分析，研究者证明了ASV系统的进化内在包含了抵御伪造攻击的防御机制。<br/><br/>4. 然而，研究也指出，伪造攻击的进步远超ASV系统的进步，这需要进一步的研究来开发更鲁棒的ASV方法。 |
| [Diversifying and Expanding Frequency-Adaptive Convolution Kernels for Sound Event Detection](https://arxiv.org/abs/2406.05341) | 1. 提出频率动态卷积（FDY conv）的概念，它使用频率自适应的滤波器，通过频率变化组合基函数来获得性能。<br/><br/>2. 然而，FDY conv缺乏明确的平均值来多样化频率自适应滤波器，这可能限制其性能。<br/><br/>3. 为了解决这个问题，提出膨胀的频率动态卷积（DFD conv），通过引入不同 dilation size（膨胀率）到基函数中，来扩大和多样化频率自适应滤波器。<br/><br/>4. 实验结果证明了在频率维度上使用不同 dilation sizes的优势，并通过对注意力权重方差分析，证明了膨胀的基函数有效地多样化了。<br/><br/>5. 最后，提出基于类间中位滤波和以交集为基础的F1分数的DFD-CRNN模型，它在多声源检测任务上超越了FDY-CRNN，提升了3.12%的性能。 |
| [Towards Lightweight Speaker Verification via Adaptive Neural Network Quantization](https://arxiv.org/abs/2406.05359) | 1. 提出一种新型的自适应均匀精度量化方法，该方法能动态生成针对每个网络层的量化中心，基于k-means聚类。<br/><br/>2. 应用到预先训练的SV系统上，得到一系列不同位宽的量化变体。<br/><br/>3. 为增强低位宽量化模型的性能，引入混合精度量化算法以及多阶段精细微调（MSFT）策略。<br/><br/>4. 设计两种不同的二进制量化方案：静态量化器和自适应量化器，以减少1位宽度量化模型的性能损失。<br/><br/>5. 实验在VoxCeleb数据集上验证了方法的有效性，实现了4-位无损均匀精度量化，并且压缩比接近8。<br/><br/>6. 与统一精度量化相比，混合精度量化不仅在相似模型大小下获得额外性能提升，还提供了根据需求调整位宽组合的灵活性。 |
| [Should you use a probabilistic duration model in TTS? Probably! Especially for spontaneous speech](https://arxiv.org/abs/2406.05401) | 1. 提出对比研究：作者在论文中设计了实验，比较传统确定性持续时间模型（deterministic duration modeling）与基于OT-CFM的强大概率模型的持续时间。<br/><br/>2. 考察不同NAR TTS方法：作者不仅考虑了基于回归、深度生成和端到端的三种不同的非自动回归（NAR）文本到语音（TTS）方法，还针对四种不同的语料库进行了实验。<br/><br/>3. 提出对自发性演讲的特殊关注：尽管先前的研究大多只考虑了朗读的口语，但作者强调了对于更常见且变化更大的自发性演讲模式的重要性，并在实验中对此进行了验证。 |
| [Autoregressive Diffusion Transformer for Text-to-Speech Synthesis](https://arxiv.org/abs/2406.05551) | 1. 提出将音频编码为连续空间中的向量序列的方案。<br/>2. 针对低比特率音频，提出使用ARDiT（Decoder-only Diffusion Transformer）这种自回归生成器来处理受限信息的问题。<br/>3. 实验表明，ARDiT在零样本文本到语音转换任务中表现出色，并且性能可以与或超越最先进的模型相媲美。<br/>4. 通过高比特率连续语音表示，模型能够近乎完美地重构，从而实现接近完美的语音编辑。<br/>5. 研究还发现，在每个自回归步骤中使用积分Kullback-Leibler（IKL）距离进行蒸馏可以显著提升样本的质量感知。<br/>6. 同时，这种方法还能将扩散模型的迭代采样过程压缩到一步，简化了训练过程。<br/>7. ARDiT还可以被训练来预测多个连续向量，从而在采样过程中大大减少延迟。<br/>8. 最后，实验表明，其中的一个模型能够在每个评估步骤生成大约170毫秒的24kHz语音，且性能损失较小。音频样本可在特定链接获取。 |
| [Text-aware and Context-aware Expressive Audiobook Speech Synthesis](https://arxiv.org/abs/2406.05672) | 1. 提出了一种名为TACA（Text-Aware and Context-Aware）的风格建模方法，用于生成具有专业Narrator多样风格的有声书合成语音。<br/><br/>2. 建立了基于对比学习的文本意识风格空间，通过语音风格的监督来覆盖各种风格。<br/><br/>3. 利用上下文编码器来整合跨句子信息，并将从文本中获得的样式嵌入与之结合。<br/><br/>4. 将上下文编码器引入两种典型的声音合成模型：基于VITS的TTS和语言模型驱动的TTS。<br/><br/>5. 实验结果表明，这种方法能够有效地捕捉多样化的风格并保持连贯的语调，从而显著提高有声书合成语音的自然性和表达力。 |
| [An Investigation of Noise Robustness for Flow-Matching-Based Zero-Shot TTS](https://arxiv.org/abs/2406.05699) | 1. 探索了多种策略来提升噪声音频提示下生成语音的质量。<br/>2. 包括了全面的训练策略：无监督预训练（使用掩蔽语音去噪）、多说话者检测、基于DNSMOS的数据过滤，以及随机噪声混合的精细调整。<br/>3. 实验结果表明，与直接在音频提示上应用增强技术相比，这些策略显著提高了语音的可理解性、说话人相似度和整体音质。 |
| [WenetSpeech4TTS: A 12,800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark](https://arxiv.org/abs/2406.05763) | 1. 提供了WenetSpeech4TTS，这是一个基于开源的WenetSpeech数据集的多领域普通话语料库。<br/><br/>2. 专门为文本到语音任务进行了优化，通过调整段落边界、提升音频质量以及消除每个段内的说话者混合，对原始的WenetSpeech数据进行了精炼。<br/><br/>3. 跟踪了更准确的转录过程，并实施了基于质量的数据过滤过程，最终获得了12,800小时的配对音频-文本数据集。<br/><br/>4. 创造了不同大小的子集，按照段落质量分数进行分类，以便于TTS模型的训练和微调。<br/><br/>5. 使用VALL-.E和NaturalSpeech 2系统在这些子集中进行了训练和微调，以验证WenetSpeech4TTS的有效性，并为后续的TTS系统性能比较提供基准。 |
| [MaLa-ASR: Multimedia-Assisted LLM-Based ASR](https://arxiv.org/abs/2406.05839) | 1. 提出MaLa-ASR，一个基于LLM的ASR模型，能够整合来自演讲幻灯片的文本关键词以提升会议内容识别能力。<br/><br/>2. 在SlideSpeech语料库的L95和S95子集上，MaLa-ASR的平均WER分别降低到9.4%和11.7%，这代表了相对于基线模型在SlideSpeech上的报道，相对的WER下降幅度分别为27.9%和44.7%。<br/><br/>3. 通过在输入提示中添加关键词，MaLa-ASR展示了LLM在语音任务中的强大性能以及方便地整合辅助信息的能力。 |
| [Soundscape Captioning using Sound Affective Quality Network and Large Language Model](https://arxiv.org/abs/2406.05914) | 1. 提出"soundscape captioning (SoundSCap)任务"，旨在填补声音场景分析自动化和主观评价劳动密集的空白。<br/><br/>2. 建立自动声音场景描述生成器（SoundSCaper），由声学模型SoundAQnet和通用大型语言模型LLM组成。<br/><br/>3. 提供评估标准：通过16名音频/声音场景专家组成的评审团，对生成的描述质量进行评分。<br/><br/>4. 比较研究结果：在评估集上，SoundSCaper生成的描述平均分低于两位声音场景专家标注的分数0.21和0.25，但这些差异没有统计显著性。这表明模型在生成声音场景描述方面有一定的竞争力。 |
| [Accent Conversion with Articulatory Representations](https://arxiv.org/abs/2406.05947) | 1. 提出使用有效articulatory语音表示来改进用于口音转换的声学模型的想法。<br/><br/>2. 源于articulatory特征能够很好地刻画语音中的口音，提出利用articulatory信息与传统的phonetic posteriograms相结合的方法。<br/><br/>3. 针对这种结合，提出了一种基于多任务学习的声学模型。这个模型的设计目的是将articulatory和phonetic信息有效地融合在一起。<br/><br/>4. 通过客观和主观评估，证明了使用articulatory特征可以提高口音转换的效率和效果。 |
| [BS-PLCNet 2: Two-stage Band-split Packet Loss Concealment Network with Intra-model Knowledge Distillation](https://arxiv.org/abs/2406.05961) | 1. 提出BS-PLCNet 2的更新版本，旨在降低计算复杂性并进一步提高性能。<br/><br/>2. 在宽带模块设计了双路径编码结构（包括非因果和因果路径），以补偿未来信息丢失的问题。<br/><br/>3. 利用模型内部知识蒸馏策略，将非因果教师的知识传递给因果学生，从而获取未来信息。<br/><br/>4. 引入轻量级的后处理模块，用于在恢复包丢失后的音频信号中进行语音失真修复和残余噪声去除。 |
| [MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance](https://arxiv.org/abs/2406.05965) | 1. 提出MakeSinger，一种用于歌唱声音合成（SVS）的半监督训练方法。<br/><br/>2. 利用classifier-free扩散指导进行SVS模型的训练，克服了SVS数据收集成本高的问题。<br/><br/>3. MakeSinger能够从任何语音和歌唱声音数据中进行训练，无需其标注，这大大增强了对大量未标注数据的处理能力。<br/><br/>4. 在推理阶段，提出的双引导机制为文本和音高提供了反向扩散步骤中的指导，通过估计被掩码输入的分数来实现。<br/><br/>5. 实验结果表明，使用半监督方式训练的模型在发音准确性、音高精度以及整体质量方面都超越了仅依赖标注数据训练的基线。 |
| [Prompting Large Language Models with Audio for General-Purpose Speech Summarization](https://arxiv.org/abs/2406.05968) | 1. 提出了一种基于大型语言模型(LLMs)的框架，用于语音摘要。<br/><br/>2. 建立了一个端到端系统，结合了指令调优的LLM和音频编码器，将语音转换为可解释的令牌表示。<br/><br/>3. 使用包含配对的语音-文本数据集进行训练，目标是生成对相同语义信息的提示保持一致的回答。<br/><br/>4. 该框架允许LLM以与处理文本相同的模式处理语音输入，从而实现语音摘要。<br/><br/>5. 与先前的方法相比，这种方法能够概括来自任意领域的口头内容，并通过改变LLM提示策略来产生不同风格的摘要。实验结果证明了其优越性。 |
| [Separate and Reconstruct: Asymmetric Encoder-Decoder for Speech Separation](https://arxiv.org/abs/2406.05983) | 1. 提出一种分离和重建的框架，用于改进时间域语音分割的性能。<br/><br/>2. 通过在解码器中使用Siamese网络，使网络直接学习根据分离目标区分特征。<br/><br/>3. 设计了全局和局部Transformer块，以处理长序列，替代传统的双路径结构中的分块处理。<br/><br/>4. 实验结果表明，提出的分离-重建框架有效，并且结合的全局和局部Transformer能够充分取代双路径结构中的分块处理角色。<br/><br/>5. 最终模型在各种基准数据集上实现了最先进的性能，并且相比之前减少了计算量。 |
| [JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis](https://arxiv.org/abs/2406.06111) | 1. 提出新的训练策略：JenGAN，通过堆叠移动的低通滤波器来确保模型的 shift-equivariant 性质。<br/><br/>2. 防止和减少生成结果中的音色问题：通过这种方法，可以防止或减少由于频率映射不当导致的音调失真和音色异常。<br/><br/>3. 保持模型结构不变：在训练过程中使用相同的模型结构进行推理，这有助于确保模型在实际应用中能够快速地处理输入并产生高质量的输出。<br/><br/>4. 实验评估：通过实验验证JenGAN的有效性，证明它能显著提升神经语音合成（Vocoder）模型的表现，并在大多数评估指标上获得更好的分数。 |
| [The Effect of Training Dataset Size on Discriminative and Diffusion-Based Speech Enhancement Systems](https://arxiv.org/abs/2406.06160) | 1. 研究深度神经网络（DNN）为基础的语音增强系统，发现其性能通常随训练数据集大小增加而提高。<br/><br/>2. 但之前针对训练数据集大小对语音增强效果影响的研究并未考虑近年来的一些新型方法，如基于扩散的生成模型。<br/><br/>3. 扩散模型通常在大规模图像生成任务中进行训练，但它们是否也需要为语音增强提供同样大的数据量是未知的。<br/><br/>4. 此外，以往研究并未控制数据多样性，因此不清楚性能提升是因为数据规模增加还是多样性的提高。<br/><br/>5. 因此，本研究系统地探讨了训练数据集大小对流行先进州际可比的判别式和扩散型语音增强系统的性能的影响。同时，通过使用固定的一组语音片段、噪声段和双耳房间 impulse responses来生成不同大小的数据集，控制了数据多样性。 |
| [EARS: An Anechoic Fullband Speech Dataset Benchmarked for Speech Enhancement and Dereverberation](https://arxiv.org/abs/2406.06185) | 1. 发布了EARS（Expressive Anechoic Recordings of Speech）数据集，这是一个高质量的语音数据集合。<br/><br/>2. 数据集包含来自不同背景的107位演讲者的语音数据，总计100小时的清洁、无回声的语音数据。<br/><br/>3. 数据集涵盖了多种不同的说话风格，包括情感化的言语、阅读的不同风格、非语言的声音、以及自由形式的对话。<br/><br/>4. 提供了各种方法在该数据集上进行语音增强和去混响的基准测试，并通过一系列客观指标评估它们的表现。<br/><br/>5. 进行了20名参与者参与的语音增强任务的主观听觉测试，其中更倾向于生成方法。<br/><br/>6. 引入了一个盲测集，允许自动在线对上传的数据进行评估。 |
| [Label-Looping: Highly Efficient Decoding for Transducers](https://arxiv.org/abs/2406.06220) | 1. 提出了一种高效的贪婪解码算法，用于Transducer的推断。<br/>2. 针对批量处理部分假设的问题，提出使用CUDA tensor构建数据结构，以支持并行化的假设操作。<br/>3. 在解码过程中，算法采用嵌套循环设计，内层循环处理所有空预测，外层循环处理非空预测，最大化GPU并行性。<br/>4. 算法具有通用性，适用于常规的Transducers和Token-以及-Duration Transducers。<br/>5. 实验表明，与传统的批量解码算法相比，该算法在使用32个批次时可以带来高达2.0X的速度提升。此外，它还可以与其他编译器或GPU调用相关的优化技术结合使用，以获得更多的速度提升。 |
| [Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning](https://arxiv.org/abs/2406.06251) | 1. 提出Voicebox Adapter，一种将细粒度条件整合到预训练语音箱（Voicebox）语音生成模型中的新方法。<br/><br/>2. 使用交叉注意力模块实现对预训练模型的精细调整。<br/><br/>3. 探索并评估了多种有效的微调策略，以确保新添加模块与预训练模型的平滑融合。<br/><br/>4. 在三个细粒度条件生成任务中展示了Voicebox Adapter的有效性和资源效率。<br/><br/>5. 随后的实验进一步强调了Voicebox Adapter在不同数据设置下的稳健性。 |
| [Sample Rate Independent Recurrent Neural Networks for Audio Effects Processing](https://arxiv.org/abs/2406.06293) | 1. 该研究针对机器学习模型在吉他放大器和效果 pedal建模中的一个限制进行，即这些模型通常在特定采样率下训练，因此在其他速率下运行时结果不可靠。<br/><br/>2. 研究者探讨了几种修改RNN结构以使其接近采样率独立的方法，特别关注了 oversampling（过采样）这一策略。<br/><br/>3. 对于整数过采样，研究者展示了之前提出的一种基于延迟的解决方案在提供高保真采样率转换的同时，还能有效地减少频谱混叠。<br/><br/>4. 对于非整数采样率调整，研究者提出了两种新的方法，并通过实验对比证明其中一种基于立方拉格插值的延迟线方法显著优于现有方法。 |
| [VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers](https://arxiv.org/abs/2406.05370) | 1. 研究提出VALL-E 2，这是神经编码语言模型的最新进展，标志着零-shot文本到语音合成(TTS)能力的人类水平首次达到。<br/><br/>2. VALL-埃2基于其前身进行了两项重大改进：重复感知采样（Repetition Aware Sampling）优化了原始核抽样过程，考虑到了解码历史中的重复令牌。这不仅稳定了解码过程，还避免了无限循环的问题。<br/><br/>3. 分组编码建模（Grouped Code Modeling）将编码代码组织成小组，有效地缩短了序列长度，这不仅提高了推理速度，也解决了长序列建模的挑战。<br/><br/>4. 在LibriSpeech和VCTK数据集上的实验结果表明，VALL-埃2超越了先前系统，在语音鲁棒性、自然度和说话者相似性方面取得了显著优势。这是首次在这些基准上达到人类水平。此外，VALL-埃2能够持续生成高质量的语音，即使面对复杂或重复句子这样的挑战。 |
| [DAISY: Data Adaptive Self-Supervised Early Exit for Speech Representation Models](https://arxiv.org/abs/2406.05464) | 1. 提出早期退出（Early Exit）的概念，用于减少模型的延迟。<br/><br/>2. 创造名为DAISY（Data Adaptive Self-Supervised Early Exit）的方法，它决定何时退出网络，基于自监督损失进行判断，无需多次训练和微调。<br/><br/>3. 通过MiniSUPERB基准测试，证明DAISY在性能上与HuBERT相当，但其推理速度更快。<br/><br/>4. 进行适应性分析，发现DAISY根据数据的噪声水平动态调整计算成本，这表明模型能够灵活地应对不同环境下的任务。 |
| [Mmm whatcha say? Uncovering distal and proximal context effects in first and second-language word perception using psychophysical reverse correlation](https://arxiv.org/abs/2406.05515) | 1. 研究使用了反向相关性方法，系统地改变了围绕不同元音对的短语中的音高和说话速率。<br/><br/>2. 对英语（/i/-/I/）和法语（/u/-/y/）的第二语言（L2）使用者进行了测试，共收集了25名参与者的数据。<br/><br/>3. 发现元音感知实际上受到来自周围音高和说话速率的冲突效应的影响：近端的同向作用在目标前0.2秒；而远端的对比性作用可以延伸到目标前1秒甚至更远。<br/><br/>4. 结果表明，无论是母语为英语还是法语的L1或L2使用者，在感知中都展现出相似的音高和说话速率的 prosodic profiles。这提供了研究跨刺激、时间尺度和声学域的声学上下文效应的新方法。 |
| [Exploring the Benefits of Tokenization of Discrete Acoustic Units](https://arxiv.org/abs/2406.05547) | 1. 提出合并基本词汇单位为更大、可变速率单元的令牌化算法，这是自然语言处理任务中的标准方法。<br/><br/>2. 但这种想法在基于音素或离散声学单元（DAUs）的词汇中被忽视了。DAUs是音频基础上的表示方式，因其在基于离散语言模型的成功应用中扮演重要角色而日益重要。<br/><br/>3. 在本文中，作者展示了对音素单位和DAUs进行令牌化处理在三个预测任务上的优势：音素到音节转换、音素到DAUs转换以及使用DAU语言建模的无监督语音生成。<br/><br/>4. 作者通过实验展示了这种处理方式能显著提高性能，并且在训练速度和推理速度上也有提升。此外，他们还提供了理论洞察，以解释为何这种方法表现优异。 |
| [Separating the "Chirp" from the "Chat": Self-supervised Visual Grounding of Sound and Language](https://arxiv.org/abs/2406.05629) | 1. 提出DenseAV，一种新颖的双编码器地面架构，该架构通过观看视频学习高分辨率、语义有意义、音频视觉上一致的特征。<br/><br/>2. 表明DenseAV能够发现单词的“意义”和声音的“位置”，而无需显式定位监督。<br/><br/>3. 证明它能自动发现并区分这两种类型的关联，而无需任何指导。<br/><br/>4. 提供了一种新的多头特征聚合操作符，该操作符直接比较密集图像和音频表示进行对比学习，这是DenseAV定位能力的关键来源。<br/><br/>5. 对比其他系统，如只能学习全局音频和视频表示的系统，DenseAV展示了其在单词定位和声音定位方面的显著优势。<br/><br/>6. 为评估AV代表通过语音和声音触发的语义分割提供了两个新的数据集。在这些和其他数据集上，我们展示了DenseAV在语音和声音触发的语义分割任务中大幅超越了先前的工作，包括ImageBind。 |
| [Heart Sound Segmentation Using Deep Learning Techniques](https://arxiv.org/abs/2406.05653) | 1. 提出了一种新颖的心脏声音分割和分类方法，目标是S1（LUB）和S2（DUB）两种声音。<br/><br/>2. 利用FFT（快速傅里叶变换）为基础的过滤技术进行信号预处理。<br/><br/>3. 采用动态规划策略进行事件检测，帮助定位心脏声音的关键时刻。<br/><br/>4. 构建一个Siamese网络，用于实现对心脏声音的鲁棒分类，提高分类的稳定性和准确性。<br/><br/>5. 在PASCAL心脏声音数据集上，该方法展示了优于现有方法的性能。 |
| [Towards Expressive Zero-Shot Speech Synthesis with Hierarchical Prosody Modeling](https://arxiv.org/abs/2406.05681) | 1. 提出一种新的语音合成模型，该模型在大规模数据集上进行训练，包括音色和层次化的语调建模。<br/><br/>2. 强调音色是与表达力紧密相关的全局属性，因此采用全局向量来模拟说话者的音色，并引导语调建模。<br/><br/>3. 提出基于扩散模型的音高预测器，以及一个语调适应器，用于层次化地建模语调。<br/><br/>4. 实验结果表明，提出的模型不仅在音色质量上与基线相当，而且在自然度和表达力方面表现出更好的性能。 |
| [SPA-SVC: Self-supervised Pitch Augmentation for Singing Voice Conversion](https://arxiv.org/abs/2406.05692) | 1. 提出一种名为SPA-SSVC的自我监督音高增强方法，用于歌唱声音转换（SVC）任务。<br/><br/>2. 创新性地引入了循环音高变换训练策略和结构相似性指数（SSIM）损失到SVC模型中。<br/><br/>3. 实验结果在公共歌唱数据集M4Singer上表明，SPA-SSVC方法显著提高了模型在一般SVC场景和特别的跨域SVC场景中的性能。 |
| [Optimizing Multi-Stuttered Speech Classification: Leveraging Whisper's Encoder for Efficient Parameter Reduction in Automated Assessment](https://arxiv.org/abs/2406.05784) | 1. 提出对多 stuttered speech进行更有效分类的问题。<br/>2. 利用Whisper，一个先进的语音识别模型，通过其编码器来处理问题，将其视为多标签分类问题。<br/>3. 实验中使用6层的Whisper，并尝试不同的层冻结策略，以找到模型的计算效率配置。<br/>4. 研究结果表明，模型的最后一个编码层对识别口吃中的停顿至关重要。<br/>5. 该研究为口吃语音识别提供了一种计算效率高的方法，有助于适应不同方言和语言。 |
| [Do Prompts Really Prompt? Exploring the Prompt Understanding Capability of Whisper](https://arxiv.org/abs/2406.05806) | 1. 本研究探讨了Whisper，一个高性能的语音识别模型，与提示信息之间互动的问题。<br/><br/>2. 研究结果出乎意料地表明，Whisper可能并未完全理解文本提示，这与预期不同。<br/><br/>3. 发现即使在更强烈地遵循文本提示中的话题信息时，性能提升也不一定保证。<br/><br/>4. 该研究还注意到，英语提示通常优于中文提示，在两种语言的语料库上表现更好。这可能是由于这两种语言训练数据分布的差异。<br/><br/>5. 然而，Whisper表现出对语言令牌误导信息的意识，通过有效地忽略错误的语言令牌并专注于正确的，实现了这一点。<br/><br/>6. 总之，这项工作提出了关于Whisper理解提示能力的问题，并鼓励进一步的研究。 |
| [Source -Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels](https://arxiv.org/abs/2406.05863) | 1. 研究领域：探索了在数据稀少语言环境下，针对有限目标语音数据集进行的源自由领域适应技术。<br/><br/>2. 问题背景：演讲验证中的隐私政策限制和/或目标语言的语音资源稀缺，导致可用数据不足。<br/><br/>3. 检验内容：研究了源与目标之间语言和通道不匹配的情况。评估并比较了不同大小标记目标数据集下的微调方法。<br/><br/>4. 研究新算法：还探讨了一种针对无标签目标数据集的迭代聚类学习算法，以适应源自由领域适应的需求。 |
| [Zero-Shot End-To-End Spoken Question Answering In Medical Domain](https://arxiv.org/abs/2406.05876) | 1. 探究了在医疗领域，端到端（E2E）方法对于 spoken question-answering (SQA)的有效性。<br/><br/>2. 提出了一种新颖的零样本SQA方法，与传统的分阶段系统相比有所改进。<br/><br/>3. 通过在一个新的开放基准上进行的全面评估，证明了该方法在资源有限的情况下，需要的资源量最多是联合13亿参数LLM模型（1.55B参数ASR模型）的14.7倍。<br/><br/>4. 在平均准确率方面，展示了这种方法比联合大型模型具有0.5%的优势。<br/><br/>这些发现强调了端到端方法在资源有限的SQA任务中潜在价值。 |
| [Contrastive Learning from Synthetic Audio Doppelgangers](https://arxiv.org/abs/2406.05923) | 1. 提出利用合成音频解决音频代表学习问题的方案。<br/>2. 利用随机参数扰动声合成器生成双胞胎样合成音，作为正例对因果变化进行对比。<br/>3. 这些合成音提供了丰富多样的对比信息，难以通过现有音频的变换实现。<br/>4. 该方法在标准音频分类基准上产生了与真实数据相当的强大表示，证明了使用合成音频的有效性。<br/>5. 方法具有轻量级特点，无需存储数据，且只有一个关键超参数，进行了详尽分析。 |
| [RawBMamba: End-to-End Bidirectional State Space Model for Audio Deepfake Detection](https://arxiv.org/abs/2406.06086) | 1. 提出RawBMamba，一个端到端的双向状态空间模型，用于音频深度伪造检测，以捕捉短-长范围的判别信息。<br/><br/>2. 利用 sinc 层和多层卷积层来捕获短期特征，设计了双向 Mamba 模型来解决单向 Mamba 模型的问题，并进一步捕获长期特征信息。<br/><br/>3. 开发了一种双向融合模块，用于整合嵌入，增强音频上下文表示，并结合短-长范围信息。<br/><br/>4. 实验结果表明，提出的 RawBMamba 在 ASVspoof2021 LA 数据集上比 Rawformer 提高了 34.1\% 的性能，且在其他数据集上也展示了竞争力。 |
| [StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection](https://arxiv.org/abs/2406.06097) | 1. 提供了StreamAtt，这是第一个针对StreamST（流式语音到文本翻译）的策略。<br/><br/>2. 推出了StreamLAAL，这是设计用来与SimulST（同步语音到文本翻译）相关指标进行比较的第一个StreamST延迟度量。<br/><br/>3. 通过在MuST- C v1.0的8种语言上进行了广泛的实验，验证了StreamAtt相对于基于流的基线和相关SimulST策略的有效性。 |
| [Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge](https://arxiv.org/abs/2406.06139) | 1. 提出Thunder，一个统一的回归-扩散模型。<br/>2. 该模型利用了Brownian bridge过程，使得模型能够在两种模式下运作。<br/>3. 在设置中，可以通过接近1的时间步长访问回归模式。<br/>4. 然而，标准得分为基础的扩散建模在这种设置下表现不佳，因为存在梯度不稳定问题。<br/>5. 为解决这个问题，论文提出修改扩散模型，使其预测清洁语音而非分数函数，从而实现与更紧凑模型相比具有竞争力的性能。 |
| [Quantifying the effect of speech pathology on automatic and human speaker verification](https://arxiv.org/abs/2406.06208) | 1. 该研究探讨了口腔癌手术后对语音病理学的影响，如何影响自动说话者验证（ASV）系统的性能。<br/><br/>2. 利用两个荷兰语数据集，NKI-OC-VC和SPOKE，它们包含手术前后同个演讲者的音频，评估了语音病理学变化与ASV性能的关系。<br/><br/>3. 研究还探讨了语音严重程度的客观/主观指标是否与ASV性能相关联。<br/><br/>4. 最后，进行了一项感知研究，比较了ASV系统和人类听众对相似度和严重性评分的判断。 |
| [Zero-Shot Audio Captioning Using Soft and Hard Prompts](https://arxiv.org/abs/2406.06295) | 1. 该论文提出了一种基于CLAP模型的音频captioning方法，以解决传统方法中的数据饥饿问题和跨领域性能下降问题。<br/><br/>2. 该方法不需要音频标注，而是依赖于文本数据进行训练，这使得模型能够从跨模态语义空间中的文本特征生成文本。<br/><br/>3. 在推理阶段，模型利用CLAP提供的音频-文本对齐信息，从音频特征生成描述性的文本。<br/><br/>4. 论文设计了两种策略来缓解文本和音频嵌入之间的差异：一种是基于混合增强的软提示，另一种是基于检索的声学意识硬提示。这些方法旨在提高模型的泛化性能，使其能够更准确、稳健地生成音频caption。 |
| [Unsupervised Improved MVDR Beamforming for Sound Enhancement](https://arxiv.org/abs/2406.06310) | 1. 提出UIMVDR，这是一种未监督的改进最小变异（Minimum Variance Distortionless Response，MVDR）模型。<br/><br/>2. UIMVDR利用单通道数据通过无监督训练和波束形成进行多通道分离。<br/><br/>3. 实验结果表明，UIMVDR在未监督条件下具有良好的泛化能力，并且能够改善与监督模型相比的分离性能，特别是在有限监督数据的情况下。<br/><br/>4. 该方法使用在线可获取的数据，减少了为多通道方法收集数据所需的努力。 |
| [A Parameter-efficient Language Extension Framework for Multilingual ASR](https://arxiv.org/abs/2406.06329) | 1. 该研究探讨了多语言语音识别模型（MASR）的持续学习问题，尝试将其概率分解为两个子问题：语言身份预测（LP）和跨语言适应（XLA）。<br/><br/>2. 基于这个分解，作者提出了一种架构为基础的语言扩展框架，旨在解决连续学习中的遗忘问题。<br/><br/>3. 该框架探索了参数效率高的微调模块（PEFT）作为XLA的潜在候选。实验在5种新语言上进行，数据资源大小广泛。<br/><br/>4. 结果表明，最佳性能的PEFT模块能够在所有语言中获得满意的表现，并且在其中三个语言上超过了持续联合学习设置的性能。<br/><br/>5. 值得注意的是，专注于权重参数或输入特征的PEFT方法在性能上显示出局限性，与插入轻量级模块（如Adapter）的方式相比，其扩展能力较差。 |
| [An automatic analysis of ultrasound vocalisations for the prediction of interaction context in captive Egyptian fruit bats](https://arxiv.org/abs/2406.06332) | 1. 提出使用深度神经网络预测动物（Rousettus Aegyptiacus）之间互动的上下文的新方法。<br/><br/>2. 实验结果表明，这种方法达到了超过30%的未加权平均召回率，这远超随机水平。<br/><br/>3. 通过对比分析，论文指出这些结果与传统的统计分析存在差异，进一步证明了深度学习模型的有效性。<br/><br/>4. 这项工作对于自动分析动物行为状态的声音数据具有重要意义。 |
| [Audio-based Step-count Estimation for Running -- Windowing and Neural Network Baselines](https://arxiv.org/abs/2406.06339) | 1. 研究音频为基础的步数计数估计，特别是在户外跑步中的应用。<br/><br/>2. 实现了基于窗口的步数差绝对误差为1.098，以及预测5秒音频窗口内步数时的皮尔逊相关系数为0.479。<br/><br/>3. 展示了音频传感器监测生理变量的可能性，并为进一步利用音频传感器进行更全面的跑步者行为刻画奠定了基础。 |
| [Predicting Heart Activity from Speech using Data-driven and Knowledge-based features](https://arxiv.org/abs/2406.06341) | 1. 该研究展示了自我监督的语音模型在预测心脏活动参数方面优于传统的声学特征。<br/><br/>2. 研究结果表明，数据驱动的表示在生理信号预测任务中具有优势。<br/><br/>3. 论文还强调了个体差异对模型泛化能力的影响，这提示在相关领域需要更多的基于语音的生理数据来减少说话者相关的挑战。 |
| [mHuBERT-147: A Compact Multilingual HuBERT Model](https://arxiv.org/abs/2406.06371) | 1. 提供了mHuBERT-147，这是第一个大规模多语言的 HuBERT 语音表示模型。<br/><br/>2. 模型是通过使用 faiss-基于聚类的方法来扩展 HuBERT 的多迭代方法，这使得标签分配比原始方法快5.2倍。<br/><br/>3. 应用了一种新的多语言批次上采样策略，利用了语言和数据集的多样性。<br/><br/>4. 在经过3个训练迭代后，模型参数量仅为95M，但性能超越了更大规模但参数更多模型在同等或更多数据上的表现。<br/><br/>5. 在ML-SUPERB 10min/1h领导板上，该模型分别排名第二和第一，且所有LID任务的SOTA分数。 |
| [MOSA: Music Motion with Semantic Annotation Dataset for Cross-Modal Music Processing](https://arxiv.org/abs/2406.06375) | 1. 提供了名为MOSA的跨模态音乐数据集。<br/>2. MOSA数据集包含高质量的3D动作捕捉数据，与音频同步，以及对音高、节拍、短语、动态、发音方式、和声等音乐元素的详细注释。<br/>3. 数据集由23专业音乐家表演了742个专业音乐作品组成，总时长超过30小时，包含570千个音符。<br/>4. MOSA数据集是目前最大规模的跨模态音乐数据集之一，具有详细的音级注释，可用于音乐信息检索（MIR）和音乐内容生成任务。 |
| [Meta Learning Text-to-Speech Synthesis in over 7000 Languages](https://arxiv.org/abs/2406.06403) | 1. 提出挑战性任务：构建一个单一的文本到语音合成系统，能够生成超过7000种语言的语音。<br/><br/>2. 创新方法：利用大规模多语种预训练和元学习相结合的新技术来近似语言表示。<br/><br/>3. 实现零样本语音合成：在缺乏可用数据的语言中实现零样本语音合成。<br/><br/>4. 系统验证：通过客观指标和人类评估，在多样化的语言环境中验证系统性能。<br/><br/>5. 公开资源分享：发布代码和模型，以支持拥有有限语言资源的社区，并促进语音技术领域的进一步创新。 |
| [Controlling Emotion in Text-to-Speech with Natural Language Prompts](https://arxiv.org/abs/2406.06406) | 1. 提出了一种基于情感丰富文本作为提示的系统，该系统条件于从文本中提取的嵌入。<br/><br/>2. 在Transformer架构的基础上，整合了说话者和提示嵌入的联合表示，在系统设计的不同阶段使用。<br/><br/>3. 训练模型的数据集是合并的情感语音和文本数据，并且在每个训练迭代中都会变化提示，以增加模型的泛化能力。<br/><br/>4. 通过客观和主观评估结果，展示了该条件合成系统的潜力，能够准确地将提示中的情感转移到语音中。同时，保持了说话者身份的精确可追踪性以及高质量和易理解的语音输出。 |
| [Multimodal Contextualized Semantic Parsing from Speech](https://arxiv.org/abs/2406.06438) | 1. 提出Semantic Parsing in Contextual Environments（SPICE）任务，旨在增强人工智能代理的环境意识，通过整合多模态输入与先前背景信息。<br/><br/>2. SPICE超越传统语义解析，提供结构化、可解释的框架，用于动态更新代理的知识库，以新信息为依据。<br/><br/>3. 创造VG-SPICE数据集，挑战代理进行视觉场景图构建，从口头对话交流中获取信息，强调语音和视觉数据的整合。<br/><br/>4. 提供Audio-Vision Dialogue Scene Parser（AViD-SP）模型，用于在VG-SPICE数据集上运行，这些创新旨在改进多模态信息处理和集成能力。 |
| [Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer](https://arxiv.org/abs/2309.07648) | 1. 提出C-FNT，一种将类为基础的语言模型融入到神经转录器（FNT）中的端到端模型。<br/><br/>2. 在C-FNT中，命名实体的LM分数可以关联到其类别而不是具体的表面形式。<br/><br/>3. 实验结果表明，C-FNT显著减少了命名实体错误，同时在一般词识别性能上没有受损。 |
| [LUPET: Incorporating Hierarchical Information Path into Multilingual ASR](https://arxiv.org/abs/2401.03689) | 1. 提出了一种新的多语言自动语音识别(ASR)设计，名为LUPET。<br/><br/>2. LUPET设计为分层信息路径，从浅层到深层逐级编码多种语言和声学信息的多个方面。<br/><br/>3. 路径始于语言身份(LID)预测，然后是音频单元发现、音素共享，最后通过混合专家路由进行令牌识别。<br/><br/>4. 在Common Voice语料库上进行了10种语言的ASR实验。结果显示LUPET在性能上超越了基线系统。<br/><br/>5. 最重要的是，LUPET有效地解决了高资源语言与低资源语言在多语言环境中的性能妥协问题。 |
| [Synthetic training set generation using text-to-audio models for environmental sound classification](https://arxiv.org/abs/2403.17864) | 1. 研究了文本到音频模型在环境声音分类任务中的应用效果。<br/><br/>2. 特别关注了使用这些模型生成的数据进行训练时，两种不同分类系统的性能表现。<br/><br/>3. 分析了两种情况：一是增加训练数据来源，包括来自两个不同文本到音频模型的数据；二是仅使用由模型生成的合成音频作为训练数据。<br/><br/>4. 结果表明，文本到音频模型在数据增强方面是有效的，但当依赖单一生成音频时，其性能下降。 |
| [ConPCO: Preserving Phoneme Characteristics for Automatic Pronunciation Assessment Leveraging Contrastive Ordinal Regularization](https://arxiv.org/abs/2406.02859) | 1. 提出了一种针对基于回归的自动发音评估（APA）模型的对比性音素有序常规化器（ConPCO），用于生成更具有音素区分性的特征。<br/><br/>2. ConPCO设计时考虑了音素特征的保留以及目标输出之间的有序关系，同时通过对比学习对音形表示进行优化。<br/><br/>3. 提供了一个层次化的APA模型来评估方法的有效性。实验在speechocean762基准数据集上进行了大量验证，表明该方法既可行又有效，与一些尖端的基线相比具有竞争力。 |
| [Singing Voice Graph Modeling for SingFake Detection](https://arxiv.org/abs/2406.03111) | 1. 提出SingGraph模型，这是针对歌唱声音深度伪造（SingFake）检测的一个创新方法。<br/><br/>2. 模型结合了MERT音频音乐理解模型的音高和节奏分析能力，以及wav2vec2.0语言模型对歌词语义的理解。<br/><br/>3. 推崇使用基于音乐领域知识的RawBoost和beat matching技术进行歌唱声音增强，以提升SingFake检测性能。<br/><br/>4. 通过在SingFake数据集上实验，该方法实现了新的最先进的（SOTA）结果，并超越了之前SOTA模型在三个不同场景下的表现。 |
| [Looking Similar, Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning](https://arxiv.org/abs/2304.05600) | 1. 探究了音频视觉表示学习中，多音频轨道与视觉场景对应关系的影响。<br/><br/>2. 利用电影和电视节目的配音版本来增强跨模对比学习。<br/><br/>3. 提出的方法能够学习到不同语音的音频代表，类似于相同视频的内容。<br/><br/>4. 通过一系列全面的实验研究了不同的训练策略对下游听觉和视听任务性能的影响。<br/><br/>5. 结果表明，这种通用方法在改善多种下游任务性能的同时，整体上并未显著影响语言任务的表现。这强调了在学习场景级别的音频视觉对应时考虑语音变化的重要性。 |
| [Streaming Audio Transformers for Online Audio Tagging](https://arxiv.org/abs/2305.17834) | 1. 提出新型模型：研究者引入了名为"Streaming Audio Transformers" (SAT)的模型，结合ViT架构和Transformer-XXL类似的块处理方式。<br/><br/>2. 优化长范围音频信号处理：SAT设计用于高效处理长距离音频信号，这有助于减少因音频信号过长而导致的问题。<br/><br/>3. 比较与现有SOTA方法：研究者将他们提出的SAT模型与其他基于Transformer的SOTA方法进行了基准比较。结果显示SAT在延迟为2s和1s时的mAP指标上取得了显著提升，并且内存使用量和计算开销也大大降低。<br/><br/>4. 公开检查点：研究者还公开了他们的SAT模型的检查点，便于其他研究人员进一步研究或应用。 |
| [End-to-End Speech-to-Text Translation: A Survey](https://arxiv.org/abs/2312.01053) | 1. 提供了关于端到端（E2E）语音识别和翻译的全面回顾。<br/>2. 概括了用于ST任务的模型、评估指标和使用的数据集，为研究者提供了参考。<br/>3. 分析了ST任务面临的挑战，并提出了未来的研究方向，这些新见解有助于推动领域的发展。 |
| [Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls](https://arxiv.org/abs/2402.09508) | 1. 提出了一种新的音乐生成方法，使用参数效率高的异构适应器结合掩码训练策略。<br/><br/>2. 该方法使得大型语言模型能够无缝处理音乐补图任务，即音乐编辑中的填充缺失部分。<br/><br/>3. 方法还整合了帧级内容为基础的控制，支持根据轨道条件进行音乐细化和根据乐谱条件进行音乐编排。<br/><br/>4. 实验应用到Fine-tune MusicGen，一个领先的自回归音乐生成模型上，证明了在多种音乐编辑任务中具有显著成效。 |
| [Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations](https://arxiv.org/abs/2406.02178) | 1. 提出Audio Mamba，一个针对学习通用音频表示的 selective state space 模型。<br/><br/>2. 通过随机遮罩谱块并利用自监督方式进行训练，模型能够从音频数据中学习。<br/><br/>3. 实验结果表明，预训练在AudioSet数据集上的模型，在十种多样化的音频识别下游任务上，显著优于同类基于SSAST的自监督音频处理方法，并展现出更好的性能对比。 |
| [An Independence-promoting Loss for Music Generation with Language Models](https://arxiv.org/abs/2406.02315) | 1. 提出独立性促进损失（Independence-Promoting Loss，IPL）的概念，用于对音乐生成语言模型中使用的自动编码器进行正则化。<br/><br/>2. IPL是一种基于最大均差原则的代理信息熵指标，适用于在可重复的核希尔伯特空间（Reproducible Kernel Hilbert Spaces，RKHSs）中实施训练和优化。<br/><br/>3. 该论文提出的目标是通过IPL促进模型学习独立的代码库，从而改善音乐生成的质量。<br/><br/>4. 这个贡献点还表明了IPL方法的通用性，可以应用于其他多流编码器。 |
| [LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes](https://arxiv.org/abs/2406.02897) | 1. 提出LiveSpeech，一个基于全自回归语言模型的零-shot文本到语音方法。<br/><br/>2. 为适应低延迟场景，提出使用动态代码本损失权重的方法。这种方法考虑了每个帧中代码本的贡献，并聚焦于困难实例。<br/><br/>3. 探索并提出了分组编码本和并行处理组的策略。这有助于提高模型在保持内容准确性、语音相似性、音频质量以及推理速度的同时，适应低延迟流媒体应用的能力。 |
| [Generalized Source Tracing: Detecting Novel Audio Deepfake Algorithm with Real Emphasis and Fake Dispersion Strategy](https://arxiv.org/abs/2406.03240) | 1. 提出Real Emphasis and Fake Dispersion(REFD)策略，用于音频深度伪造算法识别。<br/><br/>2. 该策略在区分ID样本和识别OOD样本方面表现出有效性。<br/><br/>3. 对于有效的OOD检测，研究了现有的后验方法，并提出了NSD，一种新的OOD识别方法。<br/><br/>4. NSD通过考虑特征和logits分数的相似性来识别新深度伪造算法。<br/><br/>5. 在2023年音频深度伪造检测挑战赛(ADFD Challenge 2023)的第三赛道上，REFD作为单一系统达到了86.83%的F1分数，展示了其最先进的性能。 |
| [Genuine-Focused Learning using Mask AutoEncoder for Generalized Fake Audio Detection](https://arxiv.org/abs/2406.03247) | 1. 提出Genuine-Focused Learning (GFL)框架，旨在设计高度泛化的Fake Audio Detection (FAD)方法。<br/><br/>2. 创造性地应用Counterfactual Reasoning Enhanced Representation (CRER)，基于音频重建，使用Mask AutoEncoder (MAE)架构来精确模拟真实音频特征。<br/><br/>3. 为减少训练过程中假音频的影响，引入了真实的音频重建损失，保持对学习真实数据特征的关注。<br/><br/>4. 提取内容相关的瓶颈(BN)特征，从MAE中提取，以补充原始音频的知识。<br/><br/>5. 这些BN特征被动态融合到CRER中，进一步提高了模型的鲁棒性。 |
