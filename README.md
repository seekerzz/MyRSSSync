# 五里墩茶社
---
| Title | Date | Summary |
| --- | --- | --- |
# 小工蚁创始人
---
| Title | Date | Summary |
| --- | --- | --- |
# AIGCLINK
---
| Title | Date | Summary |
| --- | --- | --- |
# 技术爬爬虾
---
| Title | Date | Summary |
| --- | --- | --- |
# 秋芝2046
---
| Title | Date | Summary |
| --- | --- | --- |
# GitHub All Languages Daily Trending
---
| Title | Summary |
| --- | --- |
| [BloopAI/vibe-kanban](https://github.com/BloopAI/vibe-kanban) | Vibe Kanban是一个基于云的敏捷项目管理工具，以下是对文档中的关键信息进行的简化和翻译：<br/><br/>1. **使用体验**：<br/>   - 用户可以轻松地添加、分配任务，并与团队协作完成工作。<br/>   - 提供了定制看板板以适应不同的项目需求。<br/><br/>2. **功能特点**：<br/>   - 自定义仪表板：允许用户创建个性化的视图，用于监控和跟踪项目状态。<br/>   - 任务管理与分配：支持添加、编辑、移动、标记任务等操作，并可通过拖拽进行优先级调整。<br/>   - 看板板个性化：能够自定义板的颜色、布局和列结构。<br/><br/>3. **性能和设计**：<br/>   - 高效工作流：Vibe Kanban通过减少冗余动作和提高可见性，帮助团队更高效地协作。<br/>   - 优化界面设计：提供简洁明了的UI，提升用户体验。<br/><br/>4. **技术实现**：<br/>   - 后端服务：使用Node.js构建API和后端逻辑，并利用PostHog进行数据跟踪分析。<br/>   - 前端技术栈：前端采用TypeScript和React框架开发，确保高性能的用户界面体验。<br/><br/>5. **部署方式**：<br/>   - 支持远程部署，允许在不直接访问服务器的情况下运行Vibe Kanban。这包括通过SSH配置远程服务器上的VSCode编辑器。<br/>   - 提供了针对不同环境（如Cloudflare Tunnel、ngrok）的接入方案，确保项目可以远程访问。<br/><br/>6. **安全性**：<br/>   - 数据安全：强调了SSL证书的重要性，用于保护数据传输的安全性。<br/><br/>7. **开发和文档**：<br/>   - 开源社区参与：邀请开发者贡献代码并提供详细的API文档。<br/>   - 提供了完整的构建和部署指南，便于新手快速上手。<br/><br/>总体来说，Vibe Kanban是一个功能全面、易于使用且可定制化的敏捷项目管理工具。其设计旨在提高团队协作效率，并通过云平台提供了灵活的部署和访问选项。 |
| [openai/openai-cookbook](https://github.com/openai/openai-cookbook) | 该文本提供了使用OpenAI API的示例代码和指南，包括常见任务的操作说明。用户需拥有OpenAI账户及API密钥以运行这些示例，并设置环境变量`OPENAI_API_KEY`或在IDE根目录下的`.env`文件中配置。大部分代码用Python编写，但也适用于其他语言。同时推荐了一些网络上的相关资源。该内容遵循MIT许可协议。 |
| [afkarxyz/SpotiFLAC](https://github.com/afkarxyz/SpotiFLAC) | 该GitHub仓库提供无需账号即可从Tidal、Qobuz与Amazon Music获取Spotify歌曲的真正FLAC格式，支持Windows、macOS与Linux操作系统。包含SpotiFLAC下载链接及截图，并推荐SpotiDownloader项目用于MP3和FLAC格式转换。声明仅用于教育或个人非营利用途，不涉及版权侵权；开发者对软件不提供任何保证且不承担法律责任。 |
| [google-gemini/computer-use-preview](https://github.com/google-gemini/computer-use-preview) | ### 中文概述：<br/><br/>这份文档详细介绍了Gemini计算机使用预览系统的工作原理、环境设置和已知问题。以下是关键点的中文摘要：<br/><br/>1. **工作原理**：<br/>   - Gemini系统利用自然语言指令来驱动浏览器操作，模仿人类行为。<br/>   - 它将屏幕捕获结果发送给Gemini模型进行解析，并生成相应的反馈。<br/><br/>2. **环境支持**：<br/>   - 支持两种主要环境：Playwright和Browserbase，分别提供了不同的功能特性与限制。<br/>   - Playwright是一个用于自动化测试的库，特别适合网页操作；而Browserbase则可能提供更稳定或者特定功能的支持。<br/><br/>3. **配置参数**：<br/>   - `--query` 参数用于指定要执行的操作命令或任务描述。<br/>   - `--env` 参数允许选择使用Playwright或Browserbase作为运行环境。<br/>   - 可以设置初始加载页面、启用鼠标热点高亮等功能，用于调试和优化体验。<br/><br/>4. **环境变量**：<br/>   - 为确保系统正常工作，需要提供Gemini API密钥以及（当选择Browserbase时）的API密钥和项目ID。<br/><br/>5. **已知问题**：<br/>   - 在某些操作系统上，Playwright可能无法正确捕获`<select>`元素的屏幕截图，因为这些元素由操作系统渲染。<br/>   - 提供了使用Browserbase作为替代方案或通过注入第三方脚本来解决这个问题的方法。<br/><br/>该系统主要目标是为用户提供一个自动化、响应式的计算机操作模拟工具，能够根据自然语言指令完成一系列复杂的任务。 |
| [organicmaps/organicmaps](https://github.com/organicmaps/organicmaps) | **Organic Maps项目介绍**<br/><br/>- **项目概述**: Organic Maps是一个免费的离线地图应用，提供全球范围的地图数据和离线导航功能。应用程序支持多种语言版本，并提供了多种交互方式如Telegram, Facebook, X（Twitter）, Instagram等。<br/><br/>- **开发与发布**: 该应用在Apple App Store中的ID为1567437057，在Google Play商店的ID为app.organicmaps。<br/><br/>- **合作与贡献**：<br/>  - 用户可以通过Star项目来表达支持。<br/>  - 在[GitHub]上报告错误或提出功能需求。<br/>  - 加入Telegram频道[@OrganicMaps, @OrganicMapsRu, @OrganicMapsTR]进行交流和获取帮助。<br/>  - 使用Mastodon, Facebook, X（Twitter）等社交媒体关注更新。<br/><br/>- **社区指南**: 社区遵循CNCF的代码行为准则，确保友好、尊重和包容性。<br/><br/>- **许可证**：<br/>  - Organic Maps应用本身使用Apache License 2.0发布。<br/>  - 地图数据文件(.mwm)有单独的许可条款，请参阅`DATA_LICENSE.txt`获取详情。<br/><br/>- **白标合作**：<br/>  对于希望以白标形式或使用Organic Maps服务器的公司或项目，应事先与[legal@organicmaps.app]联系。建议在应用中明确提及“有机地图项目”和可点击链接至[https://organicmaps.app]。<br/><br/>- **用户评价**: 鼓励用户在App Store和Google Play上进行评分，并提供反馈。 |
| [nocodb/nocodb](https://github.com/nocodb/nocodb) | NocoDB是一个开源的无代码数据库平台，旨在提供给所有互联网企业一个强大且开放源码的选择。它的目标是实现数据管理与协作上的革命性突破，为用户带来更高效、灵活和安全的数据处理体验。<br/><br/>#### 主要特点：<br/><br/>1. **丰富的表格界面**：<br/>   - 支持基础操作如创建、读取、更新和删除表、列和行。<br/>   - 提供字段操作功能，如排序、筛选、分组以及隐藏/显示列等。<br/>   - 提供多种视图类型，包括网格、画廊、表单、看板和日历视图。<br/>   - 有权限管理选项，包含协作视图和锁定视图。<br/>   - 支持公共或带有密码保护的私有内容共享。<br/><br/>2. **功能强大的App Store**：<br/>   提供集成服务，包括聊天应用（如Slack、Discord）、邮件服务（AWS SES等）以及存储解决方案（如AWS S3、Google Cloud Storage、Minio）。<br/><br/>3. **程序化访问**：<br/>   - REST API：通过API接口进行数据操作。<br/>   - NocoDB SDK：提供SDK供编程语言集成使用。<br/><br/>#### 创新点：<br/><br/>NocoDB的目标在于解决传统数据库与电子表格工具在速度和功能上的差异，打破专有SaaS服务带来的锁定、价格波动等问题。它的使命是为全球互联网企业提供一个更加开放、高效且易于操作的无代码数据库平台，以期实现技术民主化，并激发更多用户参与到在线构建和创新中。<br/><br/>#### 开源与贡献：<br/><br/>NocoDB遵循AGPLv3开源许可证，鼓励社区参与开发与贡献。它通过GitHub接收并整合来自全球开发者的技术贡献。<br/><br/>总结，NocoDB致力于为互联网业务提供一种更高效、透明且灵活的数据库解决方案，旨在打破传统数据库的局限性，并促进数据管理方式的创新。 |
| [resemble-ai/chatterbox](https://github.com/resemble-ai/chatterbox) | Chatterbox-TTS是Resemble AI团队开发的一款文本转语音模型，它支持多种语言，并具有内置的Perth水印技术来确保AI责任。以下是几个关键点：<br/><br/>1. **功能与性能**：<br/>   - 支持多国语言，包括中文等28种语言。<br/>   - 提供了不同的设置参数以适应不同场景的需求，如语速、夸张度等。<br/>   - 包含Perth水印，用于防篡改和版权保护。<br/><br/>2. **使用方法与特性**：<br/>   - 包括API文档及代码示例帮助用户快速集成模型到项目中。<br/>   - 说明了如何提取内置的水印信息以验证音频的真实性。<br/><br/>3. **额外资源**：<br/>   - 提供官方Discord频道，便于开发者社区交流和合作。<br/>   - 论文或技术报告的引用格式，鼓励用户在应用Chatterbox-TTS时进行适当引用。<br/><br/>4. **责任与安全**：<br/>   - 强调不要使用模型进行非法活动，并提醒用户的输入可能源自公开网络数据。<br/><br/>总之，Chatterbox-TTS是一款功能全面、性能优秀的文本转语音工具，同时注重了版权保护和用户行为规范。通过提供详细的API文档和支持社区，Resemble AI旨在推动技术的负责任发展与广泛应用。 |
| [sansan0/TrendRadar](https://github.com/sansan0/TrendRadar) | 本篇文档是关于一个名为TrendRadar的热点追踪与分析工具的详细教程。TrendRadar能够从11多个平台上抓取热门内容，并根据用户自定义的关键字、通知方式以及配置参数生成并推送相关报告。<br/><br/>**部署方式**<br/>- **云端部署**：通过fork项目到GitHub，利用其提供的托管服务。<br/>- **本地部署**：使用Docker进行快速部署。首先需在本地安装Docker环境，并按照TrendRadar的Docker文件构建镜像及运行容器。<br/><br/>**通知配置**<br/>提供了多种通知方式的选择：<br/>1. **企业微信**、**飞书**、**钉钉**等即时通讯工具。<br/>2. **Telegram**和**邮件**等通信渠道。<br/>用户需要在GitHub仓库中填写适当的参数以启用这些通知功能。<br/><br/>**关键词配置**<br/>用户可以自定义报告中的关键词，通过一个文本文件（`config/frequency_words.txt`）来指定普通词、必须词以及过滤词。这有助于更精确地筛选和分析特定领域的热点信息。<br/><br/>**运行模式选择**<br/>TrendRadar支持三种运行模式：<br/>1. **daily**：每天生成一次汇总报告。<br/>2. **current**：实时推送当前的榜单内容。<br/>3. **incremental**：仅推送新增的内容，适合追踪变化情况。<br/><br/>**时间窗口控制**<br/>用户可以根据需要设置一个时间窗口限制，来调整推送的时间范围。<br/><br/>**自动运行与报告生成**<br/>系统在完成抓取、筛选关键词以及应用权重算法排序后，会自动生成HTML格式的报告，并通过之前配置的通知渠道进行推送。<br/><br/>**多渠道通知**<br/>支持多种方式接收精准信息推送，减少因过载造成的遗漏或错误信息。<br/><br/>**许可证**<br/>TrendRadar采用GNU通用公共许可证v3.0（GPL-3.0）发行和许可。<br/><br/>总结来说，TrendRadar是一个功能全面的工具，适合用于追踪多平台上的热点内容，并通过灵活的通知方式提供定制化的实时信息推送。 |
| [harvard-edge/cs249r_book](https://github.com/harvard-edge/cs249r_book) | 这个表格列出了“CS249R”这本书的贡献者，包括不同的作者、编辑和贡献者。表中详细列举了各个角色以及他们对本书所做出的具体贡献，并通过各种符号表示。例如：<br/><br/>- **书籍**：“CS249R”为书籍标题。<br/>- **章节**：列出了各章节的编号（如Ch01）。<br/>- **小节**：对于每个章节，进一步细分为不同的小节或部分（如Ch01.01、Ch01.02等）。<br/><br/>这个表格提供了一种清晰的方式，让读者能够了解本书内部结构和不同贡献者的作用。通过这种方式，可以追踪到每位作者在特定内容上的工作，便于理解书籍整体的构建过程以及各个部分的责任分配。这有助于识别主要贡献者，并为未来的更新或修订提供参考。 |
| [timescale/pg-aiguide](https://github.com/timescale/pg-aiguide) | pg-aiguide是一个用于PostgreSQL的AI辅助工具，它通过提供文档搜索和技能应用功能来帮助用户更好地理解和使用PostgreSQL数据库。主要特点包括：<br/><br/>1. **语义搜索**：<br/>   - `semantic_search_postgres_docs`：在特定版本的PostgreSQL官方手册中执行语义搜索。<br/>   - `semantic_search_tiger_docs`：查询Tiger Data的文档库，包含TimescaleDB和其他扩展。<br/><br/>2. **AI优化的最佳实践技能**：<br/>   - `view_skill`功能提供了经过挑选的最佳实践指导，帮助用户在schema设计、索引策略、数据类型选择、数据完整性约束、命名约定、性能调优和现代PostgreSQL特性方面作出决策。<br/><br/>3. **生态系统文档支持**：目前支持TimescaleDB，并计划在未来增加对pgvector和PostGIS的支持。鼓励社区贡献更多扩展和支持。<br/><br/>4. **开发与贡献**：<br/>   开发者可以查看`DEVELOPMENT.md`指南来了解如何本地运行MCP服务器、添加新技能和文档等。<br/>   <br/>5. **合作与贡献**：欢迎提供新的PostgreSQL最佳实践建议、额外的文档资源、搜索质量优化以及提交bug报告和功能想法。<br/><br/>6. **许可证**：<br/>   采用Apache 2.0许可，鼓励社区参与和贡献。<br/><br/>pg-aiguide旨在通过AI技术简化PostgreSQL的学习曲线，并提高用户在设计和维护数据库时的效率。 |
# eess.AS updates on arXiv.org
---
| Title | Summary |
| --- | --- |
| [MiMo-Audio: Audio Language Models are Few-Shot Learners](https://arxiv.org/abs/2512.23808) | 贡献点如下：<br/><br/>1. **提出大规模预训练对音频语言模型的泛化能力**：论文表明，通过扩大预训练数据到超过一百万小时，能够增强模型在各种音频任务上的少样本学习能力。这为探索和优化用于音频领域的大规模预训练模型提供了新的路径。<br/><br/>2. **系统性评估少样本学习能力**：作者开发了一个全面的评估框架来测试MiMo-Audio在不同音频任务中的泛化性能，并发现MiMo-Audio-7B-Base在公开源代码模型中实现了最高水平的表现。这包括了对语音智能和音频理解基准的分析。<br/><br/>3. **展示跨任务的泛化能力**：MiMo-Audio-7B-Base不仅能够在训练数据中找到的任务上表现出色，还能处理从其训练数据中不存在的任务，如声音转换、风格转移和语音编辑。这显示了模型在不同任务之间的适应性和灵活性。<br/><br/>4. **增强后处理阶段的能力**：论文通过收集多元化的指令调参语料库并引入思考机制到音频理解和生成中，提高了MiMo-Audio的性能。MiMo-Audio-7B-Instruct在音频理解、口语对话和instruct-TTS评估中实现了公开源代码的最高水平，并且接近或超越了闭源模型的表现。<br/><br/>5. **提供可访问的资源**：论文提供了MiMo-Audio模型的检查点和全面评估套件的获取链接（https://github.com/XiaomiMiMo/MiMo-Audio），为研究者和开发者提供了一个宝贵的资源库，以用于进一步的研究、学习和应用。 |
| [Regularized autoregressive modeling and its application to audio signal reconstruction](https://arxiv.org/abs/2410.17790) | ### 贡献点：<br/><br/>1. **提出全面且通用的自回归（AR）建模框架**：论文引入了一种全新的、包容性的AR模型框架，旨在更好地处理音频领域的问题。这一框架不仅考虑时间域信号值的约束或正则化，也考虑到AR系数的限制，这在先前的研究中有所探索，但缺乏一个统一的广泛适用方法。<br/><br/>2. **优化问题和算法**：构建并提供了相应的优化问题定义及解决算法。通过算法设计，论文解决了模型训练中的关键问题，并考虑了不同改进措施对收敛速度的影响。<br/><br/>3. **深入探讨算法计算需求**：详细分析了所提出算法在实际应用中的计算复杂度和资源消耗，为潜在用户和研究人员提供了一定的使用指导和优化建议。<br/><br/>4. **实验验证**：通过音频去剪辑（declipping）和解量化（dequantization）这两个具体任务为例，展示了方法的有效性和实用性。特别是在音乐信号去剪辑和语音去剪辑上，与现有先进方法进行对比，证明了所提方法的竞争力和优势。<br/><br/>5. **引入并评价GLP算法**：论文还引用了一种名为通用线性预测（Generalized Linear Prediction, GLP）的启发式算法。此算法在科学界尚属新知且仅以专利形式出现。通过比较与GLP的性能，突出了所提出方法在去剪辑领域的优越性和创新性。<br/><br/>6. **提供广泛适用和针对性强的解决方案**：论文提供的框架不仅适用于一般信号处理需求，在特定如音乐和语音领域的问题上也展现出高效率和卓越表现，为音频工程和相关研究提供了新的工具和技术参考。 |
| [Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations](https://arxiv.org/abs/2403.00790) | 贡献点:<br/>1. 提出了一种神经编码框架"和谐托罗尼码(Harmonic Toroidal Codes)"，用于实现通过音乐理论结构衍生的流形上的动态活动来执行抽象认知操作。<br/>2. 强调了音乐理论与神经科学之间的潜在连接，使用数学和物理原理在大脑模型中模拟复杂的认知过程。<br/>3. 提供了一种将抽象的心理或认知功能编码到神经系统中的方法，这些功能通过音乐理论结构的流形上的动态活动来实现。 |
| [Automatic Stage Lighting Control: Is it a Rule-Driven Process or Generative Task?](https://arxiv.org/abs/2506.01482) | 贡献点如下：<br/><br/>1. **提出一个全新的概念**：将自动舞台照明控制（ASLC）视为生成任务，而非仅仅分类问题。这是对现有ASLC研究的突破性贡献。<br/><br/>2. **开发Skip-BART模型**：一种端到端模型，它直接从经验丰富的照明工程师处学习，并预测出生动、类人化的舞台灯光效果。<br/><br/>3. **适应BART模型**：将BART模型调整为能够接收音频音乐输入，并生成光色（色调）和光强（亮度）作为输出的创新方法。<br/><br/>4. **引入新型跳过连接机制**：在框架网格中增强音乐与光线之间的关系，以提升Skip-BART模型的表现。<br/><br/>5. **创建首个舞台照明数据集**：这是研究舞台上光照控制领域的重要资源，为后续相关研究提供了宝贵的数据支持。<br/><br/>6. **实施预训练和迁移学习技术**：这些方法有助于改进模型在有限数据条件下的训练效果。<br/><br/>7. **进行全面的验证与评价**：通过定量分析和人类评估双重标准来验证Skip-BART模型。结果显示，它优于传统的基于规则的方法，并且与实际照明工程师的表现仅有较小差距。<br/><br/>8. **提供资源支持进一步研究**：包括自收集的数据集、代码以及训练好的模型参数都已公开发布在GitHub上（https://github.com/RS2002/Skip-BART），为科研人员提供了宝贵的工具和材料。 |
| [Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions](https://arxiv.org/abs/2508.14556) | ### 贡献点:<br/><br/>1. **创新的音乐源分离模型**: 引入了针对准确语音隔离的新音乐源分离模型, 该模型在准确捕获间歇性出现的声音方面表现出色。<br/><br/>2. **改进的时间依赖性捕捉**: 使用Mamba2作为最近的状态空间模型来更好地捕获长距离时间依赖性, 优于基于Transformer的方法。<br/><br/>3. **高效的长时间序列处理**: 结合带分割策略和双路径架构, 提高了对长输入序列的处理效率。<br/><br/>4. **性能优越于最新技术**: 实验结果显示, 所提出的方法在cSDR方面表现出了11.03 dB的卓越性能, 这是迄今为止最佳的结果。<br/><br/>5. **跨输入长度和发音模式的一致性**: 模型展示了在不同输入长度和声音出现模式下的稳定且一致的表现能力。<br/><br/>6. **高分辨率音频处理的有效性**: 证明Mamba基模型对于高分辨率音频处理非常有效。<br/><br/>7. **拓展音频研究的新方向**: 这些成果为音频领域的更广泛应用提供了新的研究路径。 |
| [STSR: High-Fidelity Speech Super-Resolution via Spectral-Transient Context Modeling](https://arxiv.org/abs/2509.03913) | 1. **新型框架STSR**：提出了一种名为STSR（Speech Transform Super-Resolution）的统一端到端框架，该框架在MDCT域中运行以解决现有方法中遇到的问题。这一创新旨在平衡全局谐波一致性与局部瞬变锐度的需求。<br/><br/>2. **Spectral-Contextual Attention机制**：引入了基于频谱上下文的关注机制（Spectral-Contextual Attention），它利用分层窗口来适应性地聚合非局部频谱语境，从而在48kHz下实现了和谐音重建的一致性。<br/><br/>3. **稀疏意识的正则化策略**：采用了针对压缩频谱表示中固有瞬变成分抑制问题的稀疏意识正则化策略（Sparse-aware Regularization Strategy），以提高模型性能。<br/><br/>4. **跨模态超分辨率**：STSR提供了高质量语音恢复的强大、实时范例，同时在感知保真度和零射泛化能力方面均超越了现有最先进的基线方法。<br/><br/>5. **高效性与精确性结合**：这一框架旨在通过融合频谱域的专业知识来解决基于扩散的生成模型面临的实际部署问题（高计算需求）与时间域架构可能丢失长距频谱依赖性和谐波精确对齐能力的问题。 |
| [Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization](https://arxiv.org/abs/2509.15579) | 该论文的贡献点可以归纳如下：<br/><br/>1. **提出了一种基于块的自监督学习（Chunk SSL）算法**，作为一种统一解决方案来处理流式和离线语音预训练中的问题。此方法特别针对低时延语音人机通信的需求而设计。<br/><br/>2. **优化了掩码预测损失**，通过利用未遮盖帧以及同一块和前一个块中的其他未遮盖帧帮助恢复被遮盖的语音帧来提高算法性能。这种方法旨在提高自监督学习在处理不完整句子场景时的适应性。<br/><br/>3. **提出了一种复制与追加的数据增强方法**，以高效地进行基于块的预训练。此方法通过构建一个连贯的、数据丰富的训练环境来优化模型的学习过程。<br/><br/>4. **引入了有限量化（FSQ）模块**对输入语音特征进行了离散化处理，并发现高分辨率的FSQ码本（词汇量高达数百万个）有助于将预训练任务的知识转移至下游任务。这表明编码器在处理复杂语音信号时能够更准确地捕捉模式。<br/><br/>5. **使用了群掩码预测损失**来减少大规模代码库带来的内存和计算成本，从而优化了模型的预训练过程。<br/><br/>6. **实验验证**：通过在Librispeech和Must-C数据集上的两个语音到文本任务（语音识别与语音翻译）中进行实验，证明了所提出方法能够为流式和离线模式下的语音到文本任务提供非常竞争力的结果。这表明该算法不仅高效而且实用，在实际应用中具有很高的潜力。<br/><br/>总之，论文的主要贡献是通过Chunk SSL算法解决了自监督学习在处理不完整语音片段（如流媒体场景）时的局限性，并提出了一系列创新方法来优化预训练过程和提高模型性能，特别是在语音识别与翻译任务上。 |
| [Hear: Hierarchically Enhanced Aesthetic Representations For Multidimensional Music Evaluation](https://arxiv.org/abs/2511.18869) | ###贡献点:<br/><br/>1. **多源多层次表示模块**：提出了一种结合了多个数据来源和尺度的音乐表示方法，旨在获取相辅相成的段落级和曲目级别的特征，从而在音乐感知的复杂性和缺乏标注数据方面提供一种更加全面的方法来评估歌曲美感。<br/><br/>2. **分层增强策略**：引入了一种减轻过拟合问题的分层增强策略，确保模型在训练过程中能够更好地泛化到未见过的数据集，提高评价框架的一致性与稳定性。<br/><br/>3. **混合训练目标**：设计了一个融合回归损失和排名损失的综合训练目标，旨在实现对歌曲评分的精确度量，并可靠地识别顶级歌曲，提供了一种有效的音乐美学评估机制。<br/><br/>4. **实验验证**：通过在ICASSP 2026 SongEval基准测试中的各项指标上与基线模型进行比较，证明了HEAR框架在整个性能上的稳定领先优势。<br/><br/>5. **代码和模型权重的公开可用性**：提供了详细的实现代码和训练好的模型参数，供学术研究者、开发者和其他感兴趣的个人进行实验、进一步的研究或实际应用参考。通过GitHub平台（https://github.com/Eps-Acoustic-Revolution-Lab/EAR_HEAR）实现了成果的开放共享。<br/><br/>这些贡献点展示了HEAR框架在音乐美学评估领域的新突破，通过创新的技术手段和方法学提供了更加全面、精确且可验证的方法来评价歌曲的美感。 |
| [Fun-Audio-Chat Technical Report](https://arxiv.org/abs/2512.20156) | ###贡献点:<br/><br/>1. **Dual-Resolution Speech Representations (DRSR):** 引入了一种新颖的多分辨率语音表示方法，通过将共享的语言模型（LLM）处理音频在高效5Hz下（通过分组令牌），同时引入了演讲细化头部生成高质量的25Hz令牌。这种方法平衡了效率（约减少GPU使用量的50%）和质量。<br/><br/>2. **Core-Cocktail Training:** 提出了一种两级微调方法，其中包括中间合并步骤，以缓解灾难性遗忘问题。通过这种方式，模型能够在保留语言知识的同时，学习到强大的音频理解、推理和生成能力。<br/><br/>3. **Multi-Task DPO Training:** 应用了多任务动态参数优化（DPO）训练策略来增强模型的鲁棒性、音频理解能力、指令遵循能力和语音同理心。这种策略使Fun-Audio-Chat在多个阶段后训练中保持了语言知识的同时，获得了强大的音频处理能力。<br/><br/>4. **Performance and Scalability:** Fun-Audio-Chat 8B和MoE30B-A3B模型在语音到文本（Speech-to-Text）和语音到语音（Speech-to-Speech）任务上表现出竞争力，尤其在口语问答基准测试中名列前茅。它们在音频理解、语音功能调用、指令遵循和语音同理心方面也实现了与当前相似规模模型竞争或更优的性能。<br/><br/>5. **Full-Duplex Variant:** 提出了全双工变体Fun-Audio-Chat-Duplex，它在口语问答任务和全双工交互上表现出强大的性能。该模型提供了完整的双向通信能力。<br/><br/>6. **开源和互动演示工具:** 通过GitHub上的仓库https://github.com/FunAudioLLM/Fun-Audio-Chat，Fun-Audio-Chat-8B的训练和推理代码以及一个互动演示工具被开源发布，使得研究人员和开发者可以访问并进一步研究或应用该模型。 |
